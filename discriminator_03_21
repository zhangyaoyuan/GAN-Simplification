nohup: ignoring input
2019-03-21 21:33:21.170722: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-21 21:33:22.756343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:81:00.0
totalMemory: 10.92GiB freeMemory: 10.77GiB
2019-03-21 21:33:22.756408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-21 21:33:23.380384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-21 21:33:23.380449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-21 21:33:23.380460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-21 21:33:23.381267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10421 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:81:00.0, compute capability: 6.1)
num_filters_total is  4550
using rmsprop as the optimizer for the discriminator
building train model
WARNING:tensorflow:From /home/yaoyuan/simple/network/GAN-Simplification/cnn_discriminator.py:323: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

From /home/yaoyuan/simple/network/GAN-Simplification/cnn_discriminator.py:323: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

done
build_discriminate 
building discriminator model on device /gpu:0
building discriminator model on device /gpu:1
done
discriminator pretrain begins!
the source data in training cnn is prepare_data/good_train_clean.src.5000
the positive data in training cnn is prepare_data/good_train_clean.dst.5000
the negative data in training cnn is prepare_data/good_train_clean.out.5000
train begin
------------------------------------------Hour 0 --------------------
mv: cannot stat 'prepare_data/good_train_clean.dst.5000.shuf': No such file or directory
mv: cannot stat 'prepare_data/good_train_clean.out.5000.shuf': No such file or directory
load vocab successfully!!
Epoch : 0
epoch 0, samples 256, loss 4.993122, accuracy 0.503906 BatchTime 15.356199, for discriminator pretraining 
epoch 0, samples 512, loss 131.055801, accuracy 0.500000 BatchTime 3.045396, for discriminator pretraining 
epoch 0, samples 768, loss 2.490061, accuracy 0.535156 BatchTime 1.962189, for discriminator pretraining 
epoch 0, samples 1024, loss 21.106113, accuracy 0.496094 BatchTime 1.898373, for discriminator pretraining 
epoch 0, samples 1280, loss 115.373825, accuracy 0.500000 BatchTime 1.776621, for discriminator pretraining 
epoch 0, samples 1536, loss 16.459061, accuracy 0.476562 BatchTime 1.822864, for discriminator pretraining 
epoch 0, samples 1792, loss 108.614563, accuracy 0.500000 BatchTime 1.788110, for discriminator pretraining 
epoch 0, samples 2048, loss 12.598020, accuracy 0.476562 BatchTime 1.700694, for discriminator pretraining 
epoch 0, samples 2304, loss 104.188614, accuracy 0.500000 BatchTime 1.684173, for discriminator pretraining 
epoch 0, samples 2560, loss 10.528953, accuracy 0.476562 BatchTime 1.762329, for discriminator pretraining 
epoch 0, samples 2816, loss 97.055664, accuracy 0.500000 BatchTime 1.766116, for discriminator pretraining 
epoch 0, samples 3072, loss 9.670112, accuracy 0.488281 BatchTime 1.640089, for discriminator pretraining 
epoch 0, samples 3328, loss 97.334305, accuracy 0.500000 BatchTime 1.676549, for discriminator pretraining 
epoch 0, samples 3584, loss 8.195452, accuracy 0.492188 BatchTime 1.768460, for discriminator pretraining 
epoch 0, samples 3840, loss 93.320999, accuracy 0.500000 BatchTime 1.696989, for discriminator pretraining 
epoch 0, samples 4096, loss 6.760793, accuracy 0.484375 BatchTime 1.725455, for discriminator pretraining 
epoch 0, samples 4352, loss 90.302643, accuracy 0.500000 BatchTime 1.770393, for discriminator pretraining 
epoch 0, samples 4608, loss 6.201355, accuracy 0.515625 BatchTime 1.686545, for discriminator pretraining 
epoch 0, samples 4864, loss 89.182846, accuracy 0.500000 BatchTime 1.720702, for discriminator pretraining 
epoch 0, samples 5120, loss 6.162010, accuracy 0.503906 BatchTime 1.602925, for discriminator pretraining 
epoch 0, samples 5376, loss 89.083015, accuracy 0.500000 BatchTime 1.742863, for discriminator pretraining 
epoch 0, samples 5632, loss 5.383407, accuracy 0.492188 BatchTime 1.779043, for discriminator pretraining 
epoch 0, samples 5888, loss 86.991226, accuracy 0.500000 BatchTime 1.710015, for discriminator pretraining 
epoch 0, samples 6144, loss 4.882968, accuracy 0.500000 BatchTime 1.766437, for discriminator pretraining 
epoch 0, samples 6400, loss 83.946152, accuracy 0.500000 BatchTime 1.742714, for discriminator pretraining 
epoch 0, samples 6656, loss 5.021609, accuracy 0.515625 BatchTime 1.746849, for discriminator pretraining 
epoch 0, samples 6912, loss 83.317627, accuracy 0.500000 BatchTime 1.780350, for discriminator pretraining 
epoch 0, samples 7168, loss 4.159873, accuracy 0.515625 BatchTime 1.688197, for discriminator pretraining 
epoch 0, samples 7424, loss 82.010498, accuracy 0.500000 BatchTime 1.651289, for discriminator pretraining 
epoch 0, samples 7680, loss 4.832041, accuracy 0.503906 BatchTime 1.772723, for discriminator pretraining 
epoch 0, samples 7936, loss 80.286148, accuracy 0.500000 BatchTime 1.765973, for discriminator pretraining 
epoch 0, samples 8192, loss 6.065933, accuracy 0.515625 BatchTime 1.806820, for discriminator pretraining 
Killed
nohup: ignoring input
2019-03-21 21:35:02.560354: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-21 21:35:03.987808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:81:00.0
totalMemory: 10.92GiB freeMemory: 10.77GiB
2019-03-21 21:35:03.987904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-03-21 21:35:04.577111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-21 21:35:04.577164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-03-21 21:35:04.577171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-03-21 21:35:04.577728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10421 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:81:00.0, compute capability: 6.1)
num_filters_total is  4550
using rmsprop as the optimizer for the discriminator
building train model
WARNING:tensorflow:From /home/yaoyuan/simple/network/GAN-Simplification/cnn_discriminator.py:323: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

From /home/yaoyuan/simple/network/GAN-Simplification/cnn_discriminator.py:323: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

done
build_discriminate 
building discriminator model on device /gpu:0
building discriminator model on device /gpu:1
done
reloading file from save_model1_3000tok/pre_discriminator/dis_model_step_0_0000
INFO:tensorflow:Restoring parameters from save_model1_3000tok/pre_discriminator/dis_model_step_0_0000
Restoring parameters from save_model1_3000tok/pre_discriminator/dis_model_step_0_0000
reloading file done
discriminator pretrain begins!
the source data in training cnn is prepare_data/good_train_clean.src.5000
the positive data in training cnn is prepare_data/good_train_clean.dst.5000
the negative data in training cnn is prepare_data/good_train_clean.out.5000
train begin
------------------------------------------Hour 0 --------------------
load vocab successfully!!
Epoch : 0
epoch 0, samples 256, loss 2.249419, accuracy 0.644531 BatchTime 15.658531, for discriminator pretraining 
epoch 0, samples 512, loss 1.555151, accuracy 0.714844 BatchTime 2.840273, for discriminator pretraining 
epoch 0, samples 768, loss 2.414926, accuracy 0.660156 BatchTime 1.751740, for discriminator pretraining 
epoch 0, samples 1024, loss 2.397025, accuracy 0.660156 BatchTime 1.845993, for discriminator pretraining 
epoch 0, samples 1280, loss 1.973049, accuracy 0.691406 BatchTime 1.791373, for discriminator pretraining 
epoch 0, samples 1536, loss 2.140435, accuracy 0.695312 BatchTime 1.787190, for discriminator pretraining 
epoch 0, samples 1792, loss 1.740111, accuracy 0.703125 BatchTime 1.773035, for discriminator pretraining 
epoch 0, samples 2048, loss 2.203991, accuracy 0.691406 BatchTime 1.632095, for discriminator pretraining 
epoch 0, samples 2304, loss 1.982958, accuracy 0.691406 BatchTime 1.744054, for discriminator pretraining 
epoch 0, samples 2560, loss 2.266181, accuracy 0.683594 BatchTime 1.750940, for discriminator pretraining 
epoch 0, samples 2816, loss 1.872849, accuracy 0.671875 BatchTime 1.666547, for discriminator pretraining 
epoch 0, samples 3072, loss 2.394132, accuracy 0.691406 BatchTime 1.607645, for discriminator pretraining 
epoch 0, samples 3328, loss 2.128565, accuracy 0.683594 BatchTime 1.606477, for discriminator pretraining 
epoch 0, samples 3584, loss 1.868293, accuracy 0.718750 BatchTime 1.732294, for discriminator pretraining 
epoch 0, samples 3840, loss 1.405064, accuracy 0.757812 BatchTime 1.707926, for discriminator pretraining 
epoch 0, samples 4096, loss 2.543772, accuracy 0.671875 BatchTime 1.623917, for discriminator pretraining 
epoch 0, samples 4352, loss 2.285710, accuracy 0.660156 BatchTime 1.590811, for discriminator pretraining 
epoch 0, samples 4608, loss 2.114449, accuracy 0.726562 BatchTime 1.625632, for discriminator pretraining 
epoch 0, samples 4864, loss 2.145014, accuracy 0.648438 BatchTime 1.752805, for discriminator pretraining 
epoch 0, samples 5120, loss 2.574161, accuracy 0.667969 BatchTime 1.697950, for discriminator pretraining 
epoch 0, samples 5376, loss 1.979825, accuracy 0.703125 BatchTime 1.609015, for discriminator pretraining 
epoch 0, samples 5632, loss 1.953199, accuracy 0.703125 BatchTime 1.596312, for discriminator pretraining 
epoch 0, samples 5888, loss 1.873091, accuracy 0.687500 BatchTime 1.621715, for discriminator pretraining 
epoch 0, samples 6144, loss 2.114422, accuracy 0.718750 BatchTime 1.605410, for discriminator pretraining 
epoch 0, samples 6400, loss 1.680206, accuracy 0.707031 BatchTime 1.736198, for discriminator pretraining 
epoch 0, samples 6656, loss 2.055683, accuracy 0.707031 BatchTime 1.672514, for discriminator pretraining 
epoch 0, samples 6912, loss 2.363640, accuracy 0.656250 BatchTime 1.603074, for discriminator pretraining 
epoch 0, samples 7168, loss 2.451050, accuracy 0.640625 BatchTime 1.624416, for discriminator pretraining 
epoch 0, samples 7424, loss 1.633580, accuracy 0.710938 BatchTime 1.621502, for discriminator pretraining 
epoch 0, samples 7680, loss 2.071701, accuracy 0.687500 BatchTime 1.649151, for discriminator pretraining 
epoch 0, samples 7936, loss 1.909821, accuracy 0.703125 BatchTime 1.731332, for discriminator pretraining 
epoch 0, samples 8192, loss 2.731964, accuracy 0.644531 BatchTime 1.613967, for discriminator pretraining 
epoch 0, samples 8448, loss 1.906080, accuracy 0.683594 BatchTime 1.830796, for discriminator pretraining 
epoch 0, samples 8704, loss 2.450717, accuracy 0.644531 BatchTime 1.636843, for discriminator pretraining 
epoch 0, samples 8960, loss 2.896130, accuracy 0.652344 BatchTime 1.723040, for discriminator pretraining 
epoch 0, samples 9216, loss 2.596375, accuracy 0.571429 BatchTime 6.418180, for discriminator pretraining 
Seen  8988  examples for discriminator. Time Cost :  79.98155522346497
load vocab successfully!!
Epoch : 1
epoch 1, samples 9472, loss 0.888963, accuracy 0.800781 BatchTime 2.614695, for discriminator pretraining 
epoch 1, samples 9728, loss 1.763930, accuracy 0.718750 BatchTime 1.850977, for discriminator pretraining 
epoch 1, samples 9984, loss 2.177273, accuracy 0.679688 BatchTime 1.661630, for discriminator pretraining 
epoch 1, samples 10240, loss 1.994225, accuracy 0.679688 BatchTime 1.758471, for discriminator pretraining 
epoch 1, samples 10496, loss 1.932010, accuracy 0.718750 BatchTime 1.631269, for discriminator pretraining 
epoch 1, samples 10752, loss 1.988307, accuracy 0.632812 BatchTime 1.608360, for discriminator pretraining 
epoch 1, samples 11008, loss 2.364236, accuracy 0.722656 BatchTime 1.587522, for discriminator pretraining 
epoch 1, samples 11264, loss 1.649462, accuracy 0.730469 BatchTime 1.592017, for discriminator pretraining 
epoch 1, samples 11520, loss 1.752948, accuracy 0.710938 BatchTime 1.682243, for discriminator pretraining 
epoch 1, samples 11776, loss 1.801352, accuracy 0.683594 BatchTime 1.732997, for discriminator pretraining 
epoch 1, samples 12032, loss 2.362968, accuracy 0.710938 BatchTime 1.645800, for discriminator pretraining 
epoch 1, samples 12288, loss 1.464714, accuracy 0.726562 BatchTime 1.630898, for discriminator pretraining 
epoch 1, samples 12544, loss 1.947723, accuracy 0.679688 BatchTime 1.740541, for discriminator pretraining 
epoch 1, samples 12800, loss 1.521346, accuracy 0.707031 BatchTime 1.712399, for discriminator pretraining 
epoch 1, samples 13056, loss 2.295463, accuracy 0.683594 BatchTime 1.574063, for discriminator pretraining 
epoch 1, samples 13312, loss 2.247446, accuracy 0.671875 BatchTime 1.607219, for discriminator pretraining 
epoch 1, samples 13568, loss 2.003640, accuracy 0.734375 BatchTime 1.620406, for discriminator pretraining 
epoch 1, samples 13824, loss 1.292671, accuracy 0.726562 BatchTime 1.617236, for discriminator pretraining 
epoch 1, samples 14080, loss 2.232970, accuracy 0.699219 BatchTime 1.654550, for discriminator pretraining 
epoch 1, samples 14336, loss 1.679018, accuracy 0.730469 BatchTime 1.745715, for discriminator pretraining 
epoch 1, samples 14592, loss 1.555692, accuracy 0.718750 BatchTime 1.652536, for discriminator pretraining 
epoch 1, samples 14848, loss 1.995567, accuracy 0.664062 BatchTime 1.591825, for discriminator pretraining 
epoch 1, samples 15104, loss 1.867939, accuracy 0.687500 BatchTime 1.565257, for discriminator pretraining 
epoch 1, samples 15360, loss 2.053597, accuracy 0.664062 BatchTime 1.598976, for discriminator pretraining 
epoch 1, samples 15616, loss 1.972934, accuracy 0.714844 BatchTime 1.672083, for discriminator pretraining 
epoch 1, samples 15872, loss 1.895054, accuracy 0.714844 BatchTime 1.722559, for discriminator pretraining 
epoch 1, samples 16128, loss 1.956835, accuracy 0.679688 BatchTime 1.664278, for discriminator pretraining 
epoch 1, samples 16384, loss 1.929413, accuracy 0.675781 BatchTime 1.662250, for discriminator pretraining 
epoch 1, samples 16640, loss 1.988698, accuracy 0.703125 BatchTime 1.594898, for discriminator pretraining 
epoch 1, samples 16896, loss 1.840024, accuracy 0.695312 BatchTime 1.737352, for discriminator pretraining 
epoch 1, samples 17152, loss 2.154666, accuracy 0.683594 BatchTime 1.737077, for discriminator pretraining 
epoch 1, samples 17408, loss 1.457087, accuracy 0.714844 BatchTime 1.651397, for discriminator pretraining 
epoch 1, samples 17664, loss 1.649112, accuracy 0.738281 BatchTime 1.581554, for discriminator pretraining 
epoch 1, samples 17920, loss 2.160685, accuracy 0.687500 BatchTime 1.581622, for discriminator pretraining 
epoch 1, samples 18176, loss 1.934033, accuracy 0.707031 BatchTime 1.701071, for discriminator pretraining 
epoch 1, samples 18432, loss 2.046951, accuracy 0.642857 BatchTime 0.971681, for discriminator pretraining 
Seen  8988  examples for discriminator. Time Cost :  59.21663951873779
mv: cannot stat 'prepare_data/good_train_clean.dst.5000.shuf': No such file or directory
load vocab successfully!!
Epoch : 2
epoch 2, samples 18688, loss 0.693969, accuracy 0.824219 BatchTime 2.478741, for discriminator pretraining 
epoch 2, samples 18944, loss 1.692190, accuracy 0.738281 BatchTime 1.738482, for discriminator pretraining 
epoch 2, samples 19200, loss 2.109944, accuracy 0.699219 BatchTime 1.604095, for discriminator pretraining 
epoch 2, samples 19456, loss 1.757655, accuracy 0.734375 BatchTime 1.591226, for discriminator pretraining 
epoch 2, samples 19712, loss 1.907422, accuracy 0.691406 BatchTime 1.626903, for discriminator pretraining 
epoch 2, samples 19968, loss 1.837099, accuracy 0.703125 BatchTime 1.720307, for discriminator pretraining 
epoch 2, samples 20224, loss 1.821118, accuracy 0.695312 BatchTime 1.776038, for discriminator pretraining 
epoch 2, samples 20480, loss 2.328013, accuracy 0.695312 BatchTime 1.633548, for discriminator pretraining 
epoch 2, samples 20736, loss 1.496475, accuracy 0.699219 BatchTime 1.698696, for discriminator pretraining 
epoch 2, samples 20992, loss 1.552569, accuracy 0.734375 BatchTime 1.596298, for discriminator pretraining 
epoch 2, samples 21248, loss 1.407467, accuracy 0.710938 BatchTime 1.656893, for discriminator pretraining 
epoch 2, samples 21504, loss 1.461858, accuracy 0.769531 BatchTime 1.629126, for discriminator pretraining 
epoch 2, samples 21760, loss 1.855766, accuracy 0.699219 BatchTime 1.691211, for discriminator pretraining 
epoch 2, samples 22016, loss 1.618982, accuracy 0.726562 BatchTime 1.670724, for discriminator pretraining 
epoch 2, samples 22272, loss 1.619756, accuracy 0.703125 BatchTime 1.786158, for discriminator pretraining 
epoch 2, samples 22528, loss 1.586749, accuracy 0.734375 BatchTime 1.761702, for discriminator pretraining 
epoch 2, samples 22784, loss 1.706900, accuracy 0.726562 BatchTime 1.703928, for discriminator pretraining 
epoch 2, samples 23040, loss 1.636618, accuracy 0.738281 BatchTime 1.627494, for discriminator pretraining 
epoch 2, samples 23296, loss 1.766288, accuracy 0.699219 BatchTime 1.648539, for discriminator pretraining 
epoch 2, samples 23552, loss 1.459191, accuracy 0.761719 BatchTime 1.681474, for discriminator pretraining 
epoch 2, samples 23808, loss 1.386861, accuracy 0.738281 BatchTime 1.766170, for discriminator pretraining 
epoch 2, samples 24064, loss 1.813741, accuracy 0.718750 BatchTime 1.601804, for discriminator pretraining 
epoch 2, samples 24320, loss 1.698869, accuracy 0.687500 BatchTime 1.663944, for discriminator pretraining 
epoch 2, samples 24576, loss 1.520453, accuracy 0.730469 BatchTime 1.717601, for discriminator pretraining 
epoch 2, samples 24832, loss 1.814452, accuracy 0.718750 BatchTime 1.701604, for discriminator pretraining 
epoch 2, samples 25088, loss 1.665852, accuracy 0.742188 BatchTime 1.673588, for discriminator pretraining 
epoch 2, samples 25344, loss 1.481828, accuracy 0.695312 BatchTime 1.719258, for discriminator pretraining 
epoch 2, samples 25600, loss 1.661890, accuracy 0.726562 BatchTime 1.655591, for discriminator pretraining 
save params when epoch 2, samples 25600
epoch 2, samples 25856, loss 1.527315, accuracy 0.722656 BatchTime 1.770644, for discriminator pretraining 
epoch 2, samples 26112, loss 1.787282, accuracy 0.703125 BatchTime 1.755237, for discriminator pretraining 
epoch 2, samples 26368, loss 2.185593, accuracy 0.679688 BatchTime 1.664622, for discriminator pretraining 
epoch 2, samples 26624, loss 2.185161, accuracy 0.671875 BatchTime 1.609735, for discriminator pretraining 
epoch 2, samples 26880, loss 1.575605, accuracy 0.691406 BatchTime 1.618394, for discriminator pretraining 
epoch 2, samples 27136, loss 1.805645, accuracy 0.722656 BatchTime 1.716458, for discriminator pretraining 
epoch 2, samples 27392, loss 1.229298, accuracy 0.746094 BatchTime 1.766607, for discriminator pretraining 
epoch 2, samples 27648, loss 0.933041, accuracy 0.781250 BatchTime 6.585298, for discriminator pretraining 
Seen  8992  examples for discriminator. Time Cost :  72.71628665924072
load vocab successfully!!
Epoch : 3
epoch 3, samples 27904, loss 0.879293, accuracy 0.804688 BatchTime 2.481529, for discriminator pretraining 
epoch 3, samples 28160, loss 1.120273, accuracy 0.761719 BatchTime 1.862234, for discriminator pretraining 
epoch 3, samples 28416, loss 1.379097, accuracy 0.785156 BatchTime 1.710908, for discriminator pretraining 
epoch 3, samples 28672, loss 1.205490, accuracy 0.753906 BatchTime 1.626000, for discriminator pretraining 
epoch 3, samples 28928, loss 1.752519, accuracy 0.730469 BatchTime 1.679113, for discriminator pretraining 
epoch 3, samples 29184, loss 1.360696, accuracy 0.738281 BatchTime 1.600129, for discriminator pretraining 
epoch 3, samples 29440, loss 1.247764, accuracy 0.769531 BatchTime 1.644127, for discriminator pretraining 
epoch 3, samples 29696, loss 0.974828, accuracy 0.757812 BatchTime 1.684561, for discriminator pretraining 
epoch 3, samples 29952, loss 1.451700, accuracy 0.746094 BatchTime 1.689139, for discriminator pretraining 
epoch 3, samples 30208, loss 1.382101, accuracy 0.679688 BatchTime 1.640726, for discriminator pretraining 
epoch 3, samples 30464, loss 1.560246, accuracy 0.769531 BatchTime 1.639411, for discriminator pretraining 
epoch 3, samples 30720, loss 1.153484, accuracy 0.750000 BatchTime 1.610196, for discriminator pretraining 
epoch 3, samples 30976, loss 1.389043, accuracy 0.750000 BatchTime 1.758143, for discriminator pretraining 
epoch 3, samples 31232, loss 1.373835, accuracy 0.738281 BatchTime 1.739704, for discriminator pretraining 
epoch 3, samples 31488, loss 1.599837, accuracy 0.730469 BatchTime 1.647824, for discriminator pretraining 
epoch 3, samples 31744, loss 1.421659, accuracy 0.734375 BatchTime 1.655280, for discriminator pretraining 
epoch 3, samples 32000, loss 1.355167, accuracy 0.777344 BatchTime 1.632684, for discriminator pretraining 
epoch 3, samples 32256, loss 1.055328, accuracy 0.789062 BatchTime 1.615466, for discriminator pretraining 
epoch 3, samples 32512, loss 1.529601, accuracy 0.757812 BatchTime 1.715666, for discriminator pretraining 
epoch 3, samples 32768, loss 1.265848, accuracy 0.730469 BatchTime 1.731209, for discriminator pretraining 
epoch 3, samples 33024, loss 1.430514, accuracy 0.738281 BatchTime 1.649635, for discriminator pretraining 
epoch 3, samples 33280, loss 1.528261, accuracy 0.710938 BatchTime 1.637896, for discriminator pretraining 
epoch 3, samples 33536, loss 1.729323, accuracy 0.703125 BatchTime 1.676214, for discriminator pretraining 
epoch 3, samples 33792, loss 1.450235, accuracy 0.722656 BatchTime 1.612237, for discriminator pretraining 
epoch 3, samples 34048, loss 1.169023, accuracy 0.757812 BatchTime 1.662835, for discriminator pretraining 
epoch 3, samples 34304, loss 1.783141, accuracy 0.699219 BatchTime 1.670116, for discriminator pretraining 
epoch 3, samples 34560, loss 2.156672, accuracy 0.707031 BatchTime 1.750814, for discriminator pretraining 
epoch 3, samples 34816, loss 1.230119, accuracy 0.730469 BatchTime 1.682393, for discriminator pretraining 
epoch 3, samples 35072, loss 1.161013, accuracy 0.781250 BatchTime 1.651206, for discriminator pretraining 
epoch 3, samples 35328, loss 1.287926, accuracy 0.726562 BatchTime 1.613176, for discriminator pretraining 
epoch 3, samples 35584, loss 1.552925, accuracy 0.726562 BatchTime 1.634716, for discriminator pretraining 
epoch 3, samples 35840, loss 1.379002, accuracy 0.722656 BatchTime 1.614314, for discriminator pretraining 
epoch 3, samples 36096, loss 1.227837, accuracy 0.765625 BatchTime 1.710869, for discriminator pretraining 
epoch 3, samples 36352, loss 1.452018, accuracy 0.718750 BatchTime 1.732154, for discriminator pretraining 
epoch 3, samples 36608, loss 1.723125, accuracy 0.703125 BatchTime 1.850444, for discriminator pretraining 
epoch 3, samples 36864, loss 2.929233, accuracy 0.545455 BatchTime 6.318237, for discriminator pretraining 
Seen  8982  examples for discriminator. Time Cost :  65.17609477043152
load vocab successfully!!
Epoch : 4
epoch 4, samples 37120, loss 0.569979, accuracy 0.847656 BatchTime 2.512350, for discriminator pretraining 
epoch 4, samples 37376, loss 0.833495, accuracy 0.816406 BatchTime 1.754567, for discriminator pretraining 
epoch 4, samples 37632, loss 1.431824, accuracy 0.734375 BatchTime 1.682244, for discriminator pretraining 
epoch 4, samples 37888, loss 2.332127, accuracy 0.664062 BatchTime 1.753697, for discriminator pretraining 
epoch 4, samples 38144, loss 1.346484, accuracy 0.718750 BatchTime 1.705506, for discriminator pretraining 
epoch 4, samples 38400, loss 1.234692, accuracy 0.757812 BatchTime 1.587824, for discriminator pretraining 
epoch 4, samples 38656, loss 1.179228, accuracy 0.765625 BatchTime 1.684836, for discriminator pretraining 
epoch 4, samples 38912, loss 0.897167, accuracy 0.773438 BatchTime 1.723459, for discriminator pretraining 
epoch 4, samples 39168, loss 1.090329, accuracy 0.777344 BatchTime 1.755246, for discriminator pretraining 
epoch 4, samples 39424, loss 1.726675, accuracy 0.718750 BatchTime 1.614633, for discriminator pretraining 
epoch 4, samples 39680, loss 1.324345, accuracy 0.765625 BatchTime 1.625299, for discriminator pretraining 
epoch 4, samples 39936, loss 1.202384, accuracy 0.789062 BatchTime 1.672010, for discriminator pretraining 
epoch 4, samples 40192, loss 1.430890, accuracy 0.703125 BatchTime 1.752425, for discriminator pretraining 
epoch 4, samples 40448, loss 1.534483, accuracy 0.722656 BatchTime 1.747267, for discriminator pretraining 
epoch 4, samples 40704, loss 1.100486, accuracy 0.753906 BatchTime 1.651039, for discriminator pretraining 
epoch 4, samples 40960, loss 1.243171, accuracy 0.738281 BatchTime 1.593961, for discriminator pretraining 
epoch 4, samples 41216, loss 1.055659, accuracy 0.761719 BatchTime 1.703985, for discriminator pretraining 
epoch 4, samples 41472, loss 1.094105, accuracy 0.750000 BatchTime 1.712950, for discriminator pretraining 
epoch 4, samples 41728, loss 1.182063, accuracy 0.773438 BatchTime 1.653044, for discriminator pretraining 
epoch 4, samples 41984, loss 1.480401, accuracy 0.757812 BatchTime 1.599149, for discriminator pretraining 
epoch 4, samples 42240, loss 1.701807, accuracy 0.687500 BatchTime 1.645715, for discriminator pretraining 
epoch 4, samples 42496, loss 1.276415, accuracy 0.769531 BatchTime 1.576378, for discriminator pretraining 
epoch 4, samples 42752, loss 0.902727, accuracy 0.789062 BatchTime 1.738728, for discriminator pretraining 
epoch 4, samples 43008, loss 1.313379, accuracy 0.773438 BatchTime 1.742312, for discriminator pretraining 
epoch 4, samples 43264, loss 1.105533, accuracy 0.789062 BatchTime 1.611662, for discriminator pretraining 
epoch 4, samples 43520, loss 1.424139, accuracy 0.718750 BatchTime 1.631399, for discriminator pretraining 
epoch 4, samples 43776, loss 1.103388, accuracy 0.789062 BatchTime 1.619148, for discriminator pretraining 
epoch 4, samples 44032, loss 1.188251, accuracy 0.761719 BatchTime 1.611048, for discriminator pretraining 
epoch 4, samples 44288, loss 1.281984, accuracy 0.761719 BatchTime 1.679028, for discriminator pretraining 
epoch 4, samples 44544, loss 1.416839, accuracy 0.789062 BatchTime 1.666773, for discriminator pretraining 
epoch 4, samples 44800, loss 1.250280, accuracy 0.753906 BatchTime 1.716795, for discriminator pretraining 
epoch 4, samples 45056, loss 1.192602, accuracy 0.773438 BatchTime 1.686044, for discriminator pretraining 
epoch 4, samples 45312, loss 1.584643, accuracy 0.699219 BatchTime 1.614763, for discriminator pretraining 
epoch 4, samples 45568, loss 2.262409, accuracy 0.667969 BatchTime 1.622618, for discriminator pretraining 
epoch 4, samples 45824, loss 1.033853, accuracy 0.816406 BatchTime 1.652507, for discriminator pretraining 
epoch 4, samples 46080, loss 1.371458, accuracy 0.700000 BatchTime 7.046294, for discriminator pretraining 
Seen  8980  examples for discriminator. Time Cost :  65.55475330352783
load vocab successfully!!
Epoch : 5
epoch 5, samples 46336, loss 0.731156, accuracy 0.835938 BatchTime 2.659831, for discriminator pretraining 
epoch 5, samples 46592, loss 1.097135, accuracy 0.765625 BatchTime 1.851712, for discriminator pretraining 
epoch 5, samples 46848, loss 1.734385, accuracy 0.707031 BatchTime 1.753366, for discriminator pretraining 
epoch 5, samples 47104, loss 1.247168, accuracy 0.753906 BatchTime 1.641981, for discriminator pretraining 
epoch 5, samples 47360, loss 1.036943, accuracy 0.777344 BatchTime 1.673394, for discriminator pretraining 
epoch 5, samples 47616, loss 1.212364, accuracy 0.753906 BatchTime 1.619123, for discriminator pretraining 
epoch 5, samples 47872, loss 1.019987, accuracy 0.757812 BatchTime 1.648357, for discriminator pretraining 
epoch 5, samples 48128, loss 1.310859, accuracy 0.761719 BatchTime 1.633798, for discriminator pretraining 
epoch 5, samples 48384, loss 1.629346, accuracy 0.671875 BatchTime 1.785529, for discriminator pretraining 
epoch 5, samples 48640, loss 1.647341, accuracy 0.746094 BatchTime 1.723676, for discriminator pretraining 
epoch 5, samples 48896, loss 0.901739, accuracy 0.785156 BatchTime 1.686958, for discriminator pretraining 
epoch 5, samples 49152, loss 1.010376, accuracy 0.777344 BatchTime 1.628690, for discriminator pretraining 
epoch 5, samples 49408, loss 1.211487, accuracy 0.773438 BatchTime 1.678970, for discriminator pretraining 
epoch 5, samples 49664, loss 1.233656, accuracy 0.781250 BatchTime 1.654007, for discriminator pretraining 
epoch 5, samples 49920, loss 1.159584, accuracy 0.781250 BatchTime 1.797555, for discriminator pretraining 
epoch 5, samples 50176, loss 1.053296, accuracy 0.796875 BatchTime 1.751159, for discriminator pretraining 
epoch 5, samples 50432, loss 1.074098, accuracy 0.761719 BatchTime 1.666721, for discriminator pretraining 
epoch 5, samples 50688, loss 1.377952, accuracy 0.761719 BatchTime 1.638299, for discriminator pretraining 
epoch 5, samples 50944, loss 0.887199, accuracy 0.781250 BatchTime 1.668756, for discriminator pretraining 
epoch 5, samples 51200, loss 1.171652, accuracy 0.734375 BatchTime 1.641275, for discriminator pretraining 
save params when epoch 5, samples 51200
epoch 5, samples 51456, loss 1.043463, accuracy 0.808594 BatchTime 1.809161, for discriminator pretraining 
epoch 5, samples 51712, loss 1.110676, accuracy 0.757812 BatchTime 1.792359, for discriminator pretraining 
epoch 5, samples 51968, loss 1.203487, accuracy 0.750000 BatchTime 1.698932, for discriminator pretraining 
epoch 5, samples 52224, loss 1.007746, accuracy 0.804688 BatchTime 1.598219, for discriminator pretraining 
epoch 5, samples 52480, loss 0.893227, accuracy 0.796875 BatchTime 1.677269, for discriminator pretraining 
epoch 5, samples 52736, loss 1.565156, accuracy 0.714844 BatchTime 1.652838, for discriminator pretraining 
epoch 5, samples 52992, loss 1.479129, accuracy 0.730469 BatchTime 1.753509, for discriminator pretraining 
epoch 5, samples 53248, loss 1.255957, accuracy 0.757812 BatchTime 1.705266, for discriminator pretraining 
epoch 5, samples 53504, loss 1.017565, accuracy 0.804688 BatchTime 1.703377, for discriminator pretraining 
epoch 5, samples 53760, loss 1.145763, accuracy 0.753906 BatchTime 1.641499, for discriminator pretraining 
epoch 5, samples 54016, loss 0.920891, accuracy 0.812500 BatchTime 1.601707, for discriminator pretraining 
epoch 5, samples 54272, loss 1.223861, accuracy 0.761719 BatchTime 1.599306, for discriminator pretraining 
epoch 5, samples 54528, loss 1.559463, accuracy 0.761719 BatchTime 1.674650, for discriminator pretraining 
epoch 5, samples 54784, loss 1.519415, accuracy 0.750000 BatchTime 1.757928, for discriminator pretraining 
epoch 5, samples 55040, loss 0.780979, accuracy 0.820312 BatchTime 1.723454, for discriminator pretraining 
epoch 5, samples 55296, loss 0.667326, accuracy 0.894737 BatchTime 6.498163, for discriminator pretraining 
Seen  8998  examples for discriminator. Time Cost :  71.36900615692139
mv: cannot stat 'prepare_data/good_train_clean.dst.5000.shuf': No such file or directory
load vocab successfully!!
Epoch : 6
epoch 6, samples 55552, loss 0.506640, accuracy 0.843750 BatchTime 2.549848, for discriminator pretraining 
epoch 6, samples 55808, loss 0.631897, accuracy 0.847656 BatchTime 1.863674, for discriminator pretraining 
epoch 6, samples 56064, loss 0.686843, accuracy 0.828125 BatchTime 1.753729, for discriminator pretraining 
epoch 6, samples 56320, loss 1.206155, accuracy 0.757812 BatchTime 1.611633, for discriminator pretraining 
epoch 6, samples 56576, loss 1.291494, accuracy 0.777344 BatchTime 1.678226, for discriminator pretraining 
epoch 6, samples 56832, loss 1.995504, accuracy 0.707031 BatchTime 1.733163, for discriminator pretraining 
epoch 6, samples 57088, loss 1.421168, accuracy 0.781250 BatchTime 1.752176, for discriminator pretraining 
epoch 6, samples 57344, loss 1.412854, accuracy 0.777344 BatchTime 1.607406, for discriminator pretraining 
epoch 6, samples 57600, loss 1.229360, accuracy 0.785156 BatchTime 1.651444, for discriminator pretraining 
epoch 6, samples 57856, loss 1.479418, accuracy 0.738281 BatchTime 1.604011, for discriminator pretraining 
epoch 6, samples 58112, loss 1.616428, accuracy 0.714844 BatchTime 1.652616, for discriminator pretraining 
epoch 6, samples 58368, loss 1.297617, accuracy 0.750000 BatchTime 1.613679, for discriminator pretraining 
epoch 6, samples 58624, loss 0.891230, accuracy 0.812500 BatchTime 1.848280, for discriminator pretraining 
epoch 6, samples 58880, loss 0.806630, accuracy 0.777344 BatchTime 1.741287, for discriminator pretraining 
epoch 6, samples 59136, loss 0.607713, accuracy 0.843750 BatchTime 1.651870, for discriminator pretraining 
epoch 6, samples 59392, loss 0.808400, accuracy 0.789062 BatchTime 1.642323, for discriminator pretraining 
epoch 6, samples 59648, loss 0.974866, accuracy 0.789062 BatchTime 1.769873, for discriminator pretraining 
epoch 6, samples 59904, loss 0.909476, accuracy 0.804688 BatchTime 1.752419, for discriminator pretraining 
epoch 6, samples 60160, loss 1.281352, accuracy 0.777344 BatchTime 1.639566, for discriminator pretraining 
epoch 6, samples 60416, loss 1.729842, accuracy 0.738281 BatchTime 1.623555, for discriminator pretraining 
epoch 6, samples 60672, loss 1.461682, accuracy 0.753906 BatchTime 1.663160, for discriminator pretraining 
epoch 6, samples 60928, loss 1.067910, accuracy 0.750000 BatchTime 1.717583, for discriminator pretraining 
epoch 6, samples 61184, loss 1.621255, accuracy 0.710938 BatchTime 1.677562, for discriminator pretraining 
epoch 6, samples 61440, loss 1.362187, accuracy 0.753906 BatchTime 1.664252, for discriminator pretraining 
epoch 6, samples 61696, loss 1.105456, accuracy 0.777344 BatchTime 1.661054, for discriminator pretraining 
epoch 6, samples 61952, loss 1.115480, accuracy 0.785156 BatchTime 1.597669, for discriminator pretraining 
epoch 6, samples 62208, loss 0.932608, accuracy 0.789062 BatchTime 1.747262, for discriminator pretraining 
epoch 6, samples 62464, loss 1.026462, accuracy 0.769531 BatchTime 1.722279, for discriminator pretraining 
epoch 6, samples 62720, loss 1.001508, accuracy 0.800781 BatchTime 1.660204, for discriminator pretraining 
epoch 6, samples 62976, loss 1.207638, accuracy 0.757812 BatchTime 1.630361, for discriminator pretraining 
epoch 6, samples 63232, loss 1.227436, accuracy 0.769531 BatchTime 1.691620, for discriminator pretraining 
epoch 6, samples 63488, loss 1.093136, accuracy 0.765625 BatchTime 1.684602, for discriminator pretraining 
epoch 6, samples 63744, loss 1.334827, accuracy 0.742188 BatchTime 1.718765, for discriminator pretraining 
epoch 6, samples 64000, loss 1.013038, accuracy 0.789062 BatchTime 1.642831, for discriminator pretraining 
epoch 6, samples 64256, loss 1.062500, accuracy 0.773438 BatchTime 1.652946, for discriminator pretraining 
epoch 6, samples 64512, loss 0.922882, accuracy 0.833333 BatchTime 6.688548, for discriminator pretraining 
Seen  8984  examples for discriminator. Time Cost :  65.89373731613159
load vocab successfully!!
Epoch : 7
epoch 7, samples 64768, loss 0.595226, accuracy 0.843750 BatchTime 2.724052, for discriminator pretraining 
epoch 7, samples 65024, loss 0.665665, accuracy 0.828125 BatchTime 1.695028, for discriminator pretraining 
epoch 7, samples 65280, loss 0.911349, accuracy 0.789062 BatchTime 1.626127, for discriminator pretraining 
epoch 7, samples 65536, loss 0.880783, accuracy 0.785156 BatchTime 1.625759, for discriminator pretraining 
epoch 7, samples 65792, loss 0.732851, accuracy 0.824219 BatchTime 1.651234, for discriminator pretraining 
epoch 7, samples 66048, loss 0.862180, accuracy 0.808594 BatchTime 1.657506, for discriminator pretraining 
epoch 7, samples 66304, loss 1.348402, accuracy 0.734375 BatchTime 1.626651, for discriminator pretraining 
epoch 7, samples 66560, loss 1.278940, accuracy 0.761719 BatchTime 1.628973, for discriminator pretraining 
epoch 7, samples 66816, loss 1.001850, accuracy 0.792969 BatchTime 1.707649, for discriminator pretraining 
epoch 7, samples 67072, loss 0.871739, accuracy 0.828125 BatchTime 1.749197, for discriminator pretraining 
epoch 7, samples 67328, loss 1.073935, accuracy 0.769531 BatchTime 1.738747, for discriminator pretraining 
epoch 7, samples 67584, loss 1.112398, accuracy 0.765625 BatchTime 1.605427, for discriminator pretraining 
epoch 7, samples 67840, loss 1.200990, accuracy 0.761719 BatchTime 1.635095, for discriminator pretraining 
epoch 7, samples 68096, loss 1.008614, accuracy 0.812500 BatchTime 1.570055, for discriminator pretraining 
epoch 7, samples 68352, loss 1.037713, accuracy 0.765625 BatchTime 1.645218, for discriminator pretraining 
epoch 7, samples 68608, loss 1.086054, accuracy 0.777344 BatchTime 1.604120, for discriminator pretraining 
epoch 7, samples 68864, loss 1.223065, accuracy 0.765625 BatchTime 1.707801, for discriminator pretraining 
epoch 7, samples 69120, loss 1.474478, accuracy 0.761719 BatchTime 1.731841, for discriminator pretraining 
epoch 7, samples 69376, loss 0.989387, accuracy 0.781250 BatchTime 1.706441, for discriminator pretraining 
epoch 7, samples 69632, loss 1.288610, accuracy 0.753906 BatchTime 1.619332, for discriminator pretraining 
epoch 7, samples 69888, loss 1.115838, accuracy 0.769531 BatchTime 1.618587, for discriminator pretraining 
epoch 7, samples 70144, loss 0.844700, accuracy 0.808594 BatchTime 1.636298, for discriminator pretraining 
epoch 7, samples 70400, loss 1.055017, accuracy 0.765625 BatchTime 1.622091, for discriminator pretraining 
epoch 7, samples 70656, loss 1.172490, accuracy 0.765625 BatchTime 1.615701, for discriminator pretraining 
epoch 7, samples 70912, loss 1.022156, accuracy 0.785156 BatchTime 1.595275, for discriminator pretraining 
epoch 7, samples 71168, loss 0.881097, accuracy 0.800781 BatchTime 1.603908, for discriminator pretraining 
epoch 7, samples 71424, loss 0.853652, accuracy 0.781250 BatchTime 1.758358, for discriminator pretraining 
epoch 7, samples 71680, loss 0.984461, accuracy 0.757812 BatchTime 1.747200, for discriminator pretraining 
epoch 7, samples 71936, loss 1.713919, accuracy 0.738281 BatchTime 1.659839, for discriminator pretraining 
epoch 7, samples 72192, loss 1.798214, accuracy 0.718750 BatchTime 1.620743, for discriminator pretraining 
epoch 7, samples 72448, loss 0.818643, accuracy 0.792969 BatchTime 1.644268, for discriminator pretraining 
epoch 7, samples 72704, loss 0.949208, accuracy 0.800781 BatchTime 1.623805, for discriminator pretraining 
epoch 7, samples 72960, loss 0.900919, accuracy 0.808594 BatchTime 1.661546, for discriminator pretraining 
epoch 7, samples 73216, loss 1.168585, accuracy 0.757812 BatchTime 1.619762, for discriminator pretraining 
epoch 7, samples 73472, loss 1.205554, accuracy 0.730469 BatchTime 1.619658, for discriminator pretraining 
epoch 7, samples 73728, loss 1.368677, accuracy 0.730769 BatchTime 7.172137, for discriminator pretraining 
Seen  8986  examples for discriminator. Time Cost :  65.28240633010864
load vocab successfully!!
Epoch : 8
epoch 8, samples 73984, loss 0.641097, accuracy 0.832031 BatchTime 2.712261, for discriminator pretraining 
epoch 8, samples 74240, loss 0.836548, accuracy 0.812500 BatchTime 1.796519, for discriminator pretraining 
epoch 8, samples 74496, loss 1.125500, accuracy 0.746094 BatchTime 1.683334, for discriminator pretraining 
epoch 8, samples 74752, loss 1.082781, accuracy 0.746094 BatchTime 1.662916, for discriminator pretraining 
epoch 8, samples 75008, loss 1.401795, accuracy 0.761719 BatchTime 1.734284, for discriminator pretraining 
epoch 8, samples 75264, loss 1.074430, accuracy 0.765625 BatchTime 1.691677, for discriminator pretraining 
epoch 8, samples 75520, loss 0.979673, accuracy 0.789062 BatchTime 1.683610, for discriminator pretraining 
epoch 8, samples 75776, loss 0.837612, accuracy 0.828125 BatchTime 1.648140, for discriminator pretraining 
epoch 8, samples 76032, loss 0.705610, accuracy 0.812500 BatchTime 1.623369, for discriminator pretraining 
epoch 8, samples 76288, loss 0.804382, accuracy 0.812500 BatchTime 1.617651, for discriminator pretraining 
epoch 8, samples 76544, loss 0.668340, accuracy 0.820312 BatchTime 1.622293, for discriminator pretraining 
epoch 8, samples 76800, loss 0.759245, accuracy 0.843750 BatchTime 1.575442, for discriminator pretraining 
save params when epoch 8, samples 76800
epoch 8, samples 77056, loss 0.968099, accuracy 0.769531 BatchTime 1.675568, for discriminator pretraining 
epoch 8, samples 77312, loss 1.162173, accuracy 0.718750 BatchTime 1.720071, for discriminator pretraining 
epoch 8, samples 77568, loss 1.006875, accuracy 0.792969 BatchTime 1.756391, for discriminator pretraining 
epoch 8, samples 77824, loss 0.944777, accuracy 0.820312 BatchTime 1.633186, for discriminator pretraining 
epoch 8, samples 78080, loss 0.984483, accuracy 0.812500 BatchTime 1.644676, for discriminator pretraining 
epoch 8, samples 78336, loss 0.860536, accuracy 0.777344 BatchTime 1.656280, for discriminator pretraining 
epoch 8, samples 78592, loss 1.078535, accuracy 0.769531 BatchTime 1.726524, for discriminator pretraining 
epoch 8, samples 78848, loss 0.900053, accuracy 0.792969 BatchTime 1.773151, for discriminator pretraining 
epoch 8, samples 79104, loss 1.014219, accuracy 0.792969 BatchTime 1.705445, for discriminator pretraining 
epoch 8, samples 79360, loss 0.856504, accuracy 0.777344 BatchTime 1.676152, for discriminator pretraining 
epoch 8, samples 79616, loss 1.152472, accuracy 0.765625 BatchTime 1.635588, for discriminator pretraining 
epoch 8, samples 79872, loss 1.099372, accuracy 0.781250 BatchTime 1.732168, for discriminator pretraining 
epoch 8, samples 80128, loss 0.868424, accuracy 0.832031 BatchTime 1.640085, for discriminator pretraining 
epoch 8, samples 80384, loss 1.267561, accuracy 0.753906 BatchTime 1.767297, for discriminator pretraining 
epoch 8, samples 80640, loss 1.106771, accuracy 0.753906 BatchTime 1.698627, for discriminator pretraining 
epoch 8, samples 80896, loss 1.082254, accuracy 0.789062 BatchTime 1.676680, for discriminator pretraining 
epoch 8, samples 81152, loss 0.906353, accuracy 0.800781 BatchTime 1.649212, for discriminator pretraining 
epoch 8, samples 81408, loss 1.163038, accuracy 0.773438 BatchTime 1.680984, for discriminator pretraining 
epoch 8, samples 81664, loss 0.994459, accuracy 0.777344 BatchTime 1.675509, for discriminator pretraining 
epoch 8, samples 81920, loss 0.846227, accuracy 0.816406 BatchTime 1.763166, for discriminator pretraining 
epoch 8, samples 82176, loss 0.990681, accuracy 0.808594 BatchTime 1.739268, for discriminator pretraining 
epoch 8, samples 82432, loss 1.102971, accuracy 0.800781 BatchTime 1.688794, for discriminator pretraining 
epoch 8, samples 82688, loss 1.108499, accuracy 0.765625 BatchTime 1.666489, for discriminator pretraining 
epoch 8, samples 82944, loss 2.240306, accuracy 0.700000 BatchTime 6.840647, for discriminator pretraining 
Seen  8990  examples for discriminator. Time Cost :  72.59819078445435
load vocab successfully!!
Epoch : 9
epoch 9, samples 83200, loss 0.625945, accuracy 0.835938 BatchTime 2.575553, for discriminator pretraining 
epoch 9, samples 83456, loss 0.709501, accuracy 0.820312 BatchTime 1.784446, for discriminator pretraining 
epoch 9, samples 83712, loss 0.448497, accuracy 0.871094 BatchTime 1.743696, for discriminator pretraining 
epoch 9, samples 83968, loss 0.602778, accuracy 0.839844 BatchTime 1.798766, for discriminator pretraining 
epoch 9, samples 84224, loss 0.678522, accuracy 0.816406 BatchTime 1.682701, for discriminator pretraining 
epoch 9, samples 84480, loss 0.690737, accuracy 0.800781 BatchTime 1.589303, for discriminator pretraining 
epoch 9, samples 84736, loss 1.187058, accuracy 0.808594 BatchTime 1.616207, for discriminator pretraining 
epoch 9, samples 84992, loss 0.802523, accuracy 0.792969 BatchTime 1.664563, for discriminator pretraining 
epoch 9, samples 85248, loss 1.349013, accuracy 0.753906 BatchTime 1.663746, for discriminator pretraining 
epoch 9, samples 85504, loss 1.858354, accuracy 0.710938 BatchTime 1.704393, for discriminator pretraining 
epoch 9, samples 85760, loss 1.046298, accuracy 0.816406 BatchTime 1.631817, for discriminator pretraining 
epoch 9, samples 86016, loss 0.873742, accuracy 0.824219 BatchTime 1.596608, for discriminator pretraining 
epoch 9, samples 86272, loss 0.916442, accuracy 0.835938 BatchTime 1.655321, for discriminator pretraining 
epoch 9, samples 86528, loss 0.812028, accuracy 0.820312 BatchTime 1.662174, for discriminator pretraining 
epoch 9, samples 86784, loss 1.080620, accuracy 0.789062 BatchTime 1.783433, for discriminator pretraining 
epoch 9, samples 87040, loss 0.944114, accuracy 0.781250 BatchTime 1.732514, for discriminator pretraining 
epoch 9, samples 87296, loss 0.767349, accuracy 0.816406 BatchTime 1.675515, for discriminator pretraining 
epoch 9, samples 87552, loss 1.048345, accuracy 0.769531 BatchTime 1.661159, for discriminator pretraining 
epoch 9, samples 87808, loss 1.111432, accuracy 0.828125 BatchTime 1.665244, for discriminator pretraining 
epoch 9, samples 88064, loss 0.753340, accuracy 0.824219 BatchTime 1.762286, for discriminator pretraining 
epoch 9, samples 88320, loss 1.252594, accuracy 0.769531 BatchTime 1.717442, for discriminator pretraining 
epoch 9, samples 88576, loss 1.131607, accuracy 0.753906 BatchTime 1.648201, for discriminator pretraining 
epoch 9, samples 88832, loss 1.226888, accuracy 0.789062 BatchTime 1.631580, for discriminator pretraining 
epoch 9, samples 89088, loss 1.037288, accuracy 0.769531 BatchTime 1.662115, for discriminator pretraining 
epoch 9, samples 89344, loss 0.918712, accuracy 0.804688 BatchTime 1.658483, for discriminator pretraining 
epoch 9, samples 89600, loss 1.200165, accuracy 0.777344 BatchTime 1.662718, for discriminator pretraining 
epoch 9, samples 89856, loss 0.996769, accuracy 0.765625 BatchTime 1.640290, for discriminator pretraining 
epoch 9, samples 90112, loss 1.186339, accuracy 0.769531 BatchTime 1.739078, for discriminator pretraining 
epoch 9, samples 90368, loss 1.239551, accuracy 0.757812 BatchTime 1.791920, for discriminator pretraining 
epoch 9, samples 90624, loss 1.094143, accuracy 0.777344 BatchTime 1.690551, for discriminator pretraining 
epoch 9, samples 90880, loss 0.835356, accuracy 0.832031 BatchTime 1.692391, for discriminator pretraining 
epoch 9, samples 91136, loss 0.750312, accuracy 0.824219 BatchTime 1.677660, for discriminator pretraining 
epoch 9, samples 91392, loss 0.792829, accuracy 0.828125 BatchTime 1.749778, for discriminator pretraining 
epoch 9, samples 91648, loss 0.867235, accuracy 0.804688 BatchTime 1.807121, for discriminator pretraining 
epoch 9, samples 91904, loss 0.925848, accuracy 0.808594 BatchTime 1.656887, for discriminator pretraining 
epoch 9, samples 92160, loss 0.747144, accuracy 0.769231 BatchTime 0.875081, for discriminator pretraining 
Seen  8986  examples for discriminator. Time Cost :  60.220571756362915
load vocab successfully!!
Epoch : 10
epoch 10, samples 92416, loss 0.760988, accuracy 0.820312 BatchTime 2.716399, for discriminator pretraining 
epoch 10, samples 92672, loss 0.970648, accuracy 0.800781 BatchTime 1.889982, for discriminator pretraining 
epoch 10, samples 92928, loss 0.769438, accuracy 0.800781 BatchTime 1.697414, for discriminator pretraining 
epoch 10, samples 93184, loss 0.898735, accuracy 0.808594 BatchTime 1.658194, for discriminator pretraining 
epoch 10, samples 93440, loss 1.178826, accuracy 0.750000 BatchTime 1.657912, for discriminator pretraining 
epoch 10, samples 93696, loss 0.809582, accuracy 0.820312 BatchTime 1.642534, for discriminator pretraining 
epoch 10, samples 93952, loss 0.557173, accuracy 0.847656 BatchTime 1.696287, for discriminator pretraining 
epoch 10, samples 94208, loss 0.721318, accuracy 0.816406 BatchTime 1.691334, for discriminator pretraining 
epoch 10, samples 94464, loss 0.516445, accuracy 0.816406 BatchTime 1.654136, for discriminator pretraining 
epoch 10, samples 94720, loss 0.908735, accuracy 0.789062 BatchTime 1.690429, for discriminator pretraining 
epoch 10, samples 94976, loss 1.057209, accuracy 0.781250 BatchTime 1.752105, for discriminator pretraining 
epoch 10, samples 95232, loss 0.541815, accuracy 0.851562 BatchTime 1.738313, for discriminator pretraining 
epoch 10, samples 95488, loss 0.569886, accuracy 0.808594 BatchTime 1.654163, for discriminator pretraining 
epoch 10, samples 95744, loss 1.178547, accuracy 0.773438 BatchTime 1.665906, for discriminator pretraining 
epoch 10, samples 96000, loss 1.426043, accuracy 0.757812 BatchTime 1.672001, for discriminator pretraining 
epoch 10, samples 96256, loss 0.785755, accuracy 0.800781 BatchTime 1.651315, for discriminator pretraining 
epoch 10, samples 96512, loss 0.576110, accuracy 0.859375 BatchTime 1.612124, for discriminator pretraining 
epoch 10, samples 96768, loss 0.699487, accuracy 0.816406 BatchTime 1.634963, for discriminator pretraining 
epoch 10, samples 97024, loss 0.847593, accuracy 0.808594 BatchTime 1.734075, for discriminator pretraining 
epoch 10, samples 97280, loss 0.707896, accuracy 0.824219 BatchTime 1.743458, for discriminator pretraining 
epoch 10, samples 97536, loss 0.752988, accuracy 0.828125 BatchTime 1.684951, for discriminator pretraining 
epoch 10, samples 97792, loss 0.949140, accuracy 0.785156 BatchTime 1.695349, for discriminator pretraining 
epoch 10, samples 98048, loss 0.772009, accuracy 0.824219 BatchTime 1.675915, for discriminator pretraining 
epoch 10, samples 98304, loss 0.815422, accuracy 0.816406 BatchTime 1.601724, for discriminator pretraining 
epoch 10, samples 98560, loss 1.068427, accuracy 0.785156 BatchTime 1.629892, for discriminator pretraining 
epoch 10, samples 98816, loss 0.866019, accuracy 0.781250 BatchTime 1.659131, for discriminator pretraining 
epoch 10, samples 99072, loss 1.029383, accuracy 0.773438 BatchTime 1.712072, for discriminator pretraining 
epoch 10, samples 99328, loss 1.121591, accuracy 0.757812 BatchTime 1.760471, for discriminator pretraining 
epoch 10, samples 99584, loss 1.307064, accuracy 0.769531 BatchTime 1.706651, for discriminator pretraining 
epoch 10, samples 99840, loss 1.222974, accuracy 0.761719 BatchTime 1.675435, for discriminator pretraining 
epoch 10, samples 100096, loss 1.286663, accuracy 0.773438 BatchTime 1.687615, for discriminator pretraining 
epoch 10, samples 100352, loss 0.849999, accuracy 0.820312 BatchTime 1.659575, for discriminator pretraining 
epoch 10, samples 100608, loss 0.801930, accuracy 0.812500 BatchTime 1.717572, for discriminator pretraining 
epoch 10, samples 100864, loss 0.810121, accuracy 0.796875 BatchTime 1.780048, for discriminator pretraining 
epoch 10, samples 101120, loss 0.835677, accuracy 0.796875 BatchTime 1.734585, for discriminator pretraining 
epoch 10, samples 101376, loss 0.989032, accuracy 0.722222 BatchTime 6.850560, for discriminator pretraining 
Seen  8996  examples for discriminator. Time Cost :  66.27973532676697
load vocab successfully!!
Epoch : 11
epoch 11, samples 101632, loss 0.440724, accuracy 0.871094 BatchTime 2.809400, for discriminator pretraining 
epoch 11, samples 101888, loss 0.592965, accuracy 0.875000 BatchTime 1.849169, for discriminator pretraining 
epoch 11, samples 102144, loss 0.530257, accuracy 0.867188 BatchTime 1.691612, for discriminator pretraining 
epoch 11, samples 102400, loss 0.757021, accuracy 0.824219 BatchTime 1.653779, for discriminator pretraining 
save params when epoch 11, samples 102400
epoch 11, samples 102656, loss 1.236770, accuracy 0.757812 BatchTime 1.695131, for discriminator pretraining 
epoch 11, samples 102912, loss 0.998888, accuracy 0.789062 BatchTime 1.687187, for discriminator pretraining 
epoch 11, samples 103168, loss 0.553946, accuracy 0.875000 BatchTime 1.800730, for discriminator pretraining 
epoch 11, samples 103424, loss 0.696948, accuracy 0.843750 BatchTime 1.783079, for discriminator pretraining 
epoch 11, samples 103680, loss 1.076630, accuracy 0.750000 BatchTime 1.694727, for discriminator pretraining 
epoch 11, samples 103936, loss 1.025338, accuracy 0.792969 BatchTime 1.680962, for discriminator pretraining 
epoch 11, samples 104192, loss 1.337569, accuracy 0.769531 BatchTime 1.684586, for discriminator pretraining 
epoch 11, samples 104448, loss 1.187325, accuracy 0.785156 BatchTime 1.649319, for discriminator pretraining 
epoch 11, samples 104704, loss 0.712829, accuracy 0.812500 BatchTime 1.730129, for discriminator pretraining 
epoch 11, samples 104960, loss 0.854641, accuracy 0.839844 BatchTime 1.734000, for discriminator pretraining 
epoch 11, samples 105216, loss 0.688698, accuracy 0.824219 BatchTime 1.702673, for discriminator pretraining 
epoch 11, samples 105472, loss 0.833358, accuracy 0.832031 BatchTime 1.638361, for discriminator pretraining 
epoch 11, samples 105728, loss 1.085180, accuracy 0.804688 BatchTime 1.668851, for discriminator pretraining 
epoch 11, samples 105984, loss 1.084822, accuracy 0.792969 BatchTime 1.681104, for discriminator pretraining 
epoch 11, samples 106240, loss 0.937788, accuracy 0.800781 BatchTime 1.788334, for discriminator pretraining 
epoch 11, samples 106496, loss 0.954189, accuracy 0.781250 BatchTime 1.765497, for discriminator pretraining 
epoch 11, samples 106752, loss 0.647144, accuracy 0.816406 BatchTime 1.717367, for discriminator pretraining 
epoch 11, samples 107008, loss 0.834306, accuracy 0.812500 BatchTime 1.664531, for discriminator pretraining 
epoch 11, samples 107264, loss 0.827026, accuracy 0.804688 BatchTime 1.689761, for discriminator pretraining 
epoch 11, samples 107520, loss 0.652093, accuracy 0.812500 BatchTime 1.724888, for discriminator pretraining 
epoch 11, samples 107776, loss 0.793179, accuracy 0.828125 BatchTime 1.800806, for discriminator pretraining 
epoch 11, samples 108032, loss 1.025216, accuracy 0.808594 BatchTime 1.754548, for discriminator pretraining 
epoch 11, samples 108288, loss 0.922908, accuracy 0.812500 BatchTime 1.698163, for discriminator pretraining 
epoch 11, samples 108544, loss 1.192629, accuracy 0.761719 BatchTime 1.718609, for discriminator pretraining 
epoch 11, samples 108800, loss 0.854362, accuracy 0.804688 BatchTime 1.793767, for discriminator pretraining 
epoch 11, samples 109056, loss 0.719860, accuracy 0.832031 BatchTime 1.640722, for discriminator pretraining 
epoch 11, samples 109312, loss 0.688712, accuracy 0.800781 BatchTime 1.667188, for discriminator pretraining 
epoch 11, samples 109568, loss 0.700281, accuracy 0.800781 BatchTime 1.648331, for discriminator pretraining 
epoch 11, samples 109824, loss 0.748043, accuracy 0.804688 BatchTime 1.665899, for discriminator pretraining 
epoch 11, samples 110080, loss 0.881043, accuracy 0.800781 BatchTime 1.732682, for discriminator pretraining 
epoch 11, samples 110336, loss 0.886784, accuracy 0.812500 BatchTime 1.786326, for discriminator pretraining 
epoch 11, samples 110592, loss 1.037145, accuracy 0.766667 BatchTime 0.909077, for discriminator pretraining 
Seen  8990  examples for discriminator. Time Cost :  66.89040637016296
load vocab successfully!!
Epoch : 12
epoch 12, samples 110848, loss 0.650458, accuracy 0.851562 BatchTime 2.747726, for discriminator pretraining 
epoch 12, samples 111104, loss 0.794178, accuracy 0.812500 BatchTime 1.781618, for discriminator pretraining 
epoch 12, samples 111360, loss 0.944834, accuracy 0.785156 BatchTime 1.695089, for discriminator pretraining 
epoch 12, samples 111616, loss 1.096475, accuracy 0.769531 BatchTime 1.682864, for discriminator pretraining 
epoch 12, samples 111872, loss 1.005998, accuracy 0.804688 BatchTime 1.694754, for discriminator pretraining 
epoch 12, samples 112128, loss 0.850024, accuracy 0.812500 BatchTime 1.689263, for discriminator pretraining 
epoch 12, samples 112384, loss 0.978254, accuracy 0.812500 BatchTime 1.688518, for discriminator pretraining 
epoch 12, samples 112640, loss 1.113917, accuracy 0.792969 BatchTime 1.640460, for discriminator pretraining 
epoch 12, samples 112896, loss 0.727751, accuracy 0.820312 BatchTime 1.735171, for discriminator pretraining 
epoch 12, samples 113152, loss 0.476026, accuracy 0.839844 BatchTime 1.738340, for discriminator pretraining 
epoch 12, samples 113408, loss 1.271638, accuracy 0.761719 BatchTime 1.669358, for discriminator pretraining 
epoch 12, samples 113664, loss 1.017119, accuracy 0.800781 BatchTime 1.634664, for discriminator pretraining 
epoch 12, samples 113920, loss 0.719086, accuracy 0.816406 BatchTime 1.626711, for discriminator pretraining 
epoch 12, samples 114176, loss 0.591573, accuracy 0.828125 BatchTime 1.685023, for discriminator pretraining 
epoch 12, samples 114432, loss 0.604865, accuracy 0.847656 BatchTime 1.728256, for discriminator pretraining 
epoch 12, samples 114688, loss 0.757771, accuracy 0.808594 BatchTime 1.674101, for discriminator pretraining 
epoch 12, samples 114944, loss 1.055864, accuracy 0.792969 BatchTime 1.655617, for discriminator pretraining 
epoch 12, samples 115200, loss 0.885468, accuracy 0.812500 BatchTime 1.592126, for discriminator pretraining 
epoch 12, samples 115456, loss 0.938100, accuracy 0.812500 BatchTime 1.633677, for discriminator pretraining 
epoch 12, samples 115712, loss 0.886422, accuracy 0.808594 BatchTime 1.755530, for discriminator pretraining 
epoch 12, samples 115968, loss 1.048738, accuracy 0.777344 BatchTime 1.675074, for discriminator pretraining 
epoch 12, samples 116224, loss 0.915084, accuracy 0.785156 BatchTime 1.633997, for discriminator pretraining 
epoch 12, samples 116480, loss 1.108675, accuracy 0.796875 BatchTime 1.641584, for discriminator pretraining 
epoch 12, samples 116736, loss 0.765957, accuracy 0.816406 BatchTime 1.629692, for discriminator pretraining 
epoch 12, samples 116992, loss 0.667843, accuracy 0.808594 BatchTime 1.920464, for discriminator pretraining 
epoch 12, samples 117248, loss 0.674044, accuracy 0.812500 BatchTime 1.754961, for discriminator pretraining 
epoch 12, samples 117504, loss 0.981030, accuracy 0.792969 BatchTime 1.716035, for discriminator pretraining 
epoch 12, samples 117760, loss 0.925363, accuracy 0.812500 BatchTime 1.621722, for discriminator pretraining 
epoch 12, samples 118016, loss 0.652160, accuracy 0.847656 BatchTime 1.627949, for discriminator pretraining 
epoch 12, samples 118272, loss 0.825698, accuracy 0.785156 BatchTime 1.646335, for discriminator pretraining 
epoch 12, samples 118528, loss 0.752792, accuracy 0.820312 BatchTime 1.683302, for discriminator pretraining 
epoch 12, samples 118784, loss 0.878795, accuracy 0.808594 BatchTime 1.677490, for discriminator pretraining 
epoch 12, samples 119040, loss 0.908465, accuracy 0.777344 BatchTime 1.669996, for discriminator pretraining 
epoch 12, samples 119296, loss 1.054726, accuracy 0.753906 BatchTime 1.675956, for discriminator pretraining 
epoch 12, samples 119552, loss 0.966287, accuracy 0.808594 BatchTime 1.618438, for discriminator pretraining 
epoch 12, samples 119808, loss 0.810457, accuracy 0.782609 BatchTime 6.910715, for discriminator pretraining 
Seen  9006  examples for discriminator. Time Cost :  65.96318626403809
load vocab successfully!!
Epoch : 13
epoch 13, samples 120064, loss 0.597619, accuracy 0.835938 BatchTime 2.817359, for discriminator pretraining 
epoch 13, samples 120320, loss 0.992616, accuracy 0.769531 BatchTime 1.873888, for discriminator pretraining 
epoch 13, samples 120576, loss 1.230503, accuracy 0.773438 BatchTime 1.673716, for discriminator pretraining 
epoch 13, samples 120832, loss 0.560168, accuracy 0.882812 BatchTime 1.749702, for discriminator pretraining 
epoch 13, samples 121088, loss 0.688612, accuracy 0.820312 BatchTime 1.777446, for discriminator pretraining 
epoch 13, samples 121344, loss 0.718874, accuracy 0.832031 BatchTime 1.649519, for discriminator pretraining 
epoch 13, samples 121600, loss 0.717632, accuracy 0.847656 BatchTime 1.640549, for discriminator pretraining 
epoch 13, samples 121856, loss 0.532581, accuracy 0.875000 BatchTime 1.590022, for discriminator pretraining 
epoch 13, samples 122112, loss 0.651410, accuracy 0.851562 BatchTime 1.610992, for discriminator pretraining 
epoch 13, samples 122368, loss 0.629258, accuracy 0.835938 BatchTime 1.600815, for discriminator pretraining 
epoch 13, samples 122624, loss 0.839303, accuracy 0.804688 BatchTime 1.747605, for discriminator pretraining 
epoch 13, samples 122880, loss 0.899287, accuracy 0.792969 BatchTime 1.707796, for discriminator pretraining 
epoch 13, samples 123136, loss 0.770746, accuracy 0.835938 BatchTime 1.593109, for discriminator pretraining 
epoch 13, samples 123392, loss 0.637251, accuracy 0.855469 BatchTime 1.576686, for discriminator pretraining 
epoch 13, samples 123648, loss 0.669312, accuracy 0.843750 BatchTime 1.606764, for discriminator pretraining 
epoch 13, samples 123904, loss 0.949223, accuracy 0.777344 BatchTime 1.609432, for discriminator pretraining 
epoch 13, samples 124160, loss 1.108771, accuracy 0.789062 BatchTime 1.762634, for discriminator pretraining 
epoch 13, samples 124416, loss 0.658175, accuracy 0.835938 BatchTime 1.671631, for discriminator pretraining 
epoch 13, samples 124672, loss 0.726212, accuracy 0.824219 BatchTime 1.624451, for discriminator pretraining 
epoch 13, samples 124928, loss 0.757841, accuracy 0.812500 BatchTime 1.594920, for discriminator pretraining 
epoch 13, samples 125184, loss 0.860180, accuracy 0.804688 BatchTime 1.652088, for discriminator pretraining 
epoch 13, samples 125440, loss 0.844908, accuracy 0.800781 BatchTime 1.591869, for discriminator pretraining 
epoch 13, samples 125696, loss 0.838680, accuracy 0.812500 BatchTime 1.664190, for discriminator pretraining 
epoch 13, samples 125952, loss 0.952147, accuracy 0.796875 BatchTime 1.667724, for discriminator pretraining 
epoch 13, samples 126208, loss 1.129769, accuracy 0.789062 BatchTime 1.670271, for discriminator pretraining 
epoch 13, samples 126464, loss 0.871437, accuracy 0.816406 BatchTime 1.655739, for discriminator pretraining 
epoch 13, samples 126720, loss 0.727216, accuracy 0.820312 BatchTime 1.658173, for discriminator pretraining 
epoch 13, samples 126976, loss 0.880411, accuracy 0.796875 BatchTime 1.627476, for discriminator pretraining 
epoch 13, samples 127232, loss 0.780508, accuracy 0.796875 BatchTime 1.638818, for discriminator pretraining 
epoch 13, samples 127488, loss 0.893278, accuracy 0.808594 BatchTime 1.635741, for discriminator pretraining 
epoch 13, samples 127744, loss 0.760041, accuracy 0.820312 BatchTime 1.661219, for discriminator pretraining 
epoch 13, samples 128000, loss 0.702352, accuracy 0.835938 BatchTime 1.738780, for discriminator pretraining 
save params when epoch 13, samples 128000
epoch 13, samples 128256, loss 0.803313, accuracy 0.835938 BatchTime 1.788817, for discriminator pretraining 
epoch 13, samples 128512, loss 0.712456, accuracy 0.851562 BatchTime 1.789658, for discriminator pretraining 
epoch 13, samples 128768, loss 0.571126, accuracy 0.839844 BatchTime 1.663819, for discriminator pretraining 
epoch 13, samples 129024, loss 0.916152, accuracy 0.800000 BatchTime 0.840415, for discriminator pretraining 
Seen  8990  examples for discriminator. Time Cost :  66.29046440124512
load vocab successfully!!
Epoch : 14
epoch 14, samples 129280, loss 0.565929, accuracy 0.847656 BatchTime 2.643544, for discriminator pretraining 
epoch 14, samples 129536, loss 0.462650, accuracy 0.867188 BatchTime 1.775049, for discriminator pretraining 
epoch 14, samples 129792, loss 0.700680, accuracy 0.816406 BatchTime 1.697989, for discriminator pretraining 
epoch 14, samples 130048, loss 1.337098, accuracy 0.722656 BatchTime 1.663961, for discriminator pretraining 
epoch 14, samples 130304, loss 1.492262, accuracy 0.718750 BatchTime 1.769485, for discriminator pretraining 
epoch 14, samples 130560, loss 0.942678, accuracy 0.792969 BatchTime 1.739122, for discriminator pretraining 
epoch 14, samples 130816, loss 0.700769, accuracy 0.808594 BatchTime 1.700418, for discriminator pretraining 
epoch 14, samples 131072, loss 1.057794, accuracy 0.785156 BatchTime 1.765197, for discriminator pretraining 
epoch 14, samples 131328, loss 1.035663, accuracy 0.769531 BatchTime 1.726358, for discriminator pretraining 
epoch 14, samples 131584, loss 0.877393, accuracy 0.839844 BatchTime 1.651859, for discriminator pretraining 
epoch 14, samples 131840, loss 0.724655, accuracy 0.832031 BatchTime 1.651664, for discriminator pretraining 
epoch 14, samples 132096, loss 0.548334, accuracy 0.871094 BatchTime 1.587997, for discriminator pretraining 
epoch 14, samples 132352, loss 0.573867, accuracy 0.832031 BatchTime 1.711386, for discriminator pretraining 
epoch 14, samples 132608, loss 0.601659, accuracy 0.851562 BatchTime 1.747526, for discriminator pretraining 
epoch 14, samples 132864, loss 0.770256, accuracy 0.835938 BatchTime 1.685919, for discriminator pretraining 
epoch 14, samples 133120, loss 0.707670, accuracy 0.835938 BatchTime 1.580157, for discriminator pretraining 
epoch 14, samples 133376, loss 0.825919, accuracy 0.812500 BatchTime 1.594708, for discriminator pretraining 
epoch 14, samples 133632, loss 0.804172, accuracy 0.804688 BatchTime 1.628862, for discriminator pretraining 
epoch 14, samples 133888, loss 0.587868, accuracy 0.835938 BatchTime 1.645813, for discriminator pretraining 
epoch 14, samples 134144, loss 0.848026, accuracy 0.839844 BatchTime 1.726125, for discriminator pretraining 
epoch 14, samples 134400, loss 1.216478, accuracy 0.781250 BatchTime 1.726332, for discriminator pretraining 
epoch 14, samples 134656, loss 0.938085, accuracy 0.804688 BatchTime 1.658159, for discriminator pretraining 
epoch 14, samples 134912, loss 0.784855, accuracy 0.835938 BatchTime 1.657618, for discriminator pretraining 
epoch 14, samples 135168, loss 1.008278, accuracy 0.824219 BatchTime 1.670537, for discriminator pretraining 
epoch 14, samples 135424, loss 0.751018, accuracy 0.839844 BatchTime 1.672146, for discriminator pretraining 
epoch 14, samples 135680, loss 0.963644, accuracy 0.820312 BatchTime 1.627932, for discriminator pretraining 
epoch 14, samples 135936, loss 0.781888, accuracy 0.820312 BatchTime 1.669949, for discriminator pretraining 
epoch 14, samples 136192, loss 0.684721, accuracy 0.847656 BatchTime 1.676093, for discriminator pretraining 
epoch 14, samples 136448, loss 0.778301, accuracy 0.824219 BatchTime 1.634432, for discriminator pretraining 
epoch 14, samples 136704, loss 0.722866, accuracy 0.835938 BatchTime 1.624585, for discriminator pretraining 
epoch 14, samples 136960, loss 0.852336, accuracy 0.832031 BatchTime 1.652001, for discriminator pretraining 
epoch 14, samples 137216, loss 0.763969, accuracy 0.824219 BatchTime 1.787980, for discriminator pretraining 
epoch 14, samples 137472, loss 0.741587, accuracy 0.832031 BatchTime 1.797349, for discriminator pretraining 
epoch 14, samples 137728, loss 0.780865, accuracy 0.843750 BatchTime 1.684371, for discriminator pretraining 
epoch 14, samples 137984, loss 0.858803, accuracy 0.781250 BatchTime 1.658974, for discriminator pretraining 
epoch 14, samples 138240, loss 1.938413, accuracy 0.611111 BatchTime 6.495584, for discriminator pretraining 
Seen  8978  examples for discriminator. Time Cost :  65.5400230884552
load vocab successfully!!
Epoch : 15
epoch 15, samples 138496, loss 0.690684, accuracy 0.824219 BatchTime 2.569281, for discriminator pretraining 
epoch 15, samples 138752, loss 0.651075, accuracy 0.851562 BatchTime 1.765069, for discriminator pretraining 
epoch 15, samples 139008, loss 0.642729, accuracy 0.843750 BatchTime 1.705971, for discriminator pretraining 
epoch 15, samples 139264, loss 0.540226, accuracy 0.851562 BatchTime 1.627295, for discriminator pretraining 
epoch 15, samples 139520, loss 0.485027, accuracy 0.863281 BatchTime 1.782203, for discriminator pretraining 
epoch 15, samples 139776, loss 0.687612, accuracy 0.839844 BatchTime 1.678984, for discriminator pretraining 
epoch 15, samples 140032, loss 0.873889, accuracy 0.792969 BatchTime 1.679358, for discriminator pretraining 
epoch 15, samples 140288, loss 0.866858, accuracy 0.824219 BatchTime 1.719187, for discriminator pretraining 
epoch 15, samples 140544, loss 0.921396, accuracy 0.824219 BatchTime 1.686727, for discriminator pretraining 
epoch 15, samples 140800, loss 0.741808, accuracy 0.804688 BatchTime 1.653824, for discriminator pretraining 
epoch 15, samples 141056, loss 0.665570, accuracy 0.824219 BatchTime 1.674300, for discriminator pretraining 
epoch 15, samples 141312, loss 0.772561, accuracy 0.816406 BatchTime 1.626498, for discriminator pretraining 
epoch 15, samples 141568, loss 0.806497, accuracy 0.816406 BatchTime 1.668565, for discriminator pretraining 
epoch 15, samples 141824, loss 0.584706, accuracy 0.843750 BatchTime 1.657148, for discriminator pretraining 
epoch 15, samples 142080, loss 0.782107, accuracy 0.851562 BatchTime 1.653305, for discriminator pretraining 
epoch 15, samples 142336, loss 0.742704, accuracy 0.828125 BatchTime 1.747490, for discriminator pretraining 
epoch 15, samples 142592, loss 0.921721, accuracy 0.808594 BatchTime 1.806865, for discriminator pretraining 
epoch 15, samples 142848, loss 0.566821, accuracy 0.859375 BatchTime 1.647472, for discriminator pretraining 
epoch 15, samples 143104, loss 0.693980, accuracy 0.835938 BatchTime 1.691440, for discriminator pretraining 
epoch 15, samples 143360, loss 1.006889, accuracy 0.804688 BatchTime 1.716676, for discriminator pretraining 
epoch 15, samples 143616, loss 0.776197, accuracy 0.812500 BatchTime 1.769955, for discriminator pretraining 
epoch 15, samples 143872, loss 0.710790, accuracy 0.855469 BatchTime 1.633086, for discriminator pretraining 
epoch 15, samples 144128, loss 0.496272, accuracy 0.847656 BatchTime 1.637860, for discriminator pretraining 
epoch 15, samples 144384, loss 0.724810, accuracy 0.835938 BatchTime 1.681401, for discriminator pretraining 
epoch 15, samples 144640, loss 0.919259, accuracy 0.808594 BatchTime 1.772969, for discriminator pretraining 
epoch 15, samples 144896, loss 0.995525, accuracy 0.792969 BatchTime 1.707722, for discriminator pretraining 
epoch 15, samples 145152, loss 0.731492, accuracy 0.832031 BatchTime 1.714406, for discriminator pretraining 
epoch 15, samples 145408, loss 0.521459, accuracy 0.871094 BatchTime 1.611953, for discriminator pretraining 
epoch 15, samples 145664, loss 0.758669, accuracy 0.804688 BatchTime 1.637011, for discriminator pretraining 
epoch 15, samples 145920, loss 1.241706, accuracy 0.789062 BatchTime 1.713135, for discriminator pretraining 
epoch 15, samples 146176, loss 1.371223, accuracy 0.757812 BatchTime 1.671097, for discriminator pretraining 
epoch 15, samples 146432, loss 1.119046, accuracy 0.781250 BatchTime 1.619626, for discriminator pretraining 
epoch 15, samples 146688, loss 0.693479, accuracy 0.843750 BatchTime 1.721399, for discriminator pretraining 
epoch 15, samples 146944, loss 0.808089, accuracy 0.832031 BatchTime 1.621682, for discriminator pretraining 
epoch 15, samples 147200, loss 1.031893, accuracy 0.804688 BatchTime 1.761403, for discriminator pretraining 
epoch 15, samples 147456, loss 0.989784, accuracy 0.812500 BatchTime 0.982814, for discriminator pretraining 
Seen  8992  examples for discriminator. Time Cost :  60.33504939079285
load vocab successfully!!
Epoch : 16
epoch 16, samples 147712, loss 0.734524, accuracy 0.835938 BatchTime 2.765962, for discriminator pretraining 
epoch 16, samples 147968, loss 0.414548, accuracy 0.882812 BatchTime 1.780061, for discriminator pretraining 
epoch 16, samples 148224, loss 0.557970, accuracy 0.859375 BatchTime 1.767276, for discriminator pretraining 
epoch 16, samples 148480, loss 0.517504, accuracy 0.863281 BatchTime 1.715199, for discriminator pretraining 
epoch 16, samples 148736, loss 0.555493, accuracy 0.847656 BatchTime 1.752954, for discriminator pretraining 
epoch 16, samples 148992, loss 0.587606, accuracy 0.851562 BatchTime 1.690609, for discriminator pretraining 
epoch 16, samples 149248, loss 0.637488, accuracy 0.882812 BatchTime 1.730721, for discriminator pretraining 
epoch 16, samples 149504, loss 1.135086, accuracy 0.785156 BatchTime 1.626300, for discriminator pretraining 
epoch 16, samples 149760, loss 1.062168, accuracy 0.804688 BatchTime 1.680268, for discriminator pretraining 
epoch 16, samples 150016, loss 0.593755, accuracy 0.820312 BatchTime 1.634506, for discriminator pretraining 
epoch 16, samples 150272, loss 0.840616, accuracy 0.828125 BatchTime 1.736225, for discriminator pretraining 
epoch 16, samples 150528, loss 0.796211, accuracy 0.812500 BatchTime 1.642211, for discriminator pretraining 
epoch 16, samples 150784, loss 0.632713, accuracy 0.847656 BatchTime 1.811586, for discriminator pretraining 
epoch 16, samples 151040, loss 0.701988, accuracy 0.808594 BatchTime 1.705890, for discriminator pretraining 
epoch 16, samples 151296, loss 0.686110, accuracy 0.816406 BatchTime 1.682029, for discriminator pretraining 
epoch 16, samples 151552, loss 0.526524, accuracy 0.882812 BatchTime 1.602748, for discriminator pretraining 
epoch 16, samples 151808, loss 0.604676, accuracy 0.835938 BatchTime 1.666998, for discriminator pretraining 
epoch 16, samples 152064, loss 0.731149, accuracy 0.835938 BatchTime 1.658786, for discriminator pretraining 
epoch 16, samples 152320, loss 0.811824, accuracy 0.839844 BatchTime 1.768060, for discriminator pretraining 
epoch 16, samples 152576, loss 0.667179, accuracy 0.820312 BatchTime 1.773417, for discriminator pretraining 
epoch 16, samples 152832, loss 0.866311, accuracy 0.820312 BatchTime 1.735072, for discriminator pretraining 
epoch 16, samples 153088, loss 0.697867, accuracy 0.828125 BatchTime 1.649797, for discriminator pretraining 
epoch 16, samples 153344, loss 0.661491, accuracy 0.828125 BatchTime 1.668076, for discriminator pretraining 
epoch 16, samples 153600, loss 0.907038, accuracy 0.816406 BatchTime 1.608369, for discriminator pretraining 
save params when epoch 16, samples 153600
epoch 16, samples 153856, loss 0.955772, accuracy 0.785156 BatchTime 1.749650, for discriminator pretraining 
epoch 16, samples 154112, loss 0.866472, accuracy 0.800781 BatchTime 1.715010, for discriminator pretraining 
epoch 16, samples 154368, loss 0.874756, accuracy 0.820312 BatchTime 1.687092, for discriminator pretraining 
epoch 16, samples 154624, loss 0.868844, accuracy 0.816406 BatchTime 1.721019, for discriminator pretraining 
epoch 16, samples 154880, loss 0.644743, accuracy 0.847656 BatchTime 1.649825, for discriminator pretraining 
epoch 16, samples 155136, loss 0.940302, accuracy 0.816406 BatchTime 1.651718, for discriminator pretraining 
epoch 16, samples 155392, loss 0.837490, accuracy 0.792969 BatchTime 1.630450, for discriminator pretraining 
epoch 16, samples 155648, loss 0.621841, accuracy 0.855469 BatchTime 1.638080, for discriminator pretraining 
epoch 16, samples 155904, loss 0.962885, accuracy 0.832031 BatchTime 1.703247, for discriminator pretraining 
epoch 16, samples 156160, loss 0.823539, accuracy 0.828125 BatchTime 1.687742, for discriminator pretraining 
epoch 16, samples 156416, loss 1.247480, accuracy 0.777344 BatchTime 1.710217, for discriminator pretraining 
epoch 16, samples 156672, loss 1.190386, accuracy 0.750000 BatchTime 0.841687, for discriminator pretraining 
Seen  8996  examples for discriminator. Time Cost :  66.19922733306885
load vocab successfully!!
Epoch : 17
epoch 17, samples 156928, loss 0.538071, accuracy 0.867188 BatchTime 2.586705, for discriminator pretraining 
epoch 17, samples 157184, loss 0.522708, accuracy 0.832031 BatchTime 1.807944, for discriminator pretraining 
epoch 17, samples 157440, loss 0.591183, accuracy 0.820312 BatchTime 1.608309, for discriminator pretraining 
epoch 17, samples 157696, loss 0.445791, accuracy 0.875000 BatchTime 1.606349, for discriminator pretraining 
epoch 17, samples 157952, loss 0.584963, accuracy 0.835938 BatchTime 1.670298, for discriminator pretraining 
epoch 17, samples 158208, loss 0.894329, accuracy 0.839844 BatchTime 1.825795, for discriminator pretraining 
epoch 17, samples 158464, loss 0.711259, accuracy 0.847656 BatchTime 1.659494, for discriminator pretraining 
epoch 17, samples 158720, loss 0.520439, accuracy 0.871094 BatchTime 1.681621, for discriminator pretraining 
epoch 17, samples 158976, loss 0.729848, accuracy 0.832031 BatchTime 1.725708, for discriminator pretraining 
epoch 17, samples 159232, loss 0.695076, accuracy 0.832031 BatchTime 1.594443, for discriminator pretraining 
epoch 17, samples 159488, loss 0.630662, accuracy 0.863281 BatchTime 1.640132, for discriminator pretraining 
epoch 17, samples 159744, loss 0.843024, accuracy 0.824219 BatchTime 1.676719, for discriminator pretraining 
epoch 17, samples 160000, loss 0.457923, accuracy 0.886719 BatchTime 1.744254, for discriminator pretraining 
epoch 17, samples 160256, loss 0.697375, accuracy 0.820312 BatchTime 1.720090, for discriminator pretraining 
epoch 17, samples 160512, loss 0.785592, accuracy 0.804688 BatchTime 1.667786, for discriminator pretraining 
epoch 17, samples 160768, loss 0.812952, accuracy 0.816406 BatchTime 1.590491, for discriminator pretraining 
epoch 17, samples 161024, loss 0.772653, accuracy 0.820312 BatchTime 1.669117, for discriminator pretraining 
epoch 17, samples 161280, loss 0.613340, accuracy 0.855469 BatchTime 1.638125, for discriminator pretraining 
epoch 17, samples 161536, loss 0.527281, accuracy 0.863281 BatchTime 1.753758, for discriminator pretraining 
epoch 17, samples 161792, loss 0.624050, accuracy 0.828125 BatchTime 1.702543, for discriminator pretraining 
epoch 17, samples 162048, loss 0.814786, accuracy 0.800781 BatchTime 1.681616, for discriminator pretraining 
epoch 17, samples 162304, loss 1.148957, accuracy 0.769531 BatchTime 1.610136, for discriminator pretraining 
epoch 17, samples 162560, loss 1.078630, accuracy 0.761719 BatchTime 1.654896, for discriminator pretraining 
epoch 17, samples 162816, loss 0.939237, accuracy 0.789062 BatchTime 1.617788, for discriminator pretraining 
epoch 17, samples 163072, loss 0.781669, accuracy 0.839844 BatchTime 1.699848, for discriminator pretraining 
epoch 17, samples 163328, loss 0.729536, accuracy 0.824219 BatchTime 1.618589, for discriminator pretraining 
epoch 17, samples 163584, loss 0.809455, accuracy 0.808594 BatchTime 1.688460, for discriminator pretraining 
epoch 17, samples 163840, loss 0.786421, accuracy 0.792969 BatchTime 1.692529, for discriminator pretraining 
epoch 17, samples 164096, loss 0.827498, accuracy 0.824219 BatchTime 1.705844, for discriminator pretraining 
epoch 17, samples 164352, loss 0.939666, accuracy 0.820312 BatchTime 1.657904, for discriminator pretraining 
epoch 17, samples 164608, loss 0.587873, accuracy 0.832031 BatchTime 1.680415, for discriminator pretraining 
epoch 17, samples 164864, loss 0.712009, accuracy 0.843750 BatchTime 1.697538, for discriminator pretraining 
epoch 17, samples 165120, loss 0.796813, accuracy 0.820312 BatchTime 1.838545, for discriminator pretraining 
epoch 17, samples 165376, loss 0.639482, accuracy 0.832031 BatchTime 1.673791, for discriminator pretraining 
epoch 17, samples 165632, loss 0.585746, accuracy 0.851562 BatchTime 1.655666, for discriminator pretraining 
epoch 17, samples 165888, loss 1.910951, accuracy 0.772727 BatchTime 0.817256, for discriminator pretraining 
Seen  8982  examples for discriminator. Time Cost :  59.77245116233826
load vocab successfully!!
Epoch : 18
epoch 18, samples 166144, loss 0.570494, accuracy 0.871094 BatchTime 2.661321, for discriminator pretraining 
epoch 18, samples 166400, loss 0.679204, accuracy 0.832031 BatchTime 1.759236, for discriminator pretraining 
epoch 18, samples 166656, loss 0.818194, accuracy 0.820312 BatchTime 1.821563, for discriminator pretraining 
epoch 18, samples 166912, loss 0.607182, accuracy 0.855469 BatchTime 1.757096, for discriminator pretraining 
epoch 18, samples 167168, loss 0.568115, accuracy 0.839844 BatchTime 1.656065, for discriminator pretraining 
epoch 18, samples 167424, loss 0.642104, accuracy 0.843750 BatchTime 1.625933, for discriminator pretraining 
epoch 18, samples 167680, loss 1.011464, accuracy 0.785156 BatchTime 1.767293, for discriminator pretraining 
epoch 18, samples 167936, loss 1.099471, accuracy 0.761719 BatchTime 1.735489, for discriminator pretraining 
epoch 18, samples 168192, loss 0.836323, accuracy 0.812500 BatchTime 1.665884, for discriminator pretraining 
epoch 18, samples 168448, loss 0.593321, accuracy 0.832031 BatchTime 1.625421, for discriminator pretraining 
epoch 18, samples 168704, loss 0.726640, accuracy 0.835938 BatchTime 1.656735, for discriminator pretraining 
epoch 18, samples 168960, loss 0.646669, accuracy 0.835938 BatchTime 1.667103, for discriminator pretraining 
epoch 18, samples 169216, loss 0.607919, accuracy 0.847656 BatchTime 1.654746, for discriminator pretraining 
epoch 18, samples 169472, loss 0.685092, accuracy 0.835938 BatchTime 1.615426, for discriminator pretraining 
epoch 18, samples 169728, loss 0.791431, accuracy 0.820312 BatchTime 1.739727, for discriminator pretraining 
epoch 18, samples 169984, loss 0.970557, accuracy 0.777344 BatchTime 1.756467, for discriminator pretraining 
epoch 18, samples 170240, loss 0.701439, accuracy 0.800781 BatchTime 1.697619, for discriminator pretraining 
epoch 18, samples 170496, loss 0.972545, accuracy 0.781250 BatchTime 1.596745, for discriminator pretraining 
epoch 18, samples 170752, loss 1.097994, accuracy 0.800781 BatchTime 1.646677, for discriminator pretraining 
epoch 18, samples 171008, loss 0.760952, accuracy 0.828125 BatchTime 1.628097, for discriminator pretraining 
epoch 18, samples 171264, loss 0.763497, accuracy 0.835938 BatchTime 1.751587, for discriminator pretraining 
epoch 18, samples 171520, loss 0.825746, accuracy 0.847656 BatchTime 1.782666, for discriminator pretraining 
epoch 18, samples 171776, loss 0.534740, accuracy 0.871094 BatchTime 1.696533, for discriminator pretraining 
epoch 18, samples 172032, loss 0.624188, accuracy 0.832031 BatchTime 1.671430, for discriminator pretraining 
epoch 18, samples 172288, loss 0.740807, accuracy 0.816406 BatchTime 1.699868, for discriminator pretraining 
epoch 18, samples 172544, loss 0.808995, accuracy 0.828125 BatchTime 1.612322, for discriminator pretraining 
epoch 18, samples 172800, loss 0.899489, accuracy 0.835938 BatchTime 1.677011, for discriminator pretraining 
epoch 18, samples 173056, loss 0.534215, accuracy 0.847656 BatchTime 1.760372, for discriminator pretraining 
epoch 18, samples 173312, loss 0.591940, accuracy 0.859375 BatchTime 1.719483, for discriminator pretraining 
epoch 18, samples 173568, loss 0.730511, accuracy 0.839844 BatchTime 1.627812, for discriminator pretraining 
epoch 18, samples 173824, loss 0.685041, accuracy 0.835938 BatchTime 1.684809, for discriminator pretraining 
epoch 18, samples 174080, loss 1.094143, accuracy 0.781250 BatchTime 1.758048, for discriminator pretraining 
epoch 18, samples 174336, loss 0.581046, accuracy 0.871094 BatchTime 1.735627, for discriminator pretraining 
epoch 18, samples 174592, loss 0.762993, accuracy 0.816406 BatchTime 1.578980, for discriminator pretraining 
epoch 18, samples 174848, loss 0.809373, accuracy 0.832031 BatchTime 1.660201, for discriminator pretraining 
epoch 18, samples 175104, loss 0.792831, accuracy 0.769231 BatchTime 0.828698, for discriminator pretraining 
Seen  8986  examples for discriminator. Time Cost :  60.16651940345764
load vocab successfully!!
Epoch : 19
epoch 19, samples 175360, loss 0.393381, accuracy 0.894531 BatchTime 2.680864, for discriminator pretraining 
epoch 19, samples 175616, loss 0.572886, accuracy 0.835938 BatchTime 1.857511, for discriminator pretraining 
epoch 19, samples 175872, loss 0.575668, accuracy 0.835938 BatchTime 1.719294, for discriminator pretraining 
epoch 19, samples 176128, loss 0.677070, accuracy 0.855469 BatchTime 1.638154, for discriminator pretraining 
epoch 19, samples 176384, loss 0.388701, accuracy 0.878906 BatchTime 1.739110, for discriminator pretraining 
epoch 19, samples 176640, loss 0.499446, accuracy 0.871094 BatchTime 1.729920, for discriminator pretraining 
epoch 19, samples 176896, loss 0.872373, accuracy 0.800781 BatchTime 1.656897, for discriminator pretraining 
epoch 19, samples 177152, loss 0.940929, accuracy 0.828125 BatchTime 1.731235, for discriminator pretraining 
epoch 19, samples 177408, loss 0.669135, accuracy 0.847656 BatchTime 1.756100, for discriminator pretraining 
epoch 19, samples 177664, loss 0.685170, accuracy 0.863281 BatchTime 1.582439, for discriminator pretraining 
epoch 19, samples 177920, loss 0.648087, accuracy 0.832031 BatchTime 1.651141, for discriminator pretraining 
epoch 19, samples 178176, loss 0.930656, accuracy 0.820312 BatchTime 1.607107, for discriminator pretraining 
epoch 19, samples 178432, loss 1.122355, accuracy 0.800781 BatchTime 1.707133, for discriminator pretraining 
epoch 19, samples 178688, loss 0.803956, accuracy 0.832031 BatchTime 1.735785, for discriminator pretraining 
epoch 19, samples 178944, loss 0.560952, accuracy 0.843750 BatchTime 1.725355, for discriminator pretraining 
epoch 19, samples 179200, loss 0.643070, accuracy 0.863281 BatchTime 1.625831, for discriminator pretraining 
save params when epoch 19, samples 179200
epoch 19, samples 179456, loss 0.577520, accuracy 0.867188 BatchTime 1.650507, for discriminator pretraining 
epoch 19, samples 179712, loss 0.458270, accuracy 0.898438 BatchTime 1.675755, for discriminator pretraining 
epoch 19, samples 179968, loss 0.690970, accuracy 0.824219 BatchTime 1.725157, for discriminator pretraining 
epoch 19, samples 180224, loss 0.689753, accuracy 0.843750 BatchTime 1.634588, for discriminator pretraining 
epoch 19, samples 180480, loss 0.579148, accuracy 0.820312 BatchTime 1.655050, for discriminator pretraining 
epoch 19, samples 180736, loss 0.554752, accuracy 0.847656 BatchTime 1.672886, for discriminator pretraining 
epoch 19, samples 180992, loss 0.722274, accuracy 0.835938 BatchTime 1.767047, for discriminator pretraining 
epoch 19, samples 181248, loss 0.552057, accuracy 0.859375 BatchTime 1.691932, for discriminator pretraining 
epoch 19, samples 181504, loss 0.706919, accuracy 0.820312 BatchTime 1.653972, for discriminator pretraining 
epoch 19, samples 181760, loss 0.840193, accuracy 0.804688 BatchTime 1.607386, for discriminator pretraining 
epoch 19, samples 182016, loss 0.682962, accuracy 0.835938 BatchTime 1.668832, for discriminator pretraining 
epoch 19, samples 182272, loss 0.896642, accuracy 0.816406 BatchTime 1.628716, for discriminator pretraining 
epoch 19, samples 182528, loss 0.815655, accuracy 0.812500 BatchTime 1.769179, for discriminator pretraining 
epoch 19, samples 182784, loss 0.691450, accuracy 0.843750 BatchTime 1.724859, for discriminator pretraining 
epoch 19, samples 183040, loss 0.684059, accuracy 0.835938 BatchTime 1.653499, for discriminator pretraining 
epoch 19, samples 183296, loss 0.592925, accuracy 0.855469 BatchTime 1.640275, for discriminator pretraining 
epoch 19, samples 183552, loss 0.759255, accuracy 0.832031 BatchTime 1.647639, for discriminator pretraining 
epoch 19, samples 183808, loss 0.736431, accuracy 0.839844 BatchTime 1.623763, for discriminator pretraining 
epoch 19, samples 184064, loss 0.722834, accuracy 0.828125 BatchTime 1.755963, for discriminator pretraining 
epoch 19, samples 184320, loss 0.740056, accuracy 0.785714 BatchTime 0.953216, for discriminator pretraining 
Seen  8988  examples for discriminator. Time Cost :  67.32542610168457
load vocab successfully!!
Epoch : 20
epoch 20, samples 184576, loss 0.602321, accuracy 0.843750 BatchTime 2.710068, for discriminator pretraining 
epoch 20, samples 184832, loss 0.668277, accuracy 0.835938 BatchTime 1.775014, for discriminator pretraining 
epoch 20, samples 185088, loss 0.569625, accuracy 0.855469 BatchTime 1.688419, for discriminator pretraining 
epoch 20, samples 185344, loss 0.619026, accuracy 0.851562 BatchTime 1.627774, for discriminator pretraining 
epoch 20, samples 185600, loss 0.577388, accuracy 0.867188 BatchTime 1.652112, for discriminator pretraining 
epoch 20, samples 185856, loss 0.699248, accuracy 0.832031 BatchTime 1.681148, for discriminator pretraining 
epoch 20, samples 186112, loss 0.728667, accuracy 0.828125 BatchTime 1.662299, for discriminator pretraining 
epoch 20, samples 186368, loss 0.429443, accuracy 0.867188 BatchTime 1.632368, for discriminator pretraining 
epoch 20, samples 186624, loss 0.740440, accuracy 0.828125 BatchTime 1.661169, for discriminator pretraining 
epoch 20, samples 186880, loss 0.588457, accuracy 0.867188 BatchTime 1.608055, for discriminator pretraining 
epoch 20, samples 187136, loss 0.595616, accuracy 0.835938 BatchTime 1.765284, for discriminator pretraining 
epoch 20, samples 187392, loss 0.735618, accuracy 0.839844 BatchTime 1.769356, for discriminator pretraining 
epoch 20, samples 187648, loss 0.703103, accuracy 0.843750 BatchTime 1.759686, for discriminator pretraining 
epoch 20, samples 187904, loss 0.683803, accuracy 0.835938 BatchTime 1.788835, for discriminator pretraining 
epoch 20, samples 188160, loss 0.574605, accuracy 0.871094 BatchTime 1.662592, for discriminator pretraining 
epoch 20, samples 188416, loss 0.599591, accuracy 0.855469 BatchTime 1.612781, for discriminator pretraining 
epoch 20, samples 188672, loss 0.803917, accuracy 0.835938 BatchTime 1.666193, for discriminator pretraining 
epoch 20, samples 188928, loss 0.626355, accuracy 0.847656 BatchTime 1.613097, for discriminator pretraining 
epoch 20, samples 189184, loss 0.876123, accuracy 0.808594 BatchTime 1.648317, for discriminator pretraining 
epoch 20, samples 189440, loss 0.599182, accuracy 0.855469 BatchTime 1.608823, for discriminator pretraining 
epoch 20, samples 189696, loss 0.503835, accuracy 0.882812 BatchTime 1.622251, for discriminator pretraining 
epoch 20, samples 189952, loss 0.698848, accuracy 0.843750 BatchTime 1.621632, for discriminator pretraining 
epoch 20, samples 190208, loss 0.896767, accuracy 0.816406 BatchTime 1.723330, for discriminator pretraining 
epoch 20, samples 190464, loss 0.729113, accuracy 0.832031 BatchTime 1.747031, for discriminator pretraining 
epoch 20, samples 190720, loss 0.508313, accuracy 0.847656 BatchTime 1.692887, for discriminator pretraining 
epoch 20, samples 190976, loss 0.660959, accuracy 0.828125 BatchTime 1.629920, for discriminator pretraining 
epoch 20, samples 191232, loss 0.638717, accuracy 0.835938 BatchTime 1.711431, for discriminator pretraining 
epoch 20, samples 191488, loss 0.796202, accuracy 0.816406 BatchTime 1.713897, for discriminator pretraining 
epoch 20, samples 191744, loss 0.817574, accuracy 0.828125 BatchTime 1.737026, for discriminator pretraining 
epoch 20, samples 192000, loss 0.867121, accuracy 0.812500 BatchTime 1.677384, for discriminator pretraining 
epoch 20, samples 192256, loss 0.629129, accuracy 0.824219 BatchTime 1.644508, for discriminator pretraining 
epoch 20, samples 192512, loss 0.630868, accuracy 0.847656 BatchTime 1.625614, for discriminator pretraining 
epoch 20, samples 192768, loss 0.517764, accuracy 0.863281 BatchTime 1.643153, for discriminator pretraining 
epoch 20, samples 193024, loss 0.563146, accuracy 0.835938 BatchTime 1.685494, for discriminator pretraining 
epoch 20, samples 193280, loss 0.962217, accuracy 0.777344 BatchTime 1.791924, for discriminator pretraining 
epoch 20, samples 193536, loss 0.576392, accuracy 0.846154 BatchTime 0.860884, for discriminator pretraining 
Seen  8986  examples for discriminator. Time Cost :  59.83363628387451
load vocab successfully!!
Epoch : 21
epoch 21, samples 193792, loss 0.635898, accuracy 0.863281 BatchTime 2.632393, for discriminator pretraining 
epoch 21, samples 194048, loss 0.710437, accuracy 0.855469 BatchTime 1.767579, for discriminator pretraining 
epoch 21, samples 194304, loss 0.593151, accuracy 0.859375 BatchTime 1.685576, for discriminator pretraining 
epoch 21, samples 194560, loss 0.705249, accuracy 0.804688 BatchTime 1.716491, for discriminator pretraining 
epoch 21, samples 194816, loss 0.918076, accuracy 0.812500 BatchTime 1.714380, for discriminator pretraining 
epoch 21, samples 195072, loss 0.780727, accuracy 0.843750 BatchTime 1.638560, for discriminator pretraining 
epoch 21, samples 195328, loss 0.608246, accuracy 0.863281 BatchTime 1.663097, for discriminator pretraining 
epoch 21, samples 195584, loss 0.447756, accuracy 0.859375 BatchTime 1.638023, for discriminator pretraining 
epoch 21, samples 195840, loss 0.470864, accuracy 0.859375 BatchTime 1.615795, for discriminator pretraining 
epoch 21, samples 196096, loss 0.477827, accuracy 0.847656 BatchTime 1.602694, for discriminator pretraining 
epoch 21, samples 196352, loss 0.620518, accuracy 0.847656 BatchTime 1.663922, for discriminator pretraining 
epoch 21, samples 196608, loss 0.599348, accuracy 0.871094 BatchTime 1.623466, for discriminator pretraining 
epoch 21, samples 196864, loss 0.676222, accuracy 0.843750 BatchTime 1.782780, for discriminator pretraining 
epoch 21, samples 197120, loss 1.004745, accuracy 0.800781 BatchTime 1.682176, for discriminator pretraining 
epoch 21, samples 197376, loss 0.833065, accuracy 0.832031 BatchTime 1.618564, for discriminator pretraining 
epoch 21, samples 197632, loss 0.782670, accuracy 0.828125 BatchTime 1.569276, for discriminator pretraining 
epoch 21, samples 197888, loss 0.583297, accuracy 0.851562 BatchTime 1.637669, for discriminator pretraining 
epoch 21, samples 198144, loss 0.652589, accuracy 0.835938 BatchTime 1.620062, for discriminator pretraining 
epoch 21, samples 198400, loss 0.633171, accuracy 0.863281 BatchTime 1.650996, for discriminator pretraining 
epoch 21, samples 198656, loss 0.737335, accuracy 0.824219 BatchTime 1.626824, for discriminator pretraining 
epoch 21, samples 198912, loss 0.598033, accuracy 0.867188 BatchTime 1.656582, for discriminator pretraining 
epoch 21, samples 199168, loss 0.530021, accuracy 0.847656 BatchTime 1.749497, for discriminator pretraining 
epoch 21, samples 199424, loss 0.732916, accuracy 0.824219 BatchTime 1.766896, for discriminator pretraining 
epoch 21, samples 199680, loss 0.654005, accuracy 0.824219 BatchTime 1.581517, for discriminator pretraining 
epoch 21, samples 199936, loss 0.948979, accuracy 0.804688 BatchTime 1.636031, for discriminator pretraining 
epoch 21, samples 200192, loss 0.997649, accuracy 0.792969 BatchTime 1.624307, for discriminator pretraining 
epoch 21, samples 200448, loss 0.937077, accuracy 0.796875 BatchTime 1.648637, for discriminator pretraining 
epoch 21, samples 200704, loss 0.965660, accuracy 0.800781 BatchTime 1.613449, for discriminator pretraining 
epoch 21, samples 200960, loss 0.738402, accuracy 0.828125 BatchTime 1.638520, for discriminator pretraining 
epoch 21, samples 201216, loss 0.665668, accuracy 0.863281 BatchTime 1.670366, for discriminator pretraining 
epoch 21, samples 201472, loss 0.799762, accuracy 0.812500 BatchTime 1.757879, for discriminator pretraining 
epoch 21, samples 201728, loss 0.770092, accuracy 0.804688 BatchTime 1.709821, for discriminator pretraining 
epoch 21, samples 201984, loss 0.789519, accuracy 0.835938 BatchTime 1.882152, for discriminator pretraining 
epoch 21, samples 202240, loss 0.817158, accuracy 0.820312 BatchTime 1.616232, for discriminator pretraining 
epoch 21, samples 202496, loss 0.870963, accuracy 0.769531 BatchTime 1.673609, for discriminator pretraining 
epoch 21, samples 202752, loss 0.365995, accuracy 0.900000 BatchTime 0.838565, for discriminator pretraining 
Seen  8990  examples for discriminator. Time Cost :  59.35489749908447
load vocab successfully!!
Epoch : 22
epoch 22, samples 203008, loss 0.649603, accuracy 0.824219 BatchTime 2.542057, for discriminator pretraining 
epoch 22, samples 203264, loss 0.526804, accuracy 0.843750 BatchTime 1.755555, for discriminator pretraining 
epoch 22, samples 203520, loss 0.493705, accuracy 0.863281 BatchTime 1.685164, for discriminator pretraining 
epoch 22, samples 203776, loss 0.685450, accuracy 0.851562 BatchTime 1.620483, for discriminator pretraining 
epoch 22, samples 204032, loss 0.887617, accuracy 0.816406 BatchTime 1.638626, for discriminator pretraining 
epoch 22, samples 204288, loss 0.573898, accuracy 0.878906 BatchTime 1.577059, for discriminator pretraining 
epoch 22, samples 204544, loss 0.847460, accuracy 0.808594 BatchTime 1.637424, for discriminator pretraining 
epoch 22, samples 204800, loss 0.819804, accuracy 0.804688 BatchTime 1.640085, for discriminator pretraining 
save params when epoch 22, samples 204800
epoch 22, samples 205056, loss 0.739443, accuracy 0.847656 BatchTime 1.728441, for discriminator pretraining 
epoch 22, samples 205312, loss 0.383431, accuracy 0.910156 BatchTime 1.689369, for discriminator pretraining 
epoch 22, samples 205568, loss 0.417994, accuracy 0.894531 BatchTime 1.738513, for discriminator pretraining 
epoch 22, samples 205824, loss 0.572112, accuracy 0.863281 BatchTime 1.642533, for discriminator pretraining 
epoch 22, samples 206080, loss 0.693706, accuracy 0.820312 BatchTime 1.658969, for discriminator pretraining 
epoch 22, samples 206336, loss 0.912027, accuracy 0.800781 BatchTime 1.631473, for discriminator pretraining 
epoch 22, samples 206592, loss 0.641224, accuracy 0.828125 BatchTime 1.664649, for discriminator pretraining 
epoch 22, samples 206848, loss 0.674131, accuracy 0.851562 BatchTime 1.613133, for discriminator pretraining 
epoch 22, samples 207104, loss 0.794699, accuracy 0.820312 BatchTime 1.677265, for discriminator pretraining 
epoch 22, samples 207360, loss 0.636562, accuracy 0.843750 BatchTime 1.692920, for discriminator pretraining 
epoch 22, samples 207616, loss 0.538503, accuracy 0.859375 BatchTime 1.658382, for discriminator pretraining 
epoch 22, samples 207872, loss 0.585911, accuracy 0.859375 BatchTime 1.628854, for discriminator pretraining 
epoch 22, samples 208128, loss 0.452735, accuracy 0.875000 BatchTime 1.632274, for discriminator pretraining 
epoch 22, samples 208384, loss 0.658140, accuracy 0.843750 BatchTime 1.607970, for discriminator pretraining 
epoch 22, samples 208640, loss 0.693919, accuracy 0.843750 BatchTime 1.634881, for discriminator pretraining 
epoch 22, samples 208896, loss 0.719968, accuracy 0.835938 BatchTime 1.603910, for discriminator pretraining 
epoch 22, samples 209152, loss 0.738486, accuracy 0.792969 BatchTime 1.599784, for discriminator pretraining 
epoch 22, samples 209408, loss 0.588350, accuracy 0.800781 BatchTime 1.610600, for discriminator pretraining 
epoch 22, samples 209664, loss 0.847227, accuracy 0.835938 BatchTime 1.630734, for discriminator pretraining 
epoch 22, samples 209920, loss 0.768507, accuracy 0.843750 BatchTime 1.626385, for discriminator pretraining 
epoch 22, samples 210176, loss 0.841733, accuracy 0.800781 BatchTime 1.598052, for discriminator pretraining 
epoch 22, samples 210432, loss 0.675374, accuracy 0.839844 BatchTime 1.605359, for discriminator pretraining 
epoch 22, samples 210688, loss 0.686503, accuracy 0.828125 BatchTime 1.645425, for discriminator pretraining 
epoch 22, samples 210944, loss 0.707741, accuracy 0.847656 BatchTime 1.564484, for discriminator pretraining 
epoch 22, samples 211200, loss 0.988756, accuracy 0.824219 BatchTime 1.673888, for discriminator pretraining 
epoch 22, samples 211456, loss 0.818103, accuracy 0.808594 BatchTime 1.654577, for discriminator pretraining 
epoch 22, samples 211712, loss 0.966622, accuracy 0.816406 BatchTime 1.673953, for discriminator pretraining 
epoch 22, samples 211968, loss 0.308079, accuracy 0.880952 BatchTime 6.483533, for discriminator pretraining 
Seen  9002  examples for discriminator. Time Cost :  69.64269375801086
mv: cannot stat 'prepare_data/good_train_clean.dst.5000.shuf': No such file or directory
load vocab successfully!!
Epoch : 23
epoch 23, samples 212224, loss 0.655302, accuracy 0.847656 BatchTime 2.536883, for discriminator pretraining 
epoch 23, samples 212480, loss 0.626325, accuracy 0.859375 BatchTime 1.755615, for discriminator pretraining 
epoch 23, samples 212736, loss 0.618353, accuracy 0.851562 BatchTime 1.621940, for discriminator pretraining 
epoch 23, samples 212992, loss 0.734025, accuracy 0.851562 BatchTime 1.621033, for discriminator pretraining 
epoch 23, samples 213248, loss 0.496902, accuracy 0.859375 BatchTime 1.759574, for discriminator pretraining 
epoch 23, samples 213504, loss 0.527495, accuracy 0.855469 BatchTime 1.743960, for discriminator pretraining 
epoch 23, samples 213760, loss 0.695216, accuracy 0.859375 BatchTime 1.635993, for discriminator pretraining 
epoch 23, samples 214016, loss 0.661300, accuracy 0.839844 BatchTime 1.640137, for discriminator pretraining 
epoch 23, samples 214272, loss 0.736134, accuracy 0.820312 BatchTime 1.625108, for discriminator pretraining 
epoch 23, samples 214528, loss 1.273564, accuracy 0.792969 BatchTime 1.613051, for discriminator pretraining 
epoch 23, samples 214784, loss 0.909001, accuracy 0.800781 BatchTime 1.653875, for discriminator pretraining 
epoch 23, samples 215040, loss 0.710868, accuracy 0.847656 BatchTime 1.733161, for discriminator pretraining 
epoch 23, samples 215296, loss 0.556113, accuracy 0.859375 BatchTime 1.689691, for discriminator pretraining 
epoch 23, samples 215552, loss 0.760649, accuracy 0.824219 BatchTime 1.642596, for discriminator pretraining 
epoch 23, samples 215808, loss 0.846030, accuracy 0.808594 BatchTime 1.624015, for discriminator pretraining 
epoch 23, samples 216064, loss 0.640015, accuracy 0.843750 BatchTime 1.622018, for discriminator pretraining 
epoch 23, samples 216320, loss 0.686788, accuracy 0.835938 BatchTime 1.584982, for discriminator pretraining 
epoch 23, samples 216576, loss 0.823107, accuracy 0.789062 BatchTime 1.680676, for discriminator pretraining 
epoch 23, samples 216832, loss 1.029396, accuracy 0.812500 BatchTime 1.735563, for discriminator pretraining 
epoch 23, samples 217088, loss 0.834535, accuracy 0.835938 BatchTime 1.725646, for discriminator pretraining 
epoch 23, samples 217344, loss 0.701743, accuracy 0.816406 BatchTime 1.617785, for discriminator pretraining 
epoch 23, samples 217600, loss 0.573683, accuracy 0.859375 BatchTime 1.603067, for discriminator pretraining 
epoch 23, samples 217856, loss 1.018245, accuracy 0.800781 BatchTime 1.617109, for discriminator pretraining 
epoch 23, samples 218112, loss 0.616728, accuracy 0.835938 BatchTime 1.619587, for discriminator pretraining 
epoch 23, samples 218368, loss 0.713079, accuracy 0.855469 BatchTime 1.625720, for discriminator pretraining 
epoch 23, samples 218624, loss 0.923436, accuracy 0.796875 BatchTime 1.685391, for discriminator pretraining 
epoch 23, samples 218880, loss 0.581284, accuracy 0.843750 BatchTime 1.736745, for discriminator pretraining 
epoch 23, samples 219136, loss 0.638629, accuracy 0.855469 BatchTime 1.624045, for discriminator pretraining 
epoch 23, samples 219392, loss 0.698037, accuracy 0.828125 BatchTime 1.584044, for discriminator pretraining 
epoch 23, samples 219648, loss 0.823570, accuracy 0.839844 BatchTime 1.652073, for discriminator pretraining 
epoch 23, samples 219904, loss 0.820755, accuracy 0.828125 BatchTime 1.758706, for discriminator pretraining 
epoch 23, samples 220160, loss 0.940544, accuracy 0.816406 BatchTime 1.659213, for discriminator pretraining 
epoch 23, samples 220416, loss 0.763852, accuracy 0.820312 BatchTime 1.626306, for discriminator pretraining 
epoch 23, samples 220672, loss 0.640631, accuracy 0.820312 BatchTime 1.615704, for discriminator pretraining 
epoch 23, samples 220928, loss 0.732478, accuracy 0.847656 BatchTime 1.611659, for discriminator pretraining 
epoch 23, samples 221184, loss 0.857355, accuracy 0.833333 BatchTime 0.854790, for discriminator pretraining 
Seen  8996  examples for discriminator. Time Cost :  59.078232288360596
load vocab successfully!!
Epoch : 24
epoch 24, samples 221440, loss 0.481075, accuracy 0.867188 BatchTime 2.634328, for discriminator pretraining 
epoch 24, samples 221696, loss 0.468368, accuracy 0.886719 BatchTime 1.811043, for discriminator pretraining 
epoch 24, samples 221952, loss 0.571950, accuracy 0.847656 BatchTime 1.740277, for discriminator pretraining 
epoch 24, samples 222208, loss 0.632109, accuracy 0.843750 BatchTime 1.692653, for discriminator pretraining 
epoch 24, samples 222464, loss 0.455771, accuracy 0.890625 BatchTime 1.633339, for discriminator pretraining 
epoch 24, samples 222720, loss 0.351674, accuracy 0.875000 BatchTime 1.611438, for discriminator pretraining 
epoch 24, samples 222976, loss 0.442188, accuracy 0.847656 BatchTime 1.649605, for discriminator pretraining 
epoch 24, samples 223232, loss 0.674097, accuracy 0.835938 BatchTime 1.634460, for discriminator pretraining 
epoch 24, samples 223488, loss 0.684203, accuracy 0.835938 BatchTime 1.648465, for discriminator pretraining 
epoch 24, samples 223744, loss 0.706854, accuracy 0.847656 BatchTime 1.713707, for discriminator pretraining 
epoch 24, samples 224000, loss 1.003159, accuracy 0.800781 BatchTime 1.771050, for discriminator pretraining 
epoch 24, samples 224256, loss 0.936937, accuracy 0.808594 BatchTime 1.650481, for discriminator pretraining 
epoch 24, samples 224512, loss 0.613488, accuracy 0.847656 BatchTime 1.639397, for discriminator pretraining 
epoch 24, samples 224768, loss 0.490667, accuracy 0.863281 BatchTime 1.657042, for discriminator pretraining 
epoch 24, samples 225024, loss 0.803903, accuracy 0.832031 BatchTime 1.656670, for discriminator pretraining 
epoch 24, samples 225280, loss 0.491297, accuracy 0.855469 BatchTime 1.639885, for discriminator pretraining 
epoch 24, samples 225536, loss 0.489586, accuracy 0.859375 BatchTime 1.720550, for discriminator pretraining 
epoch 24, samples 225792, loss 0.707612, accuracy 0.847656 BatchTime 1.713079, for discriminator pretraining 
epoch 24, samples 226048, loss 0.741847, accuracy 0.835938 BatchTime 1.669913, for discriminator pretraining 
epoch 24, samples 226304, loss 1.035931, accuracy 0.808594 BatchTime 1.720038, for discriminator pretraining 
epoch 24, samples 226560, loss 0.843827, accuracy 0.816406 BatchTime 1.752028, for discriminator pretraining 
epoch 24, samples 226816, loss 0.626504, accuracy 0.851562 BatchTime 1.675999, for discriminator pretraining 
epoch 24, samples 227072, loss 0.662319, accuracy 0.820312 BatchTime 1.623666, for discriminator pretraining 
epoch 24, samples 227328, loss 0.799207, accuracy 0.812500 BatchTime 1.632607, for discriminator pretraining 
epoch 24, samples 227584, loss 0.837764, accuracy 0.839844 BatchTime 1.719425, for discriminator pretraining 
epoch 24, samples 227840, loss 0.894055, accuracy 0.796875 BatchTime 1.744778, for discriminator pretraining 
epoch 24, samples 228096, loss 0.693195, accuracy 0.832031 BatchTime 1.682460, for discriminator pretraining 
epoch 24, samples 228352, loss 0.675346, accuracy 0.824219 BatchTime 1.652842, for discriminator pretraining 
epoch 24, samples 228608, loss 0.890352, accuracy 0.808594 BatchTime 1.673945, for discriminator pretraining 
epoch 24, samples 228864, loss 0.806777, accuracy 0.824219 BatchTime 1.766290, for discriminator pretraining 
epoch 24, samples 229120, loss 0.621783, accuracy 0.832031 BatchTime 1.739289, for discriminator pretraining 
epoch 24, samples 229376, loss 0.748163, accuracy 0.828125 BatchTime 1.615036, for discriminator pretraining 
epoch 24, samples 229632, loss 0.977199, accuracy 0.804688 BatchTime 1.621033, for discriminator pretraining 
epoch 24, samples 229888, loss 0.724953, accuracy 0.800781 BatchTime 1.658107, for discriminator pretraining 
epoch 24, samples 230144, loss 0.842777, accuracy 0.828125 BatchTime 1.599802, for discriminator pretraining 
epoch 24, samples 230400, loss 0.402206, accuracy 0.928571 BatchTime 0.852595, for discriminator pretraining 
save params when epoch 24, samples 230400
Seen  8988  examples for discriminator. Time Cost :  65.14218258857727
load vocab successfully!!
Epoch : 25
epoch 25, samples 230656, loss 0.459054, accuracy 0.882812 BatchTime 2.677889, for discriminator pretraining 
epoch 25, samples 230912, loss 0.514601, accuracy 0.882812 BatchTime 1.851850, for discriminator pretraining 
epoch 25, samples 231168, loss 0.341491, accuracy 0.890625 BatchTime 1.753726, for discriminator pretraining 
epoch 25, samples 231424, loss 0.322706, accuracy 0.898438 BatchTime 1.620392, for discriminator pretraining 
epoch 25, samples 231680, loss 0.605523, accuracy 0.867188 BatchTime 1.620706, for discriminator pretraining 
epoch 25, samples 231936, loss 0.594937, accuracy 0.875000 BatchTime 1.623195, for discriminator pretraining 
epoch 25, samples 232192, loss 0.950984, accuracy 0.812500 BatchTime 1.681724, for discriminator pretraining 
epoch 25, samples 232448, loss 0.628610, accuracy 0.839844 BatchTime 1.649924, for discriminator pretraining 
epoch 25, samples 232704, loss 0.604368, accuracy 0.835938 BatchTime 1.749182, for discriminator pretraining 
epoch 25, samples 232960, loss 0.631789, accuracy 0.843750 BatchTime 1.715680, for discriminator pretraining 
epoch 25, samples 233216, loss 0.461740, accuracy 0.878906 BatchTime 1.667743, for discriminator pretraining 
epoch 25, samples 233472, loss 0.549707, accuracy 0.835938 BatchTime 1.760485, for discriminator pretraining 
epoch 25, samples 233728, loss 0.599318, accuracy 0.867188 BatchTime 1.718632, for discriminator pretraining 
epoch 25, samples 233984, loss 0.648697, accuracy 0.812500 BatchTime 1.646927, for discriminator pretraining 
epoch 25, samples 234240, loss 0.748784, accuracy 0.835938 BatchTime 1.611902, for discriminator pretraining 
epoch 25, samples 234496, loss 0.909945, accuracy 0.832031 BatchTime 1.626643, for discriminator pretraining 
epoch 25, samples 234752, loss 0.776219, accuracy 0.804688 BatchTime 1.632613, for discriminator pretraining 
epoch 25, samples 235008, loss 0.771689, accuracy 0.824219 BatchTime 1.648073, for discriminator pretraining 
epoch 25, samples 235264, loss 0.581566, accuracy 0.878906 BatchTime 1.653329, for discriminator pretraining 
epoch 25, samples 235520, loss 0.483375, accuracy 0.859375 BatchTime 1.610192, for discriminator pretraining 
epoch 25, samples 235776, loss 0.734197, accuracy 0.820312 BatchTime 1.574558, for discriminator pretraining 
epoch 25, samples 236032, loss 0.678980, accuracy 0.828125 BatchTime 1.584669, for discriminator pretraining 
epoch 25, samples 236288, loss 0.407819, accuracy 0.902344 BatchTime 1.628404, for discriminator pretraining 
epoch 25, samples 236544, loss 0.529713, accuracy 0.855469 BatchTime 1.640364, for discriminator pretraining 
epoch 25, samples 236800, loss 0.824749, accuracy 0.800781 BatchTime 1.597811, for discriminator pretraining 
epoch 25, samples 237056, loss 1.163599, accuracy 0.792969 BatchTime 1.615562, for discriminator pretraining 
epoch 25, samples 237312, loss 0.788553, accuracy 0.828125 BatchTime 1.614711, for discriminator pretraining 
epoch 25, samples 237568, loss 0.789221, accuracy 0.820312 BatchTime 1.659416, for discriminator pretraining 
epoch 25, samples 237824, loss 0.688748, accuracy 0.843750 BatchTime 1.707859, for discriminator pretraining 
epoch 25, samples 238080, loss 0.585163, accuracy 0.855469 BatchTime 1.710408, for discriminator pretraining 
epoch 25, samples 238336, loss 0.676293, accuracy 0.824219 BatchTime 1.663040, for discriminator pretraining 
epoch 25, samples 238592, loss 0.779272, accuracy 0.820312 BatchTime 1.599025, for discriminator pretraining 
epoch 25, samples 238848, loss 0.748713, accuracy 0.855469 BatchTime 1.599358, for discriminator pretraining 
epoch 25, samples 239104, loss 0.787024, accuracy 0.808594 BatchTime 1.618136, for discriminator pretraining 
epoch 25, samples 239360, loss 0.821770, accuracy 0.824219 BatchTime 1.630597, for discriminator pretraining 
epoch 25, samples 239616, loss 0.691829, accuracy 0.866667 BatchTime 0.840794, for discriminator pretraining 
Seen  8990  examples for discriminator. Time Cost :  59.04475498199463
load vocab successfully!!
Epoch : 26
epoch 26, samples 239872, loss 0.370233, accuracy 0.875000 BatchTime 2.531431, for discriminator pretraining 
epoch 26, samples 240128, loss 0.620056, accuracy 0.839844 BatchTime 1.737411, for discriminator pretraining 
epoch 26, samples 240384, loss 0.677578, accuracy 0.859375 BatchTime 1.700943, for discriminator pretraining 
epoch 26, samples 240640, loss 0.694388, accuracy 0.816406 BatchTime 1.655361, for discriminator pretraining 
epoch 26, samples 240896, loss 0.615609, accuracy 0.843750 BatchTime 1.633770, for discriminator pretraining 
epoch 26, samples 241152, loss 0.602365, accuracy 0.824219 BatchTime 1.687258, for discriminator pretraining 
epoch 26, samples 241408, loss 0.650144, accuracy 0.839844 BatchTime 1.612476, for discriminator pretraining 
epoch 26, samples 241664, loss 0.688483, accuracy 0.859375 BatchTime 1.601681, for discriminator pretraining 
epoch 26, samples 241920, loss 0.554828, accuracy 0.859375 BatchTime 1.642256, for discriminator pretraining 
epoch 26, samples 242176, loss 0.693991, accuracy 0.839844 BatchTime 1.612741, for discriminator pretraining 
epoch 26, samples 242432, loss 0.707775, accuracy 0.847656 BatchTime 1.617601, for discriminator pretraining 
epoch 26, samples 242688, loss 0.653180, accuracy 0.832031 BatchTime 1.597378, for discriminator pretraining 
epoch 26, samples 242944, loss 0.595770, accuracy 0.843750 BatchTime 1.607854, for discriminator pretraining 
epoch 26, samples 243200, loss 0.689097, accuracy 0.828125 BatchTime 1.919992, for discriminator pretraining 
epoch 26, samples 243456, loss 0.381728, accuracy 0.882812 BatchTime 1.744414, for discriminator pretraining 
epoch 26, samples 243712, loss 0.845438, accuracy 0.820312 BatchTime 1.699556, for discriminator pretraining 
epoch 26, samples 243968, loss 0.503888, accuracy 0.847656 BatchTime 1.623843, for discriminator pretraining 
epoch 26, samples 244224, loss 0.741626, accuracy 0.847656 BatchTime 1.676013, for discriminator pretraining 
epoch 26, samples 244480, loss 1.047439, accuracy 0.761719 BatchTime 1.674817, for discriminator pretraining 
epoch 26, samples 244736, loss 0.889379, accuracy 0.816406 BatchTime 1.674145, for discriminator pretraining 
epoch 26, samples 244992, loss 0.645432, accuracy 0.851562 BatchTime 1.681896, for discriminator pretraining 
epoch 26, samples 245248, loss 0.562895, accuracy 0.851562 BatchTime 1.627584, for discriminator pretraining 
epoch 26, samples 245504, loss 0.749678, accuracy 0.800781 BatchTime 1.615428, for discriminator pretraining 
epoch 26, samples 245760, loss 0.671655, accuracy 0.816406 BatchTime 1.604259, for discriminator pretraining 
epoch 26, samples 246016, loss 0.800496, accuracy 0.808594 BatchTime 1.616666, for discriminator pretraining 
epoch 26, samples 246272, loss 0.882599, accuracy 0.781250 BatchTime 1.623189, for discriminator pretraining 
epoch 26, samples 246528, loss 0.841351, accuracy 0.804688 BatchTime 1.620504, for discriminator pretraining 
epoch 26, samples 246784, loss 0.909934, accuracy 0.800781 BatchTime 1.599813, for discriminator pretraining 
epoch 26, samples 247040, loss 0.672697, accuracy 0.824219 BatchTime 1.671276, for discriminator pretraining 
epoch 26, samples 247296, loss 0.567133, accuracy 0.855469 BatchTime 1.795765, for discriminator pretraining 
epoch 26, samples 247552, loss 0.715219, accuracy 0.863281 BatchTime 1.683410, for discriminator pretraining 
epoch 26, samples 247808, loss 0.679604, accuracy 0.855469 BatchTime 1.633151, for discriminator pretraining 
epoch 26, samples 248064, loss 0.597988, accuracy 0.835938 BatchTime 1.639628, for discriminator pretraining 
epoch 26, samples 248320, loss 0.674389, accuracy 0.835938 BatchTime 1.639062, for discriminator pretraining 
epoch 26, samples 248576, loss 0.530487, accuracy 0.859375 BatchTime 1.737459, for discriminator pretraining 
epoch 26, samples 248832, loss 0.193290, accuracy 0.950000 BatchTime 7.227208, for discriminator pretraining 
Seen  9000  examples for discriminator. Time Cost :  65.50730514526367
load vocab successfully!!
Epoch : 27
epoch 27, samples 249088, loss 0.334912, accuracy 0.902344 BatchTime 2.453403, for discriminator pretraining 
epoch 27, samples 249344, loss 0.595645, accuracy 0.828125 BatchTime 1.894576, for discriminator pretraining 
epoch 27, samples 249600, loss 0.828547, accuracy 0.824219 BatchTime 1.642195, for discriminator pretraining 
epoch 27, samples 249856, loss 0.833895, accuracy 0.851562 BatchTime 1.619931, for discriminator pretraining 
epoch 27, samples 250112, loss 0.652104, accuracy 0.847656 BatchTime 1.783383, for discriminator pretraining 
epoch 27, samples 250368, loss 0.623225, accuracy 0.875000 BatchTime 1.726221, for discriminator pretraining 
epoch 27, samples 250624, loss 0.595530, accuracy 0.871094 BatchTime 1.740738, for discriminator pretraining 
epoch 27, samples 250880, loss 0.439846, accuracy 0.855469 BatchTime 1.648302, for discriminator pretraining 
epoch 27, samples 251136, loss 0.400496, accuracy 0.890625 BatchTime 1.701884, for discriminator pretraining 
epoch 27, samples 251392, loss 0.406291, accuracy 0.906250 BatchTime 1.688133, for discriminator pretraining 
epoch 27, samples 251648, loss 0.866602, accuracy 0.792969 BatchTime 1.697502, for discriminator pretraining 
epoch 27, samples 251904, loss 0.734022, accuracy 0.804688 BatchTime 1.621558, for discriminator pretraining 
epoch 27, samples 252160, loss 0.567822, accuracy 0.859375 BatchTime 1.663946, for discriminator pretraining 
epoch 27, samples 252416, loss 0.672489, accuracy 0.828125 BatchTime 1.764608, for discriminator pretraining 
epoch 27, samples 252672, loss 0.485608, accuracy 0.871094 BatchTime 1.795162, for discriminator pretraining 
epoch 27, samples 252928, loss 0.544704, accuracy 0.855469 BatchTime 1.629531, for discriminator pretraining 
epoch 27, samples 253184, loss 0.618397, accuracy 0.859375 BatchTime 1.676127, for discriminator pretraining 
epoch 27, samples 253440, loss 0.635212, accuracy 0.843750 BatchTime 1.602277, for discriminator pretraining 
epoch 27, samples 253696, loss 0.491108, accuracy 0.859375 BatchTime 1.602797, for discriminator pretraining 
epoch 27, samples 253952, loss 0.523208, accuracy 0.843750 BatchTime 1.678257, for discriminator pretraining 
epoch 27, samples 254208, loss 0.659544, accuracy 0.871094 BatchTime 1.750000, for discriminator pretraining 
epoch 27, samples 254464, loss 0.588357, accuracy 0.847656 BatchTime 1.602125, for discriminator pretraining 
epoch 27, samples 254720, loss 0.655478, accuracy 0.843750 BatchTime 1.672212, for discriminator pretraining 
epoch 27, samples 254976, loss 0.776964, accuracy 0.820312 BatchTime 1.623510, for discriminator pretraining 
epoch 27, samples 255232, loss 0.859017, accuracy 0.800781 BatchTime 1.675492, for discriminator pretraining 
epoch 27, samples 255488, loss 1.124981, accuracy 0.773438 BatchTime 1.623759, for discriminator pretraining 
epoch 27, samples 255744, loss 0.960635, accuracy 0.820312 BatchTime 1.760490, for discriminator pretraining 
epoch 27, samples 256000, loss 0.913407, accuracy 0.812500 BatchTime 1.688770, for discriminator pretraining 
save params when epoch 27, samples 256000
testing the accuracy on the evaluation sets
epoch 27, samples 256256, loss 0.587853, accuracy 0.871094 BatchTime 1.685079, for discriminator pretraining 
epoch 27, samples 256512, loss 0.787294, accuracy 0.820312 BatchTime 1.631799, for discriminator pretraining 
epoch 27, samples 256768, loss 0.771028, accuracy 0.808594 BatchTime 1.766817, for discriminator pretraining 
epoch 27, samples 257024, loss 0.794105, accuracy 0.804688 BatchTime 1.699427, for discriminator pretraining 
epoch 27, samples 257280, loss 0.551583, accuracy 0.855469 BatchTime 1.716299, for discriminator pretraining 
epoch 27, samples 257536, loss 0.636306, accuracy 0.851562 BatchTime 1.624462, for discriminator pretraining 
epoch 27, samples 257792, loss 0.884505, accuracy 0.828125 BatchTime 1.696636, for discriminator pretraining 
epoch 27, samples 258048, loss 1.101918, accuracy 0.750000 BatchTime 0.859417, for discriminator pretraining 
Seen  9000  examples for discriminator. Time Cost :  65.56480121612549
load vocab successfully!!
Epoch : 28
epoch 28, samples 258304, loss 0.426148, accuracy 0.875000 BatchTime 2.697192, for discriminator pretraining 
epoch 28, samples 258560, loss 0.430423, accuracy 0.894531 BatchTime 1.771857, for discriminator pretraining 
epoch 28, samples 258816, loss 0.724655, accuracy 0.835938 BatchTime 1.653464, for discriminator pretraining 
epoch 28, samples 259072, loss 0.789819, accuracy 0.820312 BatchTime 1.626277, for discriminator pretraining 
epoch 28, samples 259328, loss 0.451549, accuracy 0.863281 BatchTime 1.665943, for discriminator pretraining 
epoch 28, samples 259584, loss 0.376497, accuracy 0.875000 BatchTime 1.771507, for discriminator pretraining 
epoch 28, samples 259840, loss 0.527442, accuracy 0.863281 BatchTime 1.762167, for discriminator pretraining 
epoch 28, samples 260096, loss 0.528749, accuracy 0.871094 BatchTime 1.624246, for discriminator pretraining 
epoch 28, samples 260352, loss 0.631198, accuracy 0.867188 BatchTime 1.655733, for discriminator pretraining 
epoch 28, samples 260608, loss 0.692615, accuracy 0.843750 BatchTime 1.628641, for discriminator pretraining 
epoch 28, samples 260864, loss 0.588313, accuracy 0.835938 BatchTime 1.747956, for discriminator pretraining 
epoch 28, samples 261120, loss 0.635646, accuracy 0.839844 BatchTime 1.726491, for discriminator pretraining 
epoch 28, samples 261376, loss 0.639678, accuracy 0.851562 BatchTime 1.658116, for discriminator pretraining 
epoch 28, samples 261632, loss 0.775178, accuracy 0.816406 BatchTime 1.617951, for discriminator pretraining 
epoch 28, samples 261888, loss 0.668909, accuracy 0.835938 BatchTime 1.697510, for discriminator pretraining 
epoch 28, samples 262144, loss 0.675071, accuracy 0.843750 BatchTime 1.621522, for discriminator pretraining 
epoch 28, samples 262400, loss 0.720715, accuracy 0.839844 BatchTime 1.660024, for discriminator pretraining 
epoch 28, samples 262656, loss 0.747896, accuracy 0.847656 BatchTime 1.757054, for discriminator pretraining 
epoch 28, samples 262912, loss 0.471253, accuracy 0.894531 BatchTime 1.772864, for discriminator pretraining 
epoch 28, samples 263168, loss 0.594611, accuracy 0.804688 BatchTime 1.633060, for discriminator pretraining 
epoch 28, samples 263424, loss 0.751191, accuracy 0.800781 BatchTime 1.647661, for discriminator pretraining 
epoch 28, samples 263680, loss 0.493945, accuracy 0.859375 BatchTime 1.618442, for discriminator pretraining 
epoch 28, samples 263936, loss 0.684794, accuracy 0.824219 BatchTime 1.698116, for discriminator pretraining 
epoch 28, samples 264192, loss 0.643573, accuracy 0.851562 BatchTime 1.746196, for discriminator pretraining 
epoch 28, samples 264448, loss 0.707548, accuracy 0.847656 BatchTime 1.714931, for discriminator pretraining 
epoch 28, samples 264704, loss 0.667385, accuracy 0.859375 BatchTime 1.618750, for discriminator pretraining 
epoch 28, samples 264960, loss 0.711478, accuracy 0.796875 BatchTime 1.644093, for discriminator pretraining 
epoch 28, samples 265216, loss 0.885897, accuracy 0.816406 BatchTime 1.614017, for discriminator pretraining 
epoch 28, samples 265472, loss 0.891190, accuracy 0.812500 BatchTime 1.667741, for discriminator pretraining 
epoch 28, samples 265728, loss 0.690480, accuracy 0.843750 BatchTime 1.634887, for discriminator pretraining 
epoch 28, samples 265984, loss 0.850390, accuracy 0.808594 BatchTime 1.654832, for discriminator pretraining 
epoch 28, samples 266240, loss 0.596865, accuracy 0.843750 BatchTime 1.650900, for discriminator pretraining 
epoch 28, samples 266496, loss 0.905573, accuracy 0.800781 BatchTime 1.673697, for discriminator pretraining 
epoch 28, samples 266752, loss 0.531947, accuracy 0.875000 BatchTime 1.719209, for discriminator pretraining 
epoch 28, samples 267008, loss 0.772438, accuracy 0.820312 BatchTime 1.752022, for discriminator pretraining 
epoch 28, samples 267264, loss 0.958350, accuracy 0.805556 BatchTime 0.874393, for discriminator pretraining 
Seen  8996  examples for discriminator. Time Cost :  59.79929828643799
load vocab successfully!!
Epoch : 29
epoch 29, samples 267520, loss 0.363713, accuracy 0.886719 BatchTime 2.658365, for discriminator pretraining 
epoch 29, samples 267776, loss 0.526558, accuracy 0.875000 BatchTime 1.773659, for discriminator pretraining 
epoch 29, samples 268032, loss 0.770820, accuracy 0.843750 BatchTime 1.725578, for discriminator pretraining 
epoch 29, samples 268288, loss 0.720615, accuracy 0.835938 BatchTime 1.643968, for discriminator pretraining 
epoch 29, samples 268544, loss 0.442834, accuracy 0.894531 BatchTime 1.776858, for discriminator pretraining 
epoch 29, samples 268800, loss 0.378187, accuracy 0.855469 BatchTime 1.768777, for discriminator pretraining 
epoch 29, samples 269056, loss 0.334887, accuracy 0.875000 BatchTime 1.692193, for discriminator pretraining 
epoch 29, samples 269312, loss 0.396606, accuracy 0.894531 BatchTime 1.636058, for discriminator pretraining 
epoch 29, samples 269568, loss 0.483495, accuracy 0.855469 BatchTime 1.705475, for discriminator pretraining 
epoch 29, samples 269824, loss 0.543096, accuracy 0.859375 BatchTime 1.633052, for discriminator pretraining 
epoch 29, samples 270080, loss 0.503586, accuracy 0.855469 BatchTime 1.701808, for discriminator pretraining 
epoch 29, samples 270336, loss 0.434452, accuracy 0.867188 BatchTime 1.621755, for discriminator pretraining 
epoch 29, samples 270592, loss 0.885078, accuracy 0.832031 BatchTime 1.700207, for discriminator pretraining 
epoch 29, samples 270848, loss 0.724222, accuracy 0.812500 BatchTime 1.668280, for discriminator pretraining 
epoch 29, samples 271104, loss 0.847209, accuracy 0.792969 BatchTime 1.707076, for discriminator pretraining 
epoch 29, samples 271360, loss 0.593926, accuracy 0.851562 BatchTime 1.649874, for discriminator pretraining 
epoch 29, samples 271616, loss 0.646414, accuracy 0.847656 BatchTime 1.745514, for discriminator pretraining 
epoch 29, samples 271872, loss 0.695623, accuracy 0.859375 BatchTime 1.698922, for discriminator pretraining 
epoch 29, samples 272128, loss 0.854360, accuracy 0.832031 BatchTime 1.704905, for discriminator pretraining 
epoch 29, samples 272384, loss 0.862980, accuracy 0.835938 BatchTime 1.623414, for discriminator pretraining 
epoch 29, samples 272640, loss 0.641351, accuracy 0.863281 BatchTime 1.802114, for discriminator pretraining 
epoch 29, samples 272896, loss 0.475466, accuracy 0.851562 BatchTime 1.740096, for discriminator pretraining 
epoch 29, samples 273152, loss 0.634238, accuracy 0.847656 BatchTime 1.697275, for discriminator pretraining 
epoch 29, samples 273408, loss 0.695751, accuracy 0.816406 BatchTime 1.622970, for discriminator pretraining 
epoch 29, samples 273664, loss 0.927333, accuracy 0.789062 BatchTime 1.695691, for discriminator pretraining 
epoch 29, samples 273920, loss 0.536049, accuracy 0.878906 BatchTime 1.619752, for discriminator pretraining 
epoch 29, samples 274176, loss 0.550125, accuracy 0.867188 BatchTime 1.715238, for discriminator pretraining 
epoch 29, samples 274432, loss 0.703561, accuracy 0.847656 BatchTime 1.691495, for discriminator pretraining 
epoch 29, samples 274688, loss 0.734084, accuracy 0.808594 BatchTime 1.793405, for discriminator pretraining 
epoch 29, samples 274944, loss 0.652734, accuracy 0.828125 BatchTime 1.591095, for discriminator pretraining 
epoch 29, samples 275200, loss 0.656038, accuracy 0.839844 BatchTime 1.643794, for discriminator pretraining 
epoch 29, samples 275456, loss 0.549669, accuracy 0.863281 BatchTime 1.618427, for discriminator pretraining 
epoch 29, samples 275712, loss 0.879897, accuracy 0.816406 BatchTime 1.641156, for discriminator pretraining 
epoch 29, samples 275968, loss 0.746413, accuracy 0.824219 BatchTime 1.607777, for discriminator pretraining 
epoch 29, samples 276224, loss 0.715303, accuracy 0.855469 BatchTime 1.701737, for discriminator pretraining 
epoch 29, samples 276480, loss 0.901445, accuracy 0.791667 BatchTime 0.828256, for discriminator pretraining 
Seen  8984  examples for discriminator. Time Cost :  60.020747423172
load vocab successfully!!
Epoch : 30
epoch 30, samples 276736, loss 0.343128, accuracy 0.882812 BatchTime 2.666311, for discriminator pretraining 
epoch 30, samples 276992, loss 0.389608, accuracy 0.882812 BatchTime 1.811043, for discriminator pretraining 
epoch 30, samples 277248, loss 0.550695, accuracy 0.859375 BatchTime 1.735776, for discriminator pretraining 
epoch 30, samples 277504, loss 0.421638, accuracy 0.902344 BatchTime 1.663721, for discriminator pretraining 
epoch 30, samples 277760, loss 0.485308, accuracy 0.867188 BatchTime 1.733185, for discriminator pretraining 
epoch 30, samples 278016, loss 0.532767, accuracy 0.843750 BatchTime 1.647303, for discriminator pretraining 
epoch 30, samples 278272, loss 0.735815, accuracy 0.828125 BatchTime 1.731855, for discriminator pretraining 
epoch 30, samples 278528, loss 0.661831, accuracy 0.839844 BatchTime 1.595227, for discriminator pretraining 
epoch 30, samples 278784, loss 0.825379, accuracy 0.808594 BatchTime 1.760904, for discriminator pretraining 
epoch 30, samples 279040, loss 0.835816, accuracy 0.824219 BatchTime 1.724245, for discriminator pretraining 
epoch 30, samples 279296, loss 0.614736, accuracy 0.835938 BatchTime 1.752622, for discriminator pretraining 
epoch 30, samples 279552, loss 0.649175, accuracy 0.832031 BatchTime 1.647178, for discriminator pretraining 
epoch 30, samples 279808, loss 0.689814, accuracy 0.851562 BatchTime 1.733313, for discriminator pretraining 
epoch 30, samples 280064, loss 0.544290, accuracy 0.847656 BatchTime 1.630459, for discriminator pretraining 
epoch 30, samples 280320, loss 0.534104, accuracy 0.859375 BatchTime 1.724018, for discriminator pretraining 
epoch 30, samples 280576, loss 0.627184, accuracy 0.859375 BatchTime 1.620183, for discriminator pretraining 
epoch 30, samples 280832, loss 0.909964, accuracy 0.843750 BatchTime 1.720139, for discriminator pretraining 
epoch 30, samples 281088, loss 0.523790, accuracy 0.875000 BatchTime 1.594552, for discriminator pretraining 
epoch 30, samples 281344, loss 0.480093, accuracy 0.847656 BatchTime 1.702699, for discriminator pretraining 
epoch 30, samples 281600, loss 0.570135, accuracy 0.851562 BatchTime 1.632042, for discriminator pretraining 
save params when epoch 30, samples 281600
epoch 30, samples 281856, loss 0.484373, accuracy 0.863281 BatchTime 1.781986, for discriminator pretraining 
epoch 30, samples 282112, loss 0.621622, accuracy 0.828125 BatchTime 1.763529, for discriminator pretraining 
epoch 30, samples 282368, loss 0.611654, accuracy 0.867188 BatchTime 1.802695, for discriminator pretraining 
epoch 30, samples 282624, loss 0.827018, accuracy 0.847656 BatchTime 1.643118, for discriminator pretraining 
epoch 30, samples 282880, loss 0.757442, accuracy 0.816406 BatchTime 1.721397, for discriminator pretraining 
epoch 30, samples 283136, loss 0.724296, accuracy 0.820312 BatchTime 1.649625, for discriminator pretraining 
epoch 30, samples 283392, loss 0.569083, accuracy 0.867188 BatchTime 1.684630, for discriminator pretraining 
epoch 30, samples 283648, loss 0.692695, accuracy 0.843750 BatchTime 1.605853, for discriminator pretraining 
epoch 30, samples 283904, loss 0.671692, accuracy 0.828125 BatchTime 1.716156, for discriminator pretraining 
epoch 30, samples 284160, loss 0.671557, accuracy 0.812500 BatchTime 1.613204, for discriminator pretraining 
epoch 30, samples 284416, loss 0.604338, accuracy 0.855469 BatchTime 1.741901, for discriminator pretraining 
epoch 30, samples 284672, loss 0.407314, accuracy 0.878906 BatchTime 1.621203, for discriminator pretraining 
epoch 30, samples 284928, loss 0.605617, accuracy 0.847656 BatchTime 2.035955, for discriminator pretraining 
epoch 30, samples 285184, loss 0.906296, accuracy 0.820312 BatchTime 1.748430, for discriminator pretraining 
epoch 30, samples 285440, loss 0.510725, accuracy 0.875000 BatchTime 1.731733, for discriminator pretraining 
epoch 30, samples 285696, loss 0.302285, accuracy 0.937500 BatchTime 0.852325, for discriminator pretraining 
Seen  8992  examples for discriminator. Time Cost :  66.73296761512756
mv: cannot stat 'prepare_data/good_train_clean.dst.5000.shuf': No such file or directory
load vocab successfully!!
Epoch : 31
epoch 31, samples 285952, loss 0.332113, accuracy 0.906250 BatchTime 2.430947, for discriminator pretraining 
epoch 31, samples 286208, loss 0.403833, accuracy 0.875000 BatchTime 1.753472, for discriminator pretraining 
epoch 31, samples 286464, loss 0.591568, accuracy 0.820312 BatchTime 1.829065, for discriminator pretraining 
epoch 31, samples 286720, loss 0.649518, accuracy 0.847656 BatchTime 1.768480, for discriminator pretraining 
epoch 31, samples 286976, loss 0.842399, accuracy 0.843750 BatchTime 1.751805, for discriminator pretraining 
epoch 31, samples 287232, loss 0.842931, accuracy 0.816406 BatchTime 1.634041, for discriminator pretraining 
epoch 31, samples 287488, loss 0.593502, accuracy 0.894531 BatchTime 1.716419, for discriminator pretraining 
epoch 31, samples 287744, loss 0.517542, accuracy 0.886719 BatchTime 1.602591, for discriminator pretraining 
epoch 31, samples 288000, loss 0.660441, accuracy 0.808594 BatchTime 1.709086, for discriminator pretraining 
epoch 31, samples 288256, loss 0.735378, accuracy 0.839844 BatchTime 1.648848, for discriminator pretraining 
epoch 31, samples 288512, loss 0.633441, accuracy 0.882812 BatchTime 1.714237, for discriminator pretraining 
epoch 31, samples 288768, loss 0.575524, accuracy 0.835938 BatchTime 1.626722, for discriminator pretraining 
epoch 31, samples 289024, loss 0.843451, accuracy 0.820312 BatchTime 1.697814, for discriminator pretraining 
epoch 31, samples 289280, loss 0.900011, accuracy 0.808594 BatchTime 1.643255, for discriminator pretraining 
epoch 31, samples 289536, loss 0.696948, accuracy 0.871094 BatchTime 1.669542, for discriminator pretraining 
epoch 31, samples 289792, loss 0.785614, accuracy 0.835938 BatchTime 1.729544, for discriminator pretraining 
epoch 31, samples 290048, loss 0.871690, accuracy 0.816406 BatchTime 1.767230, for discriminator pretraining 
epoch 31, samples 290304, loss 0.522240, accuracy 0.882812 BatchTime 1.650145, for discriminator pretraining 
epoch 31, samples 290560, loss 0.467605, accuracy 0.851562 BatchTime 1.741945, for discriminator pretraining 
epoch 31, samples 290816, loss 0.662851, accuracy 0.847656 BatchTime 1.750430, for discriminator pretraining 
epoch 31, samples 291072, loss 0.702846, accuracy 0.835938 BatchTime 1.760311, for discriminator pretraining 
epoch 31, samples 291328, loss 0.968294, accuracy 0.808594 BatchTime 1.630774, for discriminator pretraining 
epoch 31, samples 291584, loss 0.669558, accuracy 0.847656 BatchTime 1.658049, for discriminator pretraining 
epoch 31, samples 291840, loss 0.819868, accuracy 0.816406 BatchTime 1.621249, for discriminator pretraining 
epoch 31, samples 292096, loss 0.847630, accuracy 0.816406 BatchTime 1.619891, for discriminator pretraining 
epoch 31, samples 292352, loss 0.866405, accuracy 0.824219 BatchTime 1.600208, for discriminator pretraining 
epoch 31, samples 292608, loss 0.882216, accuracy 0.808594 BatchTime 1.648211, for discriminator pretraining 
epoch 31, samples 292864, loss 0.674195, accuracy 0.820312 BatchTime 1.662340, for discriminator pretraining 
epoch 31, samples 293120, loss 0.739051, accuracy 0.808594 BatchTime 1.709675, for discriminator pretraining 
epoch 31, samples 293376, loss 0.724612, accuracy 0.832031 BatchTime 1.649704, for discriminator pretraining 
epoch 31, samples 293632, loss 0.732343, accuracy 0.835938 BatchTime 1.638255, for discriminator pretraining 
epoch 31, samples 293888, loss 0.704489, accuracy 0.835938 BatchTime 1.618281, for discriminator pretraining 
epoch 31, samples 294144, loss 0.782320, accuracy 0.835938 BatchTime 1.639562, for discriminator pretraining 
epoch 31, samples 294400, loss 0.708654, accuracy 0.824219 BatchTime 1.621952, for discriminator pretraining 
epoch 31, samples 294656, loss 0.424046, accuracy 0.863281 BatchTime 1.658098, for discriminator pretraining 
epoch 31, samples 294912, loss 0.562171, accuracy 0.833333 BatchTime 0.825235, for discriminator pretraining 
Seen  8990  examples for discriminator. Time Cost :  59.71020197868347
load vocab successfully!!
Epoch : 32
epoch 32, samples 295168, loss 0.413357, accuracy 0.886719 BatchTime 2.510489, for discriminator pretraining 
epoch 32, samples 295424, loss 0.436997, accuracy 0.878906 BatchTime 1.838865, for discriminator pretraining 
epoch 32, samples 295680, loss 0.438012, accuracy 0.882812 BatchTime 1.800612, for discriminator pretraining 
epoch 32, samples 295936, loss 0.615577, accuracy 0.855469 BatchTime 1.704265, for discriminator pretraining 
epoch 32, samples 296192, loss 0.606463, accuracy 0.855469 BatchTime 1.700765, for discriminator pretraining 
epoch 32, samples 296448, loss 0.674631, accuracy 0.847656 BatchTime 1.731340, for discriminator pretraining 
epoch 32, samples 296704, loss 0.932337, accuracy 0.800781 BatchTime 1.691359, for discriminator pretraining 
epoch 32, samples 296960, loss 0.679200, accuracy 0.832031 BatchTime 1.628638, for discriminator pretraining 
epoch 32, samples 297216, loss 0.428518, accuracy 0.890625 BatchTime 1.658242, for discriminator pretraining 
epoch 32, samples 297472, loss 0.439699, accuracy 0.878906 BatchTime 1.611195, for discriminator pretraining 
epoch 32, samples 297728, loss 0.588937, accuracy 0.863281 BatchTime 1.669005, for discriminator pretraining 
epoch 32, samples 297984, loss 0.668267, accuracy 0.828125 BatchTime 1.627013, for discriminator pretraining 
epoch 32, samples 298240, loss 0.726464, accuracy 0.839844 BatchTime 1.741569, for discriminator pretraining 
epoch 32, samples 298496, loss 0.700797, accuracy 0.847656 BatchTime 1.736977, for discriminator pretraining 
epoch 32, samples 298752, loss 0.364737, accuracy 0.882812 BatchTime 1.731275, for discriminator pretraining 
epoch 32, samples 299008, loss 0.618224, accuracy 0.835938 BatchTime 1.608662, for discriminator pretraining 
epoch 32, samples 299264, loss 0.688367, accuracy 0.816406 BatchTime 1.700087, for discriminator pretraining 
epoch 32, samples 299520, loss 0.940213, accuracy 0.800781 BatchTime 1.636661, for discriminator pretraining 
epoch 32, samples 299776, loss 0.607722, accuracy 0.855469 BatchTime 1.763651, for discriminator pretraining 
epoch 32, samples 300032, loss 0.742965, accuracy 0.839844 BatchTime 1.730409, for discriminator pretraining 
epoch 32, samples 300288, loss 0.532149, accuracy 0.855469 BatchTime 1.727524, for discriminator pretraining 
epoch 32, samples 300544, loss 0.415321, accuracy 0.886719 BatchTime 1.625215, for discriminator pretraining 
epoch 32, samples 300800, loss 0.668400, accuracy 0.835938 BatchTime 1.688188, for discriminator pretraining 
epoch 32, samples 301056, loss 0.649234, accuracy 0.832031 BatchTime 1.640274, for discriminator pretraining 
epoch 32, samples 301312, loss 0.867388, accuracy 0.808594 BatchTime 1.701072, for discriminator pretraining 
epoch 32, samples 301568, loss 1.009135, accuracy 0.808594 BatchTime 1.615995, for discriminator pretraining 
epoch 32, samples 301824, loss 0.966762, accuracy 0.816406 BatchTime 1.722974, for discriminator pretraining 
epoch 32, samples 302080, loss 0.841307, accuracy 0.816406 BatchTime 1.637675, for discriminator pretraining 
epoch 32, samples 302336, loss 0.769908, accuracy 0.812500 BatchTime 1.747747, for discriminator pretraining 
epoch 32, samples 302592, loss 0.626810, accuracy 0.851562 BatchTime 1.758171, for discriminator pretraining 
epoch 32, samples 302848, loss 0.713528, accuracy 0.828125 BatchTime 1.749503, for discriminator pretraining 
epoch 32, samples 303104, loss 0.691764, accuracy 0.843750 BatchTime 1.646279, for discriminator pretraining 
epoch 32, samples 303360, loss 0.840914, accuracy 0.835938 BatchTime 1.762782, for discriminator pretraining 
epoch 32, samples 303616, loss 0.800617, accuracy 0.812500 BatchTime 1.762447, for discriminator pretraining 
epoch 32, samples 303872, loss 0.649213, accuracy 0.847656 BatchTime 1.722290, for discriminator pretraining 
epoch 32, samples 304128, loss 0.771453, accuracy 0.785714 BatchTime 0.837995, for discriminator pretraining 
Seen  8988  examples for discriminator. Time Cost :  60.4853515625
load vocab successfully!!
Epoch : 33
epoch 33, samples 304384, loss 0.608844, accuracy 0.812500 BatchTime 2.646519, for discriminator pretraining 
epoch 33, samples 304640, loss 0.664766, accuracy 0.824219 BatchTime 1.755355, for discriminator pretraining 
epoch 33, samples 304896, loss 0.355682, accuracy 0.890625 BatchTime 1.737519, for discriminator pretraining 
epoch 33, samples 305152, loss 0.443560, accuracy 0.867188 BatchTime 1.767134, for discriminator pretraining 
epoch 33, samples 305408, loss 0.489398, accuracy 0.859375 BatchTime 1.736837, for discriminator pretraining 
epoch 33, samples 305664, loss 0.423867, accuracy 0.902344 BatchTime 1.613485, for discriminator pretraining 
epoch 33, samples 305920, loss 0.517640, accuracy 0.871094 BatchTime 1.647200, for discriminator pretraining 
epoch 33, samples 306176, loss 0.513077, accuracy 0.875000 BatchTime 1.611046, for discriminator pretraining 
epoch 33, samples 306432, loss 0.690018, accuracy 0.843750 BatchTime 1.710196, for discriminator pretraining 
epoch 33, samples 306688, loss 0.549799, accuracy 0.863281 BatchTime 1.701553, for discriminator pretraining 
epoch 33, samples 306944, loss 0.479229, accuracy 0.867188 BatchTime 1.731498, for discriminator pretraining 
epoch 33, samples 307200, loss 0.683321, accuracy 0.843750 BatchTime 1.684623, for discriminator pretraining 
save params when epoch 33, samples 307200
epoch 33, samples 307456, loss 0.703407, accuracy 0.824219 BatchTime 1.729180, for discriminator pretraining 
epoch 33, samples 307712, loss 0.496483, accuracy 0.859375 BatchTime 1.652492, for discriminator pretraining 
epoch 33, samples 307968, loss 0.485308, accuracy 0.867188 BatchTime 1.683970, for discriminator pretraining 
epoch 33, samples 308224, loss 0.806495, accuracy 0.820312 BatchTime 1.624237, for discriminator pretraining 
epoch 33, samples 308480, loss 0.582515, accuracy 0.847656 BatchTime 1.693199, for discriminator pretraining 
epoch 33, samples 308736, loss 0.819412, accuracy 0.824219 BatchTime 1.632666, for discriminator pretraining 
epoch 33, samples 308992, loss 0.712700, accuracy 0.855469 BatchTime 1.725027, for discriminator pretraining 
epoch 33, samples 309248, loss 0.545759, accuracy 0.859375 BatchTime 1.663042, for discriminator pretraining 
epoch 33, samples 309504, loss 0.635209, accuracy 0.835938 BatchTime 1.640786, for discriminator pretraining 
epoch 33, samples 309760, loss 0.543687, accuracy 0.875000 BatchTime 1.603421, for discriminator pretraining 
epoch 33, samples 310016, loss 0.775404, accuracy 0.820312 BatchTime 1.717813, for discriminator pretraining 
epoch 33, samples 310272, loss 0.711188, accuracy 0.824219 BatchTime 1.733642, for discriminator pretraining 
epoch 33, samples 310528, loss 0.787631, accuracy 0.828125 BatchTime 1.700759, for discriminator pretraining 
epoch 33, samples 310784, loss 0.571335, accuracy 0.851562 BatchTime 1.602267, for discriminator pretraining 
epoch 33, samples 311040, loss 0.496201, accuracy 0.847656 BatchTime 1.698646, for discriminator pretraining 
epoch 33, samples 311296, loss 0.484145, accuracy 0.894531 BatchTime 1.629349, for discriminator pretraining 
epoch 33, samples 311552, loss 0.847728, accuracy 0.812500 BatchTime 1.769096, for discriminator pretraining 
epoch 33, samples 311808, loss 0.733624, accuracy 0.824219 BatchTime 1.755042, for discriminator pretraining 
epoch 33, samples 312064, loss 1.050341, accuracy 0.753906 BatchTime 1.697066, for discriminator pretraining 
epoch 33, samples 312320, loss 0.908544, accuracy 0.800781 BatchTime 1.626759, for discriminator pretraining 
epoch 33, samples 312576, loss 0.642698, accuracy 0.851562 BatchTime 1.771417, for discriminator pretraining 
epoch 33, samples 312832, loss 0.482685, accuracy 0.863281 BatchTime 1.735965, for discriminator pretraining 
epoch 33, samples 313088, loss 0.581086, accuracy 0.863281 BatchTime 1.724724, for discriminator pretraining 
epoch 33, samples 313344, loss 1.018585, accuracy 0.800000 BatchTime 0.841510, for discriminator pretraining 
Seen  8990  examples for discriminator. Time Cost :  66.19638204574585
load vocab successfully!!
Epoch : 34
epoch 34, samples 313600, loss 0.589638, accuracy 0.839844 BatchTime 2.493513, for discriminator pretraining 
epoch 34, samples 313856, loss 0.709776, accuracy 0.812500 BatchTime 1.756128, for discriminator pretraining 
epoch 34, samples 314112, loss 0.475349, accuracy 0.855469 BatchTime 1.679273, for discriminator pretraining 
epoch 34, samples 314368, loss 0.454409, accuracy 0.871094 BatchTime 1.681431, for discriminator pretraining 
epoch 34, samples 314624, loss 0.522918, accuracy 0.859375 BatchTime 1.686975, for discriminator pretraining 
epoch 34, samples 314880, loss 0.535457, accuracy 0.882812 BatchTime 1.671497, for discriminator pretraining 
epoch 34, samples 315136, loss 0.461769, accuracy 0.890625 BatchTime 1.684080, for discriminator pretraining 
epoch 34, samples 315392, loss 0.555699, accuracy 0.820312 BatchTime 1.618915, for discriminator pretraining 
epoch 34, samples 315648, loss 0.434888, accuracy 0.882812 BatchTime 1.664505, for discriminator pretraining 
epoch 34, samples 315904, loss 0.389863, accuracy 0.875000 BatchTime 1.572998, for discriminator pretraining 
epoch 34, samples 316160, loss 0.785106, accuracy 0.835938 BatchTime 1.599263, for discriminator pretraining 
epoch 34, samples 316416, loss 0.760898, accuracy 0.828125 BatchTime 1.675544, for discriminator pretraining 
epoch 34, samples 316672, loss 0.552811, accuracy 0.878906 BatchTime 1.633019, for discriminator pretraining 
epoch 34, samples 316928, loss 0.500590, accuracy 0.871094 BatchTime 1.646055, for discriminator pretraining 
epoch 34, samples 317184, loss 0.637939, accuracy 0.843750 BatchTime 1.616775, for discriminator pretraining 
epoch 34, samples 317440, loss 0.656924, accuracy 0.812500 BatchTime 1.711225, for discriminator pretraining 
epoch 34, samples 317696, loss 0.647019, accuracy 0.832031 BatchTime 1.752228, for discriminator pretraining 
epoch 34, samples 317952, loss 0.492695, accuracy 0.875000 BatchTime 1.654357, for discriminator pretraining 
epoch 34, samples 318208, loss 0.602303, accuracy 0.832031 BatchTime 1.619751, for discriminator pretraining 
epoch 34, samples 318464, loss 0.316575, accuracy 0.882812 BatchTime 1.637578, for discriminator pretraining 
epoch 34, samples 318720, loss 0.739064, accuracy 0.824219 BatchTime 1.629863, for discriminator pretraining 
epoch 34, samples 318976, loss 0.535605, accuracy 0.859375 BatchTime 1.654817, for discriminator pretraining 
epoch 34, samples 319232, loss 0.815697, accuracy 0.804688 BatchTime 1.717530, for discriminator pretraining 
epoch 34, samples 319488, loss 0.967868, accuracy 0.789062 BatchTime 1.627343, for discriminator pretraining 
epoch 34, samples 319744, loss 0.913010, accuracy 0.816406 BatchTime 1.597800, for discriminator pretraining 
epoch 34, samples 320000, loss 0.868376, accuracy 0.816406 BatchTime 1.619252, for discriminator pretraining 
epoch 34, samples 320256, loss 0.597257, accuracy 0.859375 BatchTime 1.616852, for discriminator pretraining 
epoch 34, samples 320512, loss 0.660208, accuracy 0.835938 BatchTime 1.615628, for discriminator pretraining 
epoch 34, samples 320768, loss 0.514374, accuracy 0.875000 BatchTime 1.609560, for discriminator pretraining 
epoch 34, samples 321024, loss 0.642705, accuracy 0.828125 BatchTime 1.619702, for discriminator pretraining 
epoch 34, samples 321280, loss 0.741667, accuracy 0.839844 BatchTime 1.613269, for discriminator pretraining 
epoch 34, samples 321536, loss 0.812021, accuracy 0.828125 BatchTime 1.637054, for discriminator pretraining 
epoch 34, samples 321792, loss 0.714221, accuracy 0.859375 BatchTime 1.709863, for discriminator pretraining 
epoch 34, samples 322048, loss 0.567269, accuracy 0.847656 BatchTime 1.665230, for discriminator pretraining 
epoch 34, samples 322304, loss 0.625253, accuracy 0.839844 BatchTime 1.647727, for discriminator pretraining 
epoch 34, samples 322560, loss 0.470440, accuracy 0.852941 BatchTime 7.092019, for discriminator pretraining 
Seen  8994  examples for discriminator. Time Cost :  65.04284024238586
mv: cannot stat 'prepare_data/good_train_clean.dst.5000.shuf': No such file or directory
load vocab successfully!!
Epoch : 35
epoch 35, samples 322816, loss 0.369092, accuracy 0.871094 BatchTime 2.558925, for discriminator pretraining 
epoch 35, samples 323072, loss 0.555914, accuracy 0.851562 BatchTime 1.845431, for discriminator pretraining 
epoch 35, samples 323328, loss 0.502121, accuracy 0.859375 BatchTime 1.610911, for discriminator pretraining 
epoch 35, samples 323584, loss 0.651400, accuracy 0.812500 BatchTime 1.570177, for discriminator pretraining 
epoch 35, samples 323840, loss 0.638210, accuracy 0.847656 BatchTime 1.641506, for discriminator pretraining 
epoch 35, samples 324096, loss 0.734664, accuracy 0.839844 BatchTime 1.706957, for discriminator pretraining 
epoch 35, samples 324352, loss 0.653189, accuracy 0.847656 BatchTime 1.685495, for discriminator pretraining 
epoch 35, samples 324608, loss 0.966206, accuracy 0.816406 BatchTime 1.627782, for discriminator pretraining 
epoch 35, samples 324864, loss 0.579783, accuracy 0.867188 BatchTime 1.664376, for discriminator pretraining 
epoch 35, samples 325120, loss 0.601307, accuracy 0.863281 BatchTime 1.653514, for discriminator pretraining 
epoch 35, samples 325376, loss 0.744786, accuracy 0.820312 BatchTime 1.664406, for discriminator pretraining 
epoch 35, samples 325632, loss 0.541965, accuracy 0.890625 BatchTime 1.622239, for discriminator pretraining 
epoch 35, samples 325888, loss 0.477103, accuracy 0.871094 BatchTime 1.614798, for discriminator pretraining 
epoch 35, samples 326144, loss 0.600284, accuracy 0.847656 BatchTime 1.643432, for discriminator pretraining 
epoch 35, samples 326400, loss 0.674057, accuracy 0.859375 BatchTime 1.731806, for discriminator pretraining 
epoch 35, samples 326656, loss 0.841994, accuracy 0.800781 BatchTime 1.770502, for discriminator pretraining 
epoch 35, samples 326912, loss 0.885198, accuracy 0.816406 BatchTime 1.691120, for discriminator pretraining 
epoch 35, samples 327168, loss 0.491327, accuracy 0.867188 BatchTime 1.653873, for discriminator pretraining 
epoch 35, samples 327424, loss 0.635790, accuracy 0.847656 BatchTime 1.626172, for discriminator pretraining 
epoch 35, samples 327680, loss 0.513198, accuracy 0.871094 BatchTime 1.632985, for discriminator pretraining 
epoch 35, samples 327936, loss 1.035253, accuracy 0.789062 BatchTime 1.688483, for discriminator pretraining 
epoch 35, samples 328192, loss 0.394501, accuracy 0.882812 BatchTime 1.738983, for discriminator pretraining 
epoch 35, samples 328448, loss 0.667939, accuracy 0.832031 BatchTime 1.686834, for discriminator pretraining 
epoch 35, samples 328704, loss 0.749120, accuracy 0.804688 BatchTime 1.641018, for discriminator pretraining 
epoch 35, samples 328960, loss 0.574113, accuracy 0.855469 BatchTime 1.632808, for discriminator pretraining 
epoch 35, samples 329216, loss 0.452433, accuracy 0.871094 BatchTime 1.627103, for discriminator pretraining 
epoch 35, samples 329472, loss 0.574113, accuracy 0.859375 BatchTime 1.622672, for discriminator pretraining 
epoch 35, samples 329728, loss 0.691163, accuracy 0.816406 BatchTime 1.619169, for discriminator pretraining 
epoch 35, samples 329984, loss 0.492617, accuracy 0.859375 BatchTime 1.640842, for discriminator pretraining 
epoch 35, samples 330240, loss 0.696157, accuracy 0.835938 BatchTime 1.601002, for discriminator pretraining 
epoch 35, samples 330496, loss 0.733530, accuracy 0.824219 BatchTime 1.865099, for discriminator pretraining 
epoch 35, samples 330752, loss 0.595826, accuracy 0.851562 BatchTime 1.735402, for discriminator pretraining 
epoch 35, samples 331008, loss 0.570157, accuracy 0.843750 BatchTime 1.622455, for discriminator pretraining 
epoch 35, samples 331264, loss 1.109771, accuracy 0.816406 BatchTime 1.665439, for discriminator pretraining 
epoch 35, samples 331520, loss 0.872416, accuracy 0.796875 BatchTime 1.625798, for discriminator pretraining 
epoch 35, samples 331776, loss 0.816082, accuracy 0.805556 BatchTime 0.823133, for discriminator pretraining 
Seen  8996  examples for discriminator. Time Cost :  59.33262038230896
load vocab successfully!!
Epoch : 36
epoch 36, samples 332032, loss 0.633677, accuracy 0.843750 BatchTime 2.562863, for discriminator pretraining 
epoch 36, samples 332288, loss 0.332621, accuracy 0.886719 BatchTime 1.757178, for discriminator pretraining 
epoch 36, samples 332544, loss 0.576793, accuracy 0.878906 BatchTime 1.690828, for discriminator pretraining 
epoch 36, samples 332800, loss 0.741378, accuracy 0.812500 BatchTime 1.638291, for discriminator pretraining 
save params when epoch 36, samples 332800
epoch 36, samples 333056, loss 0.601703, accuracy 0.843750 BatchTime 1.743749, for discriminator pretraining 
epoch 36, samples 333312, loss 0.475570, accuracy 0.863281 BatchTime 1.753376, for discriminator pretraining 
epoch 36, samples 333568, loss 0.526737, accuracy 0.871094 BatchTime 1.715363, for discriminator pretraining 
epoch 36, samples 333824, loss 0.329976, accuracy 0.882812 BatchTime 1.593434, for discriminator pretraining 
epoch 36, samples 334080, loss 0.541838, accuracy 0.859375 BatchTime 1.631416, for discriminator pretraining 
epoch 36, samples 334336, loss 0.384061, accuracy 0.882812 BatchTime 1.693820, for discriminator pretraining 
epoch 36, samples 334592, loss 0.422275, accuracy 0.886719 BatchTime 1.742648, for discriminator pretraining 
epoch 36, samples 334848, loss 0.559051, accuracy 0.863281 BatchTime 1.650145, for discriminator pretraining 
epoch 36, samples 335104, loss 0.633828, accuracy 0.851562 BatchTime 1.605248, for discriminator pretraining 
epoch 36, samples 335360, loss 0.581669, accuracy 0.835938 BatchTime 1.612329, for discriminator pretraining 
epoch 36, samples 335616, loss 0.619039, accuracy 0.867188 BatchTime 1.661588, for discriminator pretraining 
epoch 36, samples 335872, loss 0.493754, accuracy 0.859375 BatchTime 1.749079, for discriminator pretraining 
epoch 36, samples 336128, loss 0.476321, accuracy 0.902344 BatchTime 1.773867, for discriminator pretraining 
epoch 36, samples 336384, loss 0.563312, accuracy 0.843750 BatchTime 1.634718, for discriminator pretraining 
epoch 36, samples 336640, loss 0.637041, accuracy 0.859375 BatchTime 1.692810, for discriminator pretraining 
epoch 36, samples 336896, loss 0.825816, accuracy 0.832031 BatchTime 1.674014, for discriminator pretraining 
epoch 36, samples 337152, loss 0.555066, accuracy 0.851562 BatchTime 1.646373, for discriminator pretraining 
epoch 36, samples 337408, loss 0.603691, accuracy 0.859375 BatchTime 1.750929, for discriminator pretraining 
epoch 36, samples 337664, loss 0.634917, accuracy 0.851562 BatchTime 1.695382, for discriminator pretraining 
epoch 36, samples 337920, loss 0.591543, accuracy 0.859375 BatchTime 1.665283, for discriminator pretraining 
epoch 36, samples 338176, loss 0.685719, accuracy 0.824219 BatchTime 1.604561, for discriminator pretraining 
epoch 36, samples 338432, loss 0.607811, accuracy 0.847656 BatchTime 1.577331, for discriminator pretraining 
epoch 36, samples 338688, loss 0.461630, accuracy 0.867188 BatchTime 1.594608, for discriminator pretraining 
epoch 36, samples 338944, loss 0.641786, accuracy 0.835938 BatchTime 1.722256, for discriminator pretraining 
epoch 36, samples 339200, loss 0.671170, accuracy 0.839844 BatchTime 1.775149, for discriminator pretraining 
epoch 36, samples 339456, loss 0.938201, accuracy 0.816406 BatchTime 1.640817, for discriminator pretraining 
epoch 36, samples 339712, loss 0.604832, accuracy 0.835938 BatchTime 1.620261, for discriminator pretraining 
epoch 36, samples 339968, loss 0.601236, accuracy 0.792969 BatchTime 1.591919, for discriminator pretraining 
epoch 36, samples 340224, loss 0.844416, accuracy 0.824219 BatchTime 1.614259, for discriminator pretraining 
epoch 36, samples 340480, loss 0.875480, accuracy 0.824219 BatchTime 1.621671, for discriminator pretraining 
epoch 36, samples 340736, loss 0.663488, accuracy 0.847656 BatchTime 1.632037, for discriminator pretraining 
epoch 36, samples 340992, loss 1.466076, accuracy 0.823529 BatchTime 0.905263, for discriminator pretraining 
Seen  8994  examples for discriminator. Time Cost :  65.25869965553284
load vocab successfully!!
Epoch : 37
epoch 37, samples 341248, loss 0.352443, accuracy 0.910156 BatchTime 2.716214, for discriminator pretraining 
epoch 37, samples 341504, loss 0.538367, accuracy 0.855469 BatchTime 1.803769, for discriminator pretraining 
epoch 37, samples 341760, loss 0.643556, accuracy 0.847656 BatchTime 1.659912, for discriminator pretraining 
epoch 37, samples 342016, loss 0.557691, accuracy 0.867188 BatchTime 1.660800, for discriminator pretraining 
epoch 37, samples 342272, loss 0.387197, accuracy 0.871094 BatchTime 1.573239, for discriminator pretraining 
epoch 37, samples 342528, loss 0.423476, accuracy 0.863281 BatchTime 1.616756, for discriminator pretraining 
epoch 37, samples 342784, loss 0.669569, accuracy 0.859375 BatchTime 1.632036, for discriminator pretraining 
epoch 37, samples 343040, loss 0.827537, accuracy 0.835938 BatchTime 1.741153, for discriminator pretraining 
epoch 37, samples 343296, loss 0.708922, accuracy 0.855469 BatchTime 1.716707, for discriminator pretraining 
epoch 37, samples 343552, loss 0.628891, accuracy 0.859375 BatchTime 1.629811, for discriminator pretraining 
epoch 37, samples 343808, loss 0.637638, accuracy 0.839844 BatchTime 1.593307, for discriminator pretraining 
epoch 37, samples 344064, loss 0.688316, accuracy 0.835938 BatchTime 1.611995, for discriminator pretraining 
epoch 37, samples 344320, loss 0.637830, accuracy 0.855469 BatchTime 1.628274, for discriminator pretraining 
epoch 37, samples 344576, loss 0.471993, accuracy 0.878906 BatchTime 1.729089, for discriminator pretraining 
epoch 37, samples 344832, loss 0.601793, accuracy 0.851562 BatchTime 1.656586, for discriminator pretraining 
epoch 37, samples 345088, loss 0.751492, accuracy 0.835938 BatchTime 1.634239, for discriminator pretraining 
epoch 37, samples 345344, loss 0.576304, accuracy 0.847656 BatchTime 1.624823, for discriminator pretraining 
epoch 37, samples 345600, loss 0.468481, accuracy 0.882812 BatchTime 1.639629, for discriminator pretraining 
epoch 37, samples 345856, loss 0.424364, accuracy 0.886719 BatchTime 1.630032, for discriminator pretraining 
epoch 37, samples 346112, loss 0.481097, accuracy 0.875000 BatchTime 1.713796, for discriminator pretraining 
epoch 37, samples 346368, loss 0.631129, accuracy 0.843750 BatchTime 1.731018, for discriminator pretraining 
epoch 37, samples 346624, loss 0.500201, accuracy 0.855469 BatchTime 1.676579, for discriminator pretraining 
epoch 37, samples 346880, loss 0.666603, accuracy 0.843750 BatchTime 1.625506, for discriminator pretraining 
epoch 37, samples 347136, loss 0.658084, accuracy 0.859375 BatchTime 1.627784, for discriminator pretraining 
epoch 37, samples 347392, loss 0.663659, accuracy 0.847656 BatchTime 1.635731, for discriminator pretraining 
epoch 37, samples 347648, loss 0.631269, accuracy 0.847656 BatchTime 1.641894, for discriminator pretraining 
epoch 37, samples 347904, loss 0.570022, accuracy 0.847656 BatchTime 1.732038, for discriminator pretraining 
epoch 37, samples 348160, loss 0.803398, accuracy 0.839844 BatchTime 1.727709, for discriminator pretraining 
epoch 37, samples 348416, loss 0.795945, accuracy 0.832031 BatchTime 1.679750, for discriminator pretraining 
epoch 37, samples 348672, loss 0.663036, accuracy 0.859375 BatchTime 1.616740, for discriminator pretraining 
epoch 37, samples 348928, loss 0.626992, accuracy 0.828125 BatchTime 1.613912, for discriminator pretraining 
epoch 37, samples 349184, loss 0.843037, accuracy 0.832031 BatchTime 1.691165, for discriminator pretraining 
epoch 37, samples 349440, loss 0.628010, accuracy 0.863281 BatchTime 1.623265, for discriminator pretraining 
epoch 37, samples 349696, loss 0.636662, accuracy 0.859375 BatchTime 1.658317, for discriminator pretraining 
epoch 37, samples 349952, loss 0.824684, accuracy 0.781250 BatchTime 1.738408, for discriminator pretraining 
epoch 37, samples 350208, loss 1.305885, accuracy 0.750000 BatchTime 0.946097, for discriminator pretraining 
Seen  9000  examples for discriminator. Time Cost :  59.31749129295349
load vocab successfully!!
Epoch : 38
epoch 38, samples 350464, loss 0.463272, accuracy 0.882812 BatchTime 2.588880, for discriminator pretraining 
epoch 38, samples 350720, loss 0.461578, accuracy 0.882812 BatchTime 1.767155, for discriminator pretraining 
epoch 38, samples 350976, loss 0.433949, accuracy 0.882812 BatchTime 1.702313, for discriminator pretraining 
epoch 38, samples 351232, loss 0.639890, accuracy 0.792969 BatchTime 1.753041, for discriminator pretraining 
epoch 38, samples 351488, loss 0.413747, accuracy 0.871094 BatchTime 1.689987, for discriminator pretraining 
epoch 38, samples 351744, loss 0.475512, accuracy 0.878906 BatchTime 1.616676, for discriminator pretraining 
epoch 38, samples 352000, loss 0.473016, accuracy 0.871094 BatchTime 1.615355, for discriminator pretraining 
epoch 38, samples 352256, loss 0.646818, accuracy 0.851562 BatchTime 1.634807, for discriminator pretraining 
epoch 38, samples 352512, loss 0.597494, accuracy 0.855469 BatchTime 1.615034, for discriminator pretraining 
epoch 38, samples 352768, loss 0.443978, accuracy 0.859375 BatchTime 1.637941, for discriminator pretraining 
epoch 38, samples 353024, loss 0.523555, accuracy 0.847656 BatchTime 1.631667, for discriminator pretraining 
epoch 38, samples 353280, loss 0.805817, accuracy 0.832031 BatchTime 1.676315, for discriminator pretraining 
epoch 38, samples 353536, loss 0.555893, accuracy 0.871094 BatchTime 1.774511, for discriminator pretraining 
epoch 38, samples 353792, loss 0.387396, accuracy 0.878906 BatchTime 1.680377, for discriminator pretraining 
epoch 38, samples 354048, loss 0.604051, accuracy 0.863281 BatchTime 1.594126, for discriminator pretraining 
epoch 38, samples 354304, loss 0.538336, accuracy 0.839844 BatchTime 1.623672, for discriminator pretraining 
epoch 38, samples 354560, loss 0.551870, accuracy 0.847656 BatchTime 1.639083, for discriminator pretraining 
epoch 38, samples 354816, loss 0.666581, accuracy 0.855469 BatchTime 1.618244, for discriminator pretraining 
epoch 38, samples 355072, loss 0.684980, accuracy 0.824219 BatchTime 1.619920, for discriminator pretraining 
epoch 38, samples 355328, loss 0.567964, accuracy 0.867188 BatchTime 1.670938, for discriminator pretraining 
epoch 38, samples 355584, loss 0.621416, accuracy 0.824219 BatchTime 1.745405, for discriminator pretraining 
epoch 38, samples 355840, loss 0.592906, accuracy 0.839844 BatchTime 1.717882, for discriminator pretraining 
epoch 38, samples 356096, loss 0.757413, accuracy 0.816406 BatchTime 1.625915, for discriminator pretraining 
epoch 38, samples 356352, loss 0.874914, accuracy 0.792969 BatchTime 1.633322, for discriminator pretraining 
epoch 38, samples 356608, loss 0.608369, accuracy 0.851562 BatchTime 1.620306, for discriminator pretraining 
epoch 38, samples 356864, loss 0.617293, accuracy 0.812500 BatchTime 1.702721, for discriminator pretraining 
epoch 38, samples 357120, loss 0.670928, accuracy 0.835938 BatchTime 1.720354, for discriminator pretraining 
epoch 38, samples 357376, loss 0.671289, accuracy 0.828125 BatchTime 1.636235, for discriminator pretraining 
epoch 38, samples 357632, loss 0.659571, accuracy 0.828125 BatchTime 1.737886, for discriminator pretraining 
epoch 38, samples 357888, loss 0.517984, accuracy 0.886719 BatchTime 1.745258, for discriminator pretraining 
epoch 38, samples 358144, loss 0.652905, accuracy 0.871094 BatchTime 1.641378, for discriminator pretraining 
epoch 38, samples 358400, loss 0.847852, accuracy 0.800781 BatchTime 1.652260, for discriminator pretraining 
save params when epoch 38, samples 358400
epoch 38, samples 358656, loss 0.794710, accuracy 0.785156 BatchTime 1.695333, for discriminator pretraining 
epoch 38, samples 358912, loss 0.794035, accuracy 0.820312 BatchTime 1.738835, for discriminator pretraining 
epoch 38, samples 359168, loss 0.595843, accuracy 0.855469 BatchTime 1.752663, for discriminator pretraining 
epoch 38, samples 359424, loss 1.045094, accuracy 0.795455 BatchTime 8.740580, for discriminator pretraining 
Seen  9004  examples for discriminator. Time Cost :  72.65021824836731
load vocab successfully!!
Epoch : 39
epoch 39, samples 359680, loss 0.340552, accuracy 0.875000 BatchTime 2.678359, for discriminator pretraining 
epoch 39, samples 359936, loss 0.450079, accuracy 0.886719 BatchTime 1.782579, for discriminator pretraining 
epoch 39, samples 360192, loss 0.399388, accuracy 0.871094 BatchTime 1.676095, for discriminator pretraining 
epoch 39, samples 360448, loss 0.612333, accuracy 0.851562 BatchTime 1.733037, for discriminator pretraining 
epoch 39, samples 360704, loss 0.936164, accuracy 0.820312 BatchTime 1.653781, for discriminator pretraining 
epoch 39, samples 360960, loss 0.974373, accuracy 0.855469 BatchTime 1.647229, for discriminator pretraining 
epoch 39, samples 361216, loss 0.458112, accuracy 0.867188 BatchTime 1.605169, for discriminator pretraining 
epoch 39, samples 361472, loss 0.440182, accuracy 0.875000 BatchTime 1.603209, for discriminator pretraining 
epoch 39, samples 361728, loss 0.416673, accuracy 0.863281 BatchTime 1.640656, for discriminator pretraining 
epoch 39, samples 361984, loss 0.716076, accuracy 0.832031 BatchTime 1.636505, for discriminator pretraining 
epoch 39, samples 362240, loss 0.609043, accuracy 0.867188 BatchTime 1.733834, for discriminator pretraining 
epoch 39, samples 362496, loss 0.533823, accuracy 0.886719 BatchTime 1.783572, for discriminator pretraining 
epoch 39, samples 362752, loss 0.481078, accuracy 0.855469 BatchTime 1.620190, for discriminator pretraining 
epoch 39, samples 363008, loss 0.797674, accuracy 0.804688 BatchTime 1.594070, for discriminator pretraining 
epoch 39, samples 363264, loss 0.649531, accuracy 0.851562 BatchTime 1.635637, for discriminator pretraining 
epoch 39, samples 363520, loss 0.577235, accuracy 0.859375 BatchTime 1.630205, for discriminator pretraining 
epoch 39, samples 363776, loss 0.521914, accuracy 0.847656 BatchTime 1.711438, for discriminator pretraining 
epoch 39, samples 364032, loss 0.564972, accuracy 0.851562 BatchTime 1.695169, for discriminator pretraining 
epoch 39, samples 364288, loss 0.744465, accuracy 0.832031 BatchTime 1.693752, for discriminator pretraining 
epoch 39, samples 364544, loss 0.596007, accuracy 0.847656 BatchTime 1.657350, for discriminator pretraining 
epoch 39, samples 364800, loss 0.635825, accuracy 0.847656 BatchTime 1.643405, for discriminator pretraining 
epoch 39, samples 365056, loss 0.728209, accuracy 0.839844 BatchTime 1.665143, for discriminator pretraining 
epoch 39, samples 365312, loss 0.578579, accuracy 0.875000 BatchTime 1.750677, for discriminator pretraining 
epoch 39, samples 365568, loss 0.517369, accuracy 0.863281 BatchTime 1.708015, for discriminator pretraining 
epoch 39, samples 365824, loss 0.538507, accuracy 0.835938 BatchTime 1.620569, for discriminator pretraining 
epoch 39, samples 366080, loss 0.839595, accuracy 0.824219 BatchTime 1.629852, for discriminator pretraining 
epoch 39, samples 366336, loss 0.703083, accuracy 0.839844 BatchTime 1.631189, for discriminator pretraining 
epoch 39, samples 366592, loss 0.488373, accuracy 0.851562 BatchTime 1.762618, for discriminator pretraining 
epoch 39, samples 366848, loss 0.587485, accuracy 0.847656 BatchTime 1.769269, for discriminator pretraining 
epoch 39, samples 367104, loss 0.589451, accuracy 0.824219 BatchTime 1.641473, for discriminator pretraining 
epoch 39, samples 367360, loss 0.604593, accuracy 0.867188 BatchTime 1.666438, for discriminator pretraining 
epoch 39, samples 367616, loss 0.498837, accuracy 0.871094 BatchTime 1.762918, for discriminator pretraining 
epoch 39, samples 367872, loss 0.672896, accuracy 0.824219 BatchTime 1.726965, for discriminator pretraining 
epoch 39, samples 368128, loss 0.799916, accuracy 0.832031 BatchTime 1.647303, for discriminator pretraining 
epoch 39, samples 368384, loss 0.809750, accuracy 0.832031 BatchTime 1.651000, for discriminator pretraining 
epoch 39, samples 368640, loss 0.834981, accuracy 0.815789 BatchTime 0.859802, for discriminator pretraining 
Seen  8998  examples for discriminator. Time Cost :  59.679861545562744
load vocab successfully!!
Epoch : 40
epoch 40, samples 368896, loss 0.413119, accuracy 0.882812 BatchTime 2.733948, for discriminator pretraining 
epoch 40, samples 369152, loss 0.497427, accuracy 0.871094 BatchTime 1.900697, for discriminator pretraining 
epoch 40, samples 369408, loss 0.427965, accuracy 0.871094 BatchTime 1.606606, for discriminator pretraining 
epoch 40, samples 369664, loss 0.616221, accuracy 0.824219 BatchTime 1.614954, for discriminator pretraining 
epoch 40, samples 369920, loss 0.437771, accuracy 0.886719 BatchTime 1.643180, for discriminator pretraining 
epoch 40, samples 370176, loss 0.656088, accuracy 0.855469 BatchTime 1.575682, for discriminator pretraining 
epoch 40, samples 370432, loss 0.639291, accuracy 0.847656 BatchTime 1.604079, for discriminator pretraining 
epoch 40, samples 370688, loss 0.374832, accuracy 0.898438 BatchTime 1.616875, for discriminator pretraining 
epoch 40, samples 370944, loss 0.665099, accuracy 0.839844 BatchTime 1.639873, for discriminator pretraining 
epoch 40, samples 371200, loss 0.583221, accuracy 0.863281 BatchTime 1.675001, for discriminator pretraining 
epoch 40, samples 371456, loss 0.716074, accuracy 0.835938 BatchTime 1.733388, for discriminator pretraining 
epoch 40, samples 371712, loss 0.653139, accuracy 0.832031 BatchTime 1.681301, for discriminator pretraining 
epoch 40, samples 371968, loss 0.515642, accuracy 0.894531 BatchTime 1.610745, for discriminator pretraining 
epoch 40, samples 372224, loss 0.316130, accuracy 0.882812 BatchTime 1.643895, for discriminator pretraining 
epoch 40, samples 372480, loss 0.564104, accuracy 0.828125 BatchTime 1.841170, for discriminator pretraining 
epoch 40, samples 372736, loss 0.483477, accuracy 0.875000 BatchTime 1.620609, for discriminator pretraining 
epoch 40, samples 372992, loss 0.521702, accuracy 0.867188 BatchTime 1.654963, for discriminator pretraining 
epoch 40, samples 373248, loss 0.686168, accuracy 0.843750 BatchTime 1.648776, for discriminator pretraining 
epoch 40, samples 373504, loss 0.674964, accuracy 0.851562 BatchTime 1.655967, for discriminator pretraining 
epoch 40, samples 373760, loss 0.558455, accuracy 0.855469 BatchTime 1.609334, for discriminator pretraining 
epoch 40, samples 374016, loss 0.695471, accuracy 0.835938 BatchTime 1.698134, for discriminator pretraining 
epoch 40, samples 374272, loss 0.779077, accuracy 0.847656 BatchTime 1.705781, for discriminator pretraining 
epoch 40, samples 374528, loss 0.588533, accuracy 0.863281 BatchTime 1.724132, for discriminator pretraining 
epoch 40, samples 374784, loss 0.407928, accuracy 0.886719 BatchTime 1.690840, for discriminator pretraining 
epoch 40, samples 375040, loss 0.604942, accuracy 0.867188 BatchTime 1.698025, for discriminator pretraining 
epoch 40, samples 375296, loss 0.640986, accuracy 0.855469 BatchTime 1.672839, for discriminator pretraining 
epoch 40, samples 375552, loss 0.616702, accuracy 0.824219 BatchTime 1.669639, for discriminator pretraining 
epoch 40, samples 375808, loss 0.529588, accuracy 0.863281 BatchTime 1.623984, for discriminator pretraining 
epoch 40, samples 376064, loss 0.727204, accuracy 0.832031 BatchTime 1.685722, for discriminator pretraining 
epoch 40, samples 376320, loss 0.897319, accuracy 0.824219 BatchTime 1.665063, for discriminator pretraining 
epoch 40, samples 376576, loss 0.950104, accuracy 0.812500 BatchTime 1.767409, for discriminator pretraining 
epoch 40, samples 376832, loss 0.648264, accuracy 0.855469 BatchTime 1.860780, for discriminator pretraining 
epoch 40, samples 377088, loss 0.854958, accuracy 0.792969 BatchTime 1.665589, for discriminator pretraining 
epoch 40, samples 377344, loss 0.426353, accuracy 0.871094 BatchTime 1.664297, for discriminator pretraining 
epoch 40, samples 377600, loss 0.645188, accuracy 0.867188 BatchTime 1.696996, for discriminator pretraining 
epoch 40, samples 377856, loss 0.069974, accuracy 1.000000 BatchTime 0.883468, for discriminator pretraining 
Seen  8986  examples for discriminator. Time Cost :  59.8451144695282
load vocab successfully!!
Epoch : 41
epoch 41, samples 378112, loss 0.401624, accuracy 0.894531 BatchTime 2.855695, for discriminator pretraining 
epoch 41, samples 378368, loss 0.532171, accuracy 0.878906 BatchTime 1.857397, for discriminator pretraining 
epoch 41, samples 378624, loss 0.421735, accuracy 0.867188 BatchTime 1.753087, for discriminator pretraining 
epoch 41, samples 378880, loss 0.451845, accuracy 0.859375 BatchTime 1.623542, for discriminator pretraining 
epoch 41, samples 379136, loss 0.658807, accuracy 0.851562 BatchTime 1.720733, for discriminator pretraining 
epoch 41, samples 379392, loss 0.726416, accuracy 0.812500 BatchTime 1.573111, for discriminator pretraining 
epoch 41, samples 379648, loss 0.643593, accuracy 0.824219 BatchTime 1.659110, for discriminator pretraining 
epoch 41, samples 379904, loss 0.515035, accuracy 0.875000 BatchTime 1.707700, for discriminator pretraining 
epoch 41, samples 380160, loss 0.535513, accuracy 0.859375 BatchTime 1.747212, for discriminator pretraining 
epoch 41, samples 380416, loss 0.409931, accuracy 0.875000 BatchTime 1.667809, for discriminator pretraining 
epoch 41, samples 380672, loss 0.578649, accuracy 0.855469 BatchTime 1.673562, for discriminator pretraining 
epoch 41, samples 380928, loss 0.493338, accuracy 0.875000 BatchTime 1.596868, for discriminator pretraining 
epoch 41, samples 381184, loss 0.358600, accuracy 0.886719 BatchTime 1.698499, for discriminator pretraining 
epoch 41, samples 381440, loss 0.715490, accuracy 0.816406 BatchTime 1.570858, for discriminator pretraining 
epoch 41, samples 381696, loss 0.617982, accuracy 0.847656 BatchTime 1.628826, for discriminator pretraining 
epoch 41, samples 381952, loss 0.524481, accuracy 0.882812 BatchTime 1.592947, for discriminator pretraining 
epoch 41, samples 382208, loss 0.577756, accuracy 0.851562 BatchTime 1.649362, for discriminator pretraining 
epoch 41, samples 382464, loss 0.650585, accuracy 0.863281 BatchTime 1.705983, for discriminator pretraining 
epoch 41, samples 382720, loss 0.492671, accuracy 0.855469 BatchTime 1.736616, for discriminator pretraining 
epoch 41, samples 382976, loss 0.836856, accuracy 0.835938 BatchTime 1.663389, for discriminator pretraining 
epoch 41, samples 383232, loss 1.000567, accuracy 0.812500 BatchTime 1.686385, for discriminator pretraining 
epoch 41, samples 383488, loss 0.704475, accuracy 0.843750 BatchTime 1.614166, for discriminator pretraining 
epoch 41, samples 383744, loss 0.607941, accuracy 0.828125 BatchTime 1.647284, for discriminator pretraining 
epoch 41, samples 384000, loss 0.659066, accuracy 0.832031 BatchTime 1.612165, for discriminator pretraining 
save params when epoch 41, samples 384000
epoch 41, samples 384256, loss 0.581357, accuracy 0.878906 BatchTime 1.768949, for discriminator pretraining 
epoch 41, samples 384512, loss 0.815692, accuracy 0.816406 BatchTime 1.738899, for discriminator pretraining 
epoch 41, samples 384768, loss 0.973987, accuracy 0.832031 BatchTime 1.715658, for discriminator pretraining 
epoch 41, samples 385024, loss 0.859679, accuracy 0.796875 BatchTime 1.615524, for discriminator pretraining 
epoch 41, samples 385280, loss 0.817824, accuracy 0.839844 BatchTime 1.659042, for discriminator pretraining 
epoch 41, samples 385536, loss 0.676218, accuracy 0.835938 BatchTime 1.586019, for discriminator pretraining 
epoch 41, samples 385792, loss 0.743775, accuracy 0.867188 BatchTime 1.674159, for discriminator pretraining 
epoch 41, samples 386048, loss 0.662653, accuracy 0.828125 BatchTime 1.604023, for discriminator pretraining 
epoch 41, samples 386304, loss 0.837661, accuracy 0.824219 BatchTime 1.725845, for discriminator pretraining 
epoch 41, samples 386560, loss 0.769808, accuracy 0.789062 BatchTime 1.610075, for discriminator pretraining 
epoch 41, samples 386816, loss 0.708238, accuracy 0.824219 BatchTime 1.709313, for discriminator pretraining 
epoch 41, samples 387072, loss 0.286104, accuracy 0.846154 BatchTime 0.834064, for discriminator pretraining 
Seen  8986  examples for discriminator. Time Cost :  65.16617131233215
load vocab successfully!!
Epoch : 42
epoch 42, samples 387328, loss 0.307396, accuracy 0.898438 BatchTime 2.645883, for discriminator pretraining 
epoch 42, samples 387584, loss 0.293405, accuracy 0.921875 BatchTime 1.797294, for discriminator pretraining 
epoch 42, samples 387840, loss 0.412880, accuracy 0.875000 BatchTime 1.693704, for discriminator pretraining 
epoch 42, samples 388096, loss 0.464189, accuracy 0.882812 BatchTime 1.616948, for discriminator pretraining 
epoch 42, samples 388352, loss 0.512530, accuracy 0.859375 BatchTime 1.707474, for discriminator pretraining 
epoch 42, samples 388608, loss 0.638715, accuracy 0.820312 BatchTime 1.631551, for discriminator pretraining 
epoch 42, samples 388864, loss 0.282304, accuracy 0.914062 BatchTime 1.720743, for discriminator pretraining 
epoch 42, samples 389120, loss 0.589258, accuracy 0.824219 BatchTime 1.697331, for discriminator pretraining 
epoch 42, samples 389376, loss 0.830736, accuracy 0.808594 BatchTime 1.741956, for discriminator pretraining 
epoch 42, samples 389632, loss 0.546552, accuracy 0.843750 BatchTime 1.555120, for discriminator pretraining 
epoch 42, samples 389888, loss 0.603009, accuracy 0.871094 BatchTime 1.652422, for discriminator pretraining 
epoch 42, samples 390144, loss 0.815537, accuracy 0.835938 BatchTime 1.604382, for discriminator pretraining 
epoch 42, samples 390400, loss 0.696810, accuracy 0.820312 BatchTime 1.719115, for discriminator pretraining 
epoch 42, samples 390656, loss 0.332539, accuracy 0.910156 BatchTime 1.674756, for discriminator pretraining 
epoch 42, samples 390912, loss 0.505547, accuracy 0.851562 BatchTime 1.777883, for discriminator pretraining 
epoch 42, samples 391168, loss 0.691496, accuracy 0.820312 BatchTime 1.650322, for discriminator pretraining 
epoch 42, samples 391424, loss 0.503780, accuracy 0.863281 BatchTime 1.668862, for discriminator pretraining 
epoch 42, samples 391680, loss 0.669885, accuracy 0.859375 BatchTime 1.616401, for discriminator pretraining 
epoch 42, samples 391936, loss 0.631790, accuracy 0.843750 BatchTime 1.719641, for discriminator pretraining 
epoch 42, samples 392192, loss 0.555366, accuracy 0.835938 BatchTime 1.736647, for discriminator pretraining 
epoch 42, samples 392448, loss 0.682960, accuracy 0.847656 BatchTime 1.779668, for discriminator pretraining 
epoch 42, samples 392704, loss 0.646061, accuracy 0.851562 BatchTime 1.647351, for discriminator pretraining 
epoch 42, samples 392960, loss 0.688520, accuracy 0.832031 BatchTime 1.730206, for discriminator pretraining 
epoch 42, samples 393216, loss 0.726792, accuracy 0.800781 BatchTime 1.645314, for discriminator pretraining 
epoch 42, samples 393472, loss 0.707450, accuracy 0.839844 BatchTime 1.733331, for discriminator pretraining 
epoch 42, samples 393728, loss 0.706819, accuracy 0.835938 BatchTime 1.752043, for discriminator pretraining 
epoch 42, samples 393984, loss 0.579802, accuracy 0.867188 BatchTime 1.791645, for discriminator pretraining 
epoch 42, samples 394240, loss 0.566725, accuracy 0.847656 BatchTime 1.645193, for discriminator pretraining 
epoch 42, samples 394496, loss 0.576593, accuracy 0.851562 BatchTime 1.736205, for discriminator pretraining 
epoch 42, samples 394752, loss 0.477532, accuracy 0.851562 BatchTime 1.639392, for discriminator pretraining 
epoch 42, samples 395008, loss 0.761982, accuracy 0.832031 BatchTime 1.785049, for discriminator pretraining 
epoch 42, samples 395264, loss 0.879421, accuracy 0.828125 BatchTime 1.655465, for discriminator pretraining 
epoch 42, samples 395520, loss 0.767025, accuracy 0.832031 BatchTime 1.772383, for discriminator pretraining 
epoch 42, samples 395776, loss 0.675072, accuracy 0.851562 BatchTime 1.677235, for discriminator pretraining 
epoch 42, samples 396032, loss 0.586015, accuracy 0.847656 BatchTime 1.837319, for discriminator pretraining 
epoch 42, samples 396288, loss 0.372236, accuracy 0.882353 BatchTime 0.990258, for discriminator pretraining 
Seen  8994  examples for discriminator. Time Cost :  60.659088134765625
load vocab successfully!!
Epoch : 43
epoch 43, samples 396544, loss 0.435121, accuracy 0.847656 BatchTime 2.847919, for discriminator pretraining 
epoch 43, samples 396800, loss 0.522956, accuracy 0.882812 BatchTime 1.823031, for discriminator pretraining 
epoch 43, samples 397056, loss 0.536631, accuracy 0.847656 BatchTime 1.776950, for discriminator pretraining 
epoch 43, samples 397312, loss 0.470446, accuracy 0.886719 BatchTime 1.680596, for discriminator pretraining 
epoch 43, samples 397568, loss 0.474773, accuracy 0.894531 BatchTime 1.755475, for discriminator pretraining 
epoch 43, samples 397824, loss 0.512512, accuracy 0.851562 BatchTime 1.639749, for discriminator pretraining 
epoch 43, samples 398080, loss 0.397009, accuracy 0.886719 BatchTime 1.713024, for discriminator pretraining 
epoch 43, samples 398336, loss 0.649798, accuracy 0.859375 BatchTime 1.738314, for discriminator pretraining 
epoch 43, samples 398592, loss 0.843243, accuracy 0.816406 BatchTime 1.821499, for discriminator pretraining 
epoch 43, samples 398848, loss 0.642549, accuracy 0.843750 BatchTime 1.648820, for discriminator pretraining 
epoch 43, samples 399104, loss 0.534841, accuracy 0.851562 BatchTime 1.733740, for discriminator pretraining 
epoch 43, samples 399360, loss 0.507163, accuracy 0.867188 BatchTime 1.586136, for discriminator pretraining 
epoch 43, samples 399616, loss 0.531826, accuracy 0.859375 BatchTime 1.788373, for discriminator pretraining 
epoch 43, samples 399872, loss 0.496577, accuracy 0.886719 BatchTime 1.771751, for discriminator pretraining 
epoch 43, samples 400128, loss 0.690881, accuracy 0.828125 BatchTime 1.726983, for discriminator pretraining 
epoch 43, samples 400384, loss 0.545364, accuracy 0.875000 BatchTime 1.629295, for discriminator pretraining 
epoch 43, samples 400640, loss 0.770842, accuracy 0.812500 BatchTime 1.742241, for discriminator pretraining 
epoch 43, samples 400896, loss 0.766777, accuracy 0.851562 BatchTime 1.625032, for discriminator pretraining 
epoch 43, samples 401152, loss 0.419381, accuracy 0.867188 BatchTime 1.719959, for discriminator pretraining 
epoch 43, samples 401408, loss 0.767168, accuracy 0.820312 BatchTime 1.672562, for discriminator pretraining 
epoch 43, samples 401664, loss 0.775283, accuracy 0.851562 BatchTime 1.701729, for discriminator pretraining 
epoch 43, samples 401920, loss 0.567595, accuracy 0.843750 BatchTime 1.608641, for discriminator pretraining 
epoch 43, samples 402176, loss 0.667920, accuracy 0.835938 BatchTime 1.721655, for discriminator pretraining 
epoch 43, samples 402432, loss 0.680185, accuracy 0.851562 BatchTime 1.716885, for discriminator pretraining 
epoch 43, samples 402688, loss 0.826122, accuracy 0.832031 BatchTime 1.800684, for discriminator pretraining 
epoch 43, samples 402944, loss 0.616760, accuracy 0.859375 BatchTime 1.678062, for discriminator pretraining 
epoch 43, samples 403200, loss 0.580758, accuracy 0.832031 BatchTime 1.789443, for discriminator pretraining 
epoch 43, samples 403456, loss 0.527716, accuracy 0.855469 BatchTime 1.631350, for discriminator pretraining 
epoch 43, samples 403712, loss 0.762300, accuracy 0.832031 BatchTime 1.721170, for discriminator pretraining 
epoch 43, samples 403968, loss 0.581658, accuracy 0.867188 BatchTime 1.678203, for discriminator pretraining 
epoch 43, samples 404224, loss 0.654322, accuracy 0.843750 BatchTime 1.848074, for discriminator pretraining 
epoch 43, samples 404480, loss 0.785503, accuracy 0.839844 BatchTime 1.751574, for discriminator pretraining 
epoch 43, samples 404736, loss 0.537223, accuracy 0.863281 BatchTime 1.689326, for discriminator pretraining 
epoch 43, samples 404992, loss 0.587804, accuracy 0.859375 BatchTime 1.553045, for discriminator pretraining 
epoch 43, samples 405248, loss 0.447046, accuracy 0.859375 BatchTime 1.706905, for discriminator pretraining 
epoch 43, samples 405504, loss 0.450329, accuracy 0.916667 BatchTime 6.692243, for discriminator pretraining 
Seen  9008  examples for discriminator. Time Cost :  66.76660966873169
load vocab successfully!!
Epoch : 44
epoch 44, samples 405760, loss 0.352494, accuracy 0.898438 BatchTime 2.549428, for discriminator pretraining 
epoch 44, samples 406016, loss 0.528604, accuracy 0.851562 BatchTime 1.810925, for discriminator pretraining 
epoch 44, samples 406272, loss 0.434652, accuracy 0.871094 BatchTime 1.769084, for discriminator pretraining 
epoch 44, samples 406528, loss 0.536257, accuracy 0.855469 BatchTime 1.632808, for discriminator pretraining 
epoch 44, samples 406784, loss 0.468905, accuracy 0.878906 BatchTime 1.757533, for discriminator pretraining 
epoch 44, samples 407040, loss 0.504772, accuracy 0.875000 BatchTime 1.773098, for discriminator pretraining 
epoch 44, samples 407296, loss 0.465283, accuracy 0.890625 BatchTime 1.812415, for discriminator pretraining 
epoch 44, samples 407552, loss 0.555654, accuracy 0.847656 BatchTime 1.642690, for discriminator pretraining 
epoch 44, samples 407808, loss 0.478649, accuracy 0.878906 BatchTime 1.720707, for discriminator pretraining 
epoch 44, samples 408064, loss 0.576886, accuracy 0.875000 BatchTime 1.644684, for discriminator pretraining 
epoch 44, samples 408320, loss 0.677459, accuracy 0.839844 BatchTime 1.687552, for discriminator pretraining 
epoch 44, samples 408576, loss 0.546401, accuracy 0.863281 BatchTime 1.650727, for discriminator pretraining 
epoch 44, samples 408832, loss 0.578892, accuracy 0.847656 BatchTime 1.780751, for discriminator pretraining 
epoch 44, samples 409088, loss 0.464587, accuracy 0.890625 BatchTime 1.747232, for discriminator pretraining 
epoch 44, samples 409344, loss 0.553313, accuracy 0.855469 BatchTime 1.776004, for discriminator pretraining 
epoch 44, samples 409600, loss 0.592502, accuracy 0.835938 BatchTime 1.638807, for discriminator pretraining 
save params when epoch 44, samples 409600
epoch 44, samples 409856, loss 0.455787, accuracy 0.867188 BatchTime 1.735242, for discriminator pretraining 
epoch 44, samples 410112, loss 0.561153, accuracy 0.859375 BatchTime 1.755682, for discriminator pretraining 
epoch 44, samples 410368, loss 0.398819, accuracy 0.886719 BatchTime 1.733504, for discriminator pretraining 
epoch 44, samples 410624, loss 0.539063, accuracy 0.867188 BatchTime 1.632719, for discriminator pretraining 
epoch 44, samples 410880, loss 0.455979, accuracy 0.847656 BatchTime 1.711639, for discriminator pretraining 
epoch 44, samples 411136, loss 0.848906, accuracy 0.847656 BatchTime 1.645155, for discriminator pretraining 
epoch 44, samples 411392, loss 0.601432, accuracy 0.851562 BatchTime 1.803895, for discriminator pretraining 
epoch 44, samples 411648, loss 0.692231, accuracy 0.839844 BatchTime 1.758256, for discriminator pretraining 
epoch 44, samples 411904, loss 0.664507, accuracy 0.851562 BatchTime 1.713405, for discriminator pretraining 
epoch 44, samples 412160, loss 0.598580, accuracy 0.847656 BatchTime 1.620301, for discriminator pretraining 
epoch 44, samples 412416, loss 0.569018, accuracy 0.859375 BatchTime 1.648587, for discriminator pretraining 
epoch 44, samples 412672, loss 0.544173, accuracy 0.863281 BatchTime 1.619913, for discriminator pretraining 
epoch 44, samples 412928, loss 0.758475, accuracy 0.824219 BatchTime 1.751272, for discriminator pretraining 
epoch 44, samples 413184, loss 0.536568, accuracy 0.824219 BatchTime 1.653116, for discriminator pretraining 
epoch 44, samples 413440, loss 0.803566, accuracy 0.835938 BatchTime 1.734051, for discriminator pretraining 
epoch 44, samples 413696, loss 0.922343, accuracy 0.804688 BatchTime 1.630675, for discriminator pretraining 
epoch 44, samples 413952, loss 0.764346, accuracy 0.816406 BatchTime 1.667753, for discriminator pretraining 
epoch 44, samples 414208, loss 0.685729, accuracy 0.886719 BatchTime 1.682760, for discriminator pretraining 
epoch 44, samples 414464, loss 0.569189, accuracy 0.882812 BatchTime 1.773013, for discriminator pretraining 
epoch 44, samples 414720, loss 0.505482, accuracy 0.843750 BatchTime 0.902077, for discriminator pretraining 
Seen  8992  examples for discriminator. Time Cost :  67.41141438484192
load vocab successfully!!
Epoch : 45
epoch 45, samples 414976, loss 0.757289, accuracy 0.835938 BatchTime 2.632112, for discriminator pretraining 
epoch 45, samples 415232, loss 0.424962, accuracy 0.875000 BatchTime 1.977361, for discriminator pretraining 
epoch 45, samples 415488, loss 0.408307, accuracy 0.871094 BatchTime 1.722492, for discriminator pretraining 
epoch 45, samples 415744, loss 0.337435, accuracy 0.894531 BatchTime 1.693298, for discriminator pretraining 
epoch 45, samples 416000, loss 0.364769, accuracy 0.894531 BatchTime 1.738229, for discriminator pretraining 
epoch 45, samples 416256, loss 0.477987, accuracy 0.847656 BatchTime 1.690746, for discriminator pretraining 
epoch 45, samples 416512, loss 0.645992, accuracy 0.847656 BatchTime 1.742444, for discriminator pretraining 
epoch 45, samples 416768, loss 0.527033, accuracy 0.871094 BatchTime 1.632350, for discriminator pretraining 
epoch 45, samples 417024, loss 0.580074, accuracy 0.851562 BatchTime 1.682723, for discriminator pretraining 
epoch 45, samples 417280, loss 0.384747, accuracy 0.898438 BatchTime 1.641434, for discriminator pretraining 
epoch 45, samples 417536, loss 0.647017, accuracy 0.835938 BatchTime 1.736304, for discriminator pretraining 
epoch 45, samples 417792, loss 0.540691, accuracy 0.851562 BatchTime 1.732239, for discriminator pretraining 
epoch 45, samples 418048, loss 0.769430, accuracy 0.820312 BatchTime 1.837510, for discriminator pretraining 
epoch 45, samples 418304, loss 0.742145, accuracy 0.843750 BatchTime 1.661006, for discriminator pretraining 
epoch 45, samples 418560, loss 0.651284, accuracy 0.843750 BatchTime 1.752629, for discriminator pretraining 
epoch 45, samples 418816, loss 0.746055, accuracy 0.828125 BatchTime 1.642461, for discriminator pretraining 
epoch 45, samples 419072, loss 0.617633, accuracy 0.851562 BatchTime 1.737838, for discriminator pretraining 
epoch 45, samples 419328, loss 0.555901, accuracy 0.847656 BatchTime 1.629676, for discriminator pretraining 
epoch 45, samples 419584, loss 0.632537, accuracy 0.875000 BatchTime 1.712488, for discriminator pretraining 
epoch 45, samples 419840, loss 0.655659, accuracy 0.816406 BatchTime 1.637916, for discriminator pretraining 
epoch 45, samples 420096, loss 0.579860, accuracy 0.832031 BatchTime 1.804705, for discriminator pretraining 
epoch 45, samples 420352, loss 0.580703, accuracy 0.867188 BatchTime 1.762488, for discriminator pretraining 
epoch 45, samples 420608, loss 0.469159, accuracy 0.882812 BatchTime 1.737284, for discriminator pretraining 
epoch 45, samples 420864, loss 0.689852, accuracy 0.839844 BatchTime 1.621346, for discriminator pretraining 
epoch 45, samples 421120, loss 0.732827, accuracy 0.820312 BatchTime 1.779732, for discriminator pretraining 
epoch 45, samples 421376, loss 0.506203, accuracy 0.843750 BatchTime 1.647226, for discriminator pretraining 
epoch 45, samples 421632, loss 0.493824, accuracy 0.863281 BatchTime 1.705070, for discriminator pretraining 
epoch 45, samples 421888, loss 0.696178, accuracy 0.835938 BatchTime 1.726259, for discriminator pretraining 
epoch 45, samples 422144, loss 0.628198, accuracy 0.859375 BatchTime 1.795938, for discriminator pretraining 
epoch 45, samples 422400, loss 0.810965, accuracy 0.812500 BatchTime 1.634735, for discriminator pretraining 
epoch 45, samples 422656, loss 0.700005, accuracy 0.859375 BatchTime 1.701520, for discriminator pretraining 
epoch 45, samples 422912, loss 0.738505, accuracy 0.839844 BatchTime 1.694924, for discriminator pretraining 
epoch 45, samples 423168, loss 0.483723, accuracy 0.890625 BatchTime 1.840826, for discriminator pretraining 
epoch 45, samples 423424, loss 0.493284, accuracy 0.847656 BatchTime 1.673532, for discriminator pretraining 
epoch 45, samples 423680, loss 0.557106, accuracy 0.851562 BatchTime 1.702872, for discriminator pretraining 
epoch 45, samples 423936, loss 0.767417, accuracy 0.850000 BatchTime 0.833312, for discriminator pretraining 
Seen  9000  examples for discriminator. Time Cost :  61.08573031425476
load vocab successfully!!
Epoch : 46
epoch 46, samples 424192, loss 0.383600, accuracy 0.871094 BatchTime 2.468530, for discriminator pretraining 
epoch 46, samples 424448, loss 0.507894, accuracy 0.859375 BatchTime 1.763784, for discriminator pretraining 
epoch 46, samples 424704, loss 0.467542, accuracy 0.875000 BatchTime 1.758349, for discriminator pretraining 
epoch 46, samples 424960, loss 0.514078, accuracy 0.832031 BatchTime 1.627302, for discriminator pretraining 
epoch 46, samples 425216, loss 0.228654, accuracy 0.898438 BatchTime 1.778467, for discriminator pretraining 
epoch 46, samples 425472, loss 0.263417, accuracy 0.906250 BatchTime 1.667913, for discriminator pretraining 
epoch 46, samples 425728, loss 0.638384, accuracy 0.812500 BatchTime 1.783144, for discriminator pretraining 
epoch 46, samples 425984, loss 0.702632, accuracy 0.824219 BatchTime 1.743255, for discriminator pretraining 
epoch 46, samples 426240, loss 0.760162, accuracy 0.832031 BatchTime 1.781066, for discriminator pretraining 
epoch 46, samples 426496, loss 0.788592, accuracy 0.820312 BatchTime 1.681619, for discriminator pretraining 
epoch 46, samples 426752, loss 0.535428, accuracy 0.855469 BatchTime 1.762714, for discriminator pretraining 
epoch 46, samples 427008, loss 0.561440, accuracy 0.859375 BatchTime 1.637884, for discriminator pretraining 
epoch 46, samples 427264, loss 0.611055, accuracy 0.878906 BatchTime 1.740571, for discriminator pretraining 
epoch 46, samples 427520, loss 0.463159, accuracy 0.859375 BatchTime 1.708805, for discriminator pretraining 
epoch 46, samples 427776, loss 0.413272, accuracy 0.898438 BatchTime 1.781215, for discriminator pretraining 
epoch 46, samples 428032, loss 0.512740, accuracy 0.851562 BatchTime 1.693017, for discriminator pretraining 
epoch 46, samples 428288, loss 0.633179, accuracy 0.843750 BatchTime 1.740154, for discriminator pretraining 
epoch 46, samples 428544, loss 0.603409, accuracy 0.843750 BatchTime 1.623666, for discriminator pretraining 
epoch 46, samples 428800, loss 0.648072, accuracy 0.847656 BatchTime 1.821003, for discriminator pretraining 
epoch 46, samples 429056, loss 0.600144, accuracy 0.847656 BatchTime 1.764245, for discriminator pretraining 
epoch 46, samples 429312, loss 0.642840, accuracy 0.839844 BatchTime 1.776651, for discriminator pretraining 
epoch 46, samples 429568, loss 0.396837, accuracy 0.882812 BatchTime 1.675195, for discriminator pretraining 
epoch 46, samples 429824, loss 0.418136, accuracy 0.882812 BatchTime 1.785428, for discriminator pretraining 
epoch 46, samples 430080, loss 0.470544, accuracy 0.863281 BatchTime 1.673800, for discriminator pretraining 
epoch 46, samples 430336, loss 0.676125, accuracy 0.843750 BatchTime 1.804309, for discriminator pretraining 
epoch 46, samples 430592, loss 0.588679, accuracy 0.843750 BatchTime 1.842309, for discriminator pretraining 
epoch 46, samples 430848, loss 0.674786, accuracy 0.835938 BatchTime 1.802011, for discriminator pretraining 
epoch 46, samples 431104, loss 0.394304, accuracy 0.902344 BatchTime 1.655160, for discriminator pretraining 
epoch 46, samples 431360, loss 0.677665, accuracy 0.843750 BatchTime 1.768775, for discriminator pretraining 
epoch 46, samples 431616, loss 0.566093, accuracy 0.875000 BatchTime 1.639376, for discriminator pretraining 
epoch 46, samples 431872, loss 0.752548, accuracy 0.820312 BatchTime 1.821072, for discriminator pretraining 
epoch 46, samples 432128, loss 0.699673, accuracy 0.855469 BatchTime 1.741553, for discriminator pretraining 
epoch 46, samples 432384, loss 0.737567, accuracy 0.835938 BatchTime 1.726725, for discriminator pretraining 
epoch 46, samples 432640, loss 0.834377, accuracy 0.824219 BatchTime 1.612565, for discriminator pretraining 
epoch 46, samples 432896, loss 0.717259, accuracy 0.828125 BatchTime 1.742585, for discriminator pretraining 
epoch 46, samples 433152, loss 1.069704, accuracy 0.805556 BatchTime 0.813218, for discriminator pretraining 
Seen  8996  examples for discriminator. Time Cost :  61.5449755191803
load vocab successfully!!
Epoch : 47
epoch 47, samples 433408, loss 0.358404, accuracy 0.882812 BatchTime 2.488738, for discriminator pretraining 
epoch 47, samples 433664, loss 0.350602, accuracy 0.890625 BatchTime 1.769395, for discriminator pretraining 
epoch 47, samples 433920, loss 0.536665, accuracy 0.855469 BatchTime 1.773045, for discriminator pretraining 
epoch 47, samples 434176, loss 0.715334, accuracy 0.847656 BatchTime 1.753447, for discriminator pretraining 
epoch 47, samples 434432, loss 0.458888, accuracy 0.882812 BatchTime 1.811095, for discriminator pretraining 
epoch 47, samples 434688, loss 0.464698, accuracy 0.871094 BatchTime 1.623916, for discriminator pretraining 
epoch 47, samples 434944, loss 0.493898, accuracy 0.882812 BatchTime 1.702628, for discriminator pretraining 
epoch 47, samples 435200, loss 0.457695, accuracy 0.859375 BatchTime 1.615380, for discriminator pretraining 
save params when epoch 47, samples 435200
epoch 47, samples 435456, loss 0.606843, accuracy 0.859375 BatchTime 1.672453, for discriminator pretraining 
epoch 47, samples 435712, loss 0.678913, accuracy 0.835938 BatchTime 1.590981, for discriminator pretraining 
epoch 47, samples 435968, loss 0.647200, accuracy 0.855469 BatchTime 1.746425, for discriminator pretraining 
epoch 47, samples 436224, loss 0.407031, accuracy 0.878906 BatchTime 1.698848, for discriminator pretraining 
epoch 47, samples 436480, loss 0.801874, accuracy 0.820312 BatchTime 1.814939, for discriminator pretraining 
epoch 47, samples 436736, loss 0.862264, accuracy 0.781250 BatchTime 1.690279, for discriminator pretraining 
epoch 47, samples 436992, loss 0.610290, accuracy 0.847656 BatchTime 1.747980, for discriminator pretraining 
epoch 47, samples 437248, loss 0.513558, accuracy 0.863281 BatchTime 1.685504, for discriminator pretraining 
epoch 47, samples 437504, loss 0.550269, accuracy 0.867188 BatchTime 1.782616, for discriminator pretraining 
epoch 47, samples 437760, loss 0.520803, accuracy 0.859375 BatchTime 1.632023, for discriminator pretraining 
epoch 47, samples 438016, loss 0.396225, accuracy 0.875000 BatchTime 1.667279, for discriminator pretraining 
epoch 47, samples 438272, loss 0.646971, accuracy 0.828125 BatchTime 1.666179, for discriminator pretraining 
epoch 47, samples 438528, loss 0.788590, accuracy 0.863281 BatchTime 1.761754, for discriminator pretraining 
epoch 47, samples 438784, loss 0.689413, accuracy 0.863281 BatchTime 1.642344, for discriminator pretraining 
epoch 47, samples 439040, loss 0.638444, accuracy 0.875000 BatchTime 1.746409, for discriminator pretraining 
epoch 47, samples 439296, loss 0.519724, accuracy 0.875000 BatchTime 1.669260, for discriminator pretraining 
epoch 47, samples 439552, loss 0.824887, accuracy 0.808594 BatchTime 1.778134, for discriminator pretraining 
epoch 47, samples 439808, loss 0.551155, accuracy 0.859375 BatchTime 1.687498, for discriminator pretraining 
epoch 47, samples 440064, loss 0.640447, accuracy 0.832031 BatchTime 1.773014, for discriminator pretraining 
epoch 47, samples 440320, loss 0.359448, accuracy 0.867188 BatchTime 1.628754, for discriminator pretraining 
epoch 47, samples 440576, loss 0.701655, accuracy 0.839844 BatchTime 1.695697, for discriminator pretraining 
epoch 47, samples 440832, loss 0.777185, accuracy 0.812500 BatchTime 1.635432, for discriminator pretraining 
epoch 47, samples 441088, loss 0.551078, accuracy 0.828125 BatchTime 1.805762, for discriminator pretraining 
epoch 47, samples 441344, loss 0.579204, accuracy 0.867188 BatchTime 1.724776, for discriminator pretraining 
epoch 47, samples 441600, loss 0.478559, accuracy 0.878906 BatchTime 1.753968, for discriminator pretraining 
epoch 47, samples 441856, loss 0.589947, accuracy 0.824219 BatchTime 1.614085, for discriminator pretraining 
epoch 47, samples 442112, loss 0.557981, accuracy 0.847656 BatchTime 1.732780, for discriminator pretraining 
epoch 47, samples 442368, loss 0.993627, accuracy 0.750000 BatchTime 0.895119, for discriminator pretraining 
Seen  9000  examples for discriminator. Time Cost :  67.5392587184906
load vocab successfully!!
Epoch : 48
epoch 48, samples 442624, loss 0.403255, accuracy 0.859375 BatchTime 2.721733, for discriminator pretraining 
epoch 48, samples 442880, loss 0.415319, accuracy 0.878906 BatchTime 1.764770, for discriminator pretraining 
epoch 48, samples 443136, loss 0.510576, accuracy 0.890625 BatchTime 1.743655, for discriminator pretraining 
epoch 48, samples 443392, loss 0.467771, accuracy 0.851562 BatchTime 1.632027, for discriminator pretraining 
epoch 48, samples 443648, loss 0.443163, accuracy 0.847656 BatchTime 1.807387, for discriminator pretraining 
epoch 48, samples 443904, loss 0.434892, accuracy 0.882812 BatchTime 1.768688, for discriminator pretraining 
epoch 48, samples 444160, loss 0.677980, accuracy 0.843750 BatchTime 1.785674, for discriminator pretraining 
epoch 48, samples 444416, loss 0.683242, accuracy 0.843750 BatchTime 1.643985, for discriminator pretraining 
epoch 48, samples 444672, loss 0.469976, accuracy 0.871094 BatchTime 1.793230, for discriminator pretraining 
epoch 48, samples 444928, loss 0.495889, accuracy 0.859375 BatchTime 1.758838, for discriminator pretraining 
epoch 48, samples 445184, loss 0.500345, accuracy 0.859375 BatchTime 1.805524, for discriminator pretraining 
epoch 48, samples 445440, loss 0.502117, accuracy 0.859375 BatchTime 1.615817, for discriminator pretraining 
epoch 48, samples 445696, loss 0.437788, accuracy 0.855469 BatchTime 1.770499, for discriminator pretraining 
epoch 48, samples 445952, loss 0.615832, accuracy 0.859375 BatchTime 1.651648, for discriminator pretraining 
epoch 48, samples 446208, loss 0.632397, accuracy 0.851562 BatchTime 1.776690, for discriminator pretraining 
epoch 48, samples 446464, loss 0.483269, accuracy 0.882812 BatchTime 1.670806, for discriminator pretraining 
epoch 48, samples 446720, loss 0.697612, accuracy 0.875000 BatchTime 1.801652, for discriminator pretraining 
epoch 48, samples 446976, loss 0.479516, accuracy 0.894531 BatchTime 1.665153, for discriminator pretraining 
epoch 48, samples 447232, loss 0.553344, accuracy 0.859375 BatchTime 1.686017, for discriminator pretraining 
epoch 48, samples 447488, loss 0.306074, accuracy 0.902344 BatchTime 1.620338, for discriminator pretraining 
epoch 48, samples 447744, loss 0.500569, accuracy 0.851562 BatchTime 1.763018, for discriminator pretraining 
epoch 48, samples 448000, loss 0.563813, accuracy 0.851562 BatchTime 1.678260, for discriminator pretraining 
epoch 48, samples 448256, loss 0.549712, accuracy 0.863281 BatchTime 1.794241, for discriminator pretraining 
epoch 48, samples 448512, loss 0.581865, accuracy 0.871094 BatchTime 1.748158, for discriminator pretraining 
epoch 48, samples 448768, loss 0.607453, accuracy 0.843750 BatchTime 1.826277, for discriminator pretraining 
epoch 48, samples 449024, loss 0.634701, accuracy 0.835938 BatchTime 1.640487, for discriminator pretraining 
epoch 48, samples 449280, loss 0.418916, accuracy 0.882812 BatchTime 1.768039, for discriminator pretraining 
epoch 48, samples 449536, loss 0.697486, accuracy 0.828125 BatchTime 1.654488, for discriminator pretraining 
epoch 48, samples 449792, loss 0.756616, accuracy 0.839844 BatchTime 1.778944, for discriminator pretraining 
epoch 48, samples 450048, loss 0.796998, accuracy 0.839844 BatchTime 1.656957, for discriminator pretraining 
epoch 48, samples 450304, loss 0.831999, accuracy 0.808594 BatchTime 1.856539, for discriminator pretraining 
epoch 48, samples 450560, loss 0.688537, accuracy 0.828125 BatchTime 1.740415, for discriminator pretraining 
epoch 48, samples 450816, loss 0.587480, accuracy 0.847656 BatchTime 1.809046, for discriminator pretraining 
epoch 48, samples 451072, loss 0.565837, accuracy 0.839844 BatchTime 1.709798, for discriminator pretraining 
epoch 48, samples 451328, loss 0.690970, accuracy 0.839844 BatchTime 1.759763, for discriminator pretraining 
epoch 48, samples 451584, loss 1.532903, accuracy 0.791667 BatchTime 0.865105, for discriminator pretraining 
Seen  8984  examples for discriminator. Time Cost :  61.67432951927185
load vocab successfully!!
Epoch : 49
epoch 49, samples 451840, loss 0.423215, accuracy 0.898438 BatchTime 2.782386, for discriminator pretraining 
epoch 49, samples 452096, loss 0.749228, accuracy 0.824219 BatchTime 1.853657, for discriminator pretraining 
epoch 49, samples 452352, loss 0.599092, accuracy 0.839844 BatchTime 1.789382, for discriminator pretraining 
epoch 49, samples 452608, loss 0.454622, accuracy 0.871094 BatchTime 1.649266, for discriminator pretraining 
epoch 49, samples 452864, loss 0.482977, accuracy 0.863281 BatchTime 1.762394, for discriminator pretraining 
epoch 49, samples 453120, loss 0.620009, accuracy 0.847656 BatchTime 1.744292, for discriminator pretraining 
epoch 49, samples 453376, loss 0.629783, accuracy 0.839844 BatchTime 1.803712, for discriminator pretraining 
epoch 49, samples 453632, loss 0.534072, accuracy 0.859375 BatchTime 1.608455, for discriminator pretraining 
epoch 49, samples 453888, loss 0.449450, accuracy 0.902344 BatchTime 1.681326, for discriminator pretraining 
epoch 49, samples 454144, loss 0.337890, accuracy 0.902344 BatchTime 1.600151, for discriminator pretraining 
epoch 49, samples 454400, loss 0.458161, accuracy 0.894531 BatchTime 1.757076, for discriminator pretraining 
epoch 49, samples 454656, loss 0.283715, accuracy 0.886719 BatchTime 1.705380, for discriminator pretraining 
epoch 49, samples 454912, loss 0.603120, accuracy 0.863281 BatchTime 1.820842, for discriminator pretraining 
epoch 49, samples 455168, loss 0.397430, accuracy 0.890625 BatchTime 1.679823, for discriminator pretraining 
epoch 49, samples 455424, loss 0.506876, accuracy 0.855469 BatchTime 1.757790, for discriminator pretraining 
epoch 49, samples 455680, loss 0.579425, accuracy 0.832031 BatchTime 1.657438, for discriminator pretraining 
epoch 49, samples 455936, loss 0.627466, accuracy 0.871094 BatchTime 1.689089, for discriminator pretraining 
epoch 49, samples 456192, loss 0.762545, accuracy 0.839844 BatchTime 1.614988, for discriminator pretraining 
epoch 49, samples 456448, loss 0.610654, accuracy 0.859375 BatchTime 1.642901, for discriminator pretraining 
epoch 49, samples 456704, loss 0.495580, accuracy 0.863281 BatchTime 1.671005, for discriminator pretraining 
epoch 49, samples 456960, loss 0.702216, accuracy 0.871094 BatchTime 1.793398, for discriminator pretraining 
epoch 49, samples 457216, loss 0.537458, accuracy 0.871094 BatchTime 1.725658, for discriminator pretraining 
epoch 49, samples 457472, loss 0.491883, accuracy 0.855469 BatchTime 1.727527, for discriminator pretraining 
epoch 49, samples 457728, loss 0.612191, accuracy 0.843750 BatchTime 1.626330, for discriminator pretraining 
epoch 49, samples 457984, loss 0.650766, accuracy 0.859375 BatchTime 1.704570, for discriminator pretraining 
epoch 49, samples 458240, loss 0.618975, accuracy 0.839844 BatchTime 1.568486, for discriminator pretraining 
epoch 49, samples 458496, loss 0.556168, accuracy 0.855469 BatchTime 1.678030, for discriminator pretraining 
epoch 49, samples 458752, loss 0.647762, accuracy 0.832031 BatchTime 1.670062, for discriminator pretraining 
epoch 49, samples 459008, loss 0.600461, accuracy 0.851562 BatchTime 1.785776, for discriminator pretraining 
epoch 49, samples 459264, loss 0.710388, accuracy 0.843750 BatchTime 1.730325, for discriminator pretraining 
epoch 49, samples 459520, loss 0.681017, accuracy 0.843750 BatchTime 1.731653, for discriminator pretraining 
epoch 49, samples 459776, loss 0.410624, accuracy 0.875000 BatchTime 1.832966, for discriminator pretraining 
epoch 49, samples 460032, loss 0.788240, accuracy 0.800781 BatchTime 1.689332, for discriminator pretraining 
epoch 49, samples 460288, loss 0.444006, accuracy 0.875000 BatchTime 1.628348, for discriminator pretraining 
epoch 49, samples 460544, loss 0.643113, accuracy 0.843750 BatchTime 1.656740, for discriminator pretraining 
epoch 49, samples 460800, loss 0.633311, accuracy 0.833333 BatchTime 0.975022, for discriminator pretraining 
save params when epoch 49, samples 460800
Seen  9002  examples for discriminator. Time Cost :  66.38727927207947
load vocab successfully!!
Epoch : 50
epoch 50, samples 461056, loss 0.449626, accuracy 0.878906 BatchTime 2.676992, for discriminator pretraining 
epoch 50, samples 461312, loss 0.541071, accuracy 0.843750 BatchTime 1.818253, for discriminator pretraining 
epoch 50, samples 461568, loss 0.462243, accuracy 0.867188 BatchTime 1.684138, for discriminator pretraining 
epoch 50, samples 461824, loss 0.350695, accuracy 0.910156 BatchTime 1.689751, for discriminator pretraining 
epoch 50, samples 462080, loss 0.337135, accuracy 0.875000 BatchTime 1.744848, for discriminator pretraining 
epoch 50, samples 462336, loss 0.514568, accuracy 0.843750 BatchTime 1.603007, for discriminator pretraining 
epoch 50, samples 462592, loss 0.589597, accuracy 0.859375 BatchTime 1.751419, for discriminator pretraining 
epoch 50, samples 462848, loss 0.525458, accuracy 0.859375 BatchTime 1.741514, for discriminator pretraining 
epoch 50, samples 463104, loss 0.507685, accuracy 0.875000 BatchTime 1.737835, for discriminator pretraining 
epoch 50, samples 463360, loss 0.431108, accuracy 0.863281 BatchTime 1.629434, for discriminator pretraining 
epoch 50, samples 463616, loss 0.560516, accuracy 0.875000 BatchTime 1.724402, for discriminator pretraining 
epoch 50, samples 463872, loss 0.546488, accuracy 0.859375 BatchTime 1.624554, for discriminator pretraining 
epoch 50, samples 464128, loss 0.422111, accuracy 0.894531 BatchTime 1.676677, for discriminator pretraining 
epoch 50, samples 464384, loss 0.343209, accuracy 0.871094 BatchTime 1.742130, for discriminator pretraining 
epoch 50, samples 464640, loss 0.570418, accuracy 0.847656 BatchTime 1.791372, for discriminator pretraining 
epoch 50, samples 464896, loss 0.530196, accuracy 0.859375 BatchTime 1.634131, for discriminator pretraining 
epoch 50, samples 465152, loss 0.427952, accuracy 0.875000 BatchTime 1.691030, for discriminator pretraining 
epoch 50, samples 465408, loss 0.571065, accuracy 0.843750 BatchTime 1.630449, for discriminator pretraining 
epoch 50, samples 465664, loss 0.599597, accuracy 0.867188 BatchTime 1.705293, for discriminator pretraining 
epoch 50, samples 465920, loss 0.704953, accuracy 0.847656 BatchTime 1.617597, for discriminator pretraining 
epoch 50, samples 466176, loss 0.716200, accuracy 0.847656 BatchTime 1.680398, for discriminator pretraining 
epoch 50, samples 466432, loss 0.392555, accuracy 0.886719 BatchTime 1.644059, for discriminator pretraining 
epoch 50, samples 466688, loss 0.470002, accuracy 0.906250 BatchTime 1.730148, for discriminator pretraining 
epoch 50, samples 466944, loss 0.549967, accuracy 0.859375 BatchTime 1.644657, for discriminator pretraining 
epoch 50, samples 467200, loss 0.676812, accuracy 0.835938 BatchTime 1.665212, for discriminator pretraining 
epoch 50, samples 467456, loss 0.696305, accuracy 0.851562 BatchTime 1.711757, for discriminator pretraining 
epoch 50, samples 467712, loss 0.545960, accuracy 0.843750 BatchTime 1.749352, for discriminator pretraining 
epoch 50, samples 467968, loss 0.856447, accuracy 0.808594 BatchTime 1.649184, for discriminator pretraining 
epoch 50, samples 468224, loss 0.911813, accuracy 0.804688 BatchTime 1.702590, for discriminator pretraining 
epoch 50, samples 468480, loss 0.676265, accuracy 0.835938 BatchTime 1.643675, for discriminator pretraining 
epoch 50, samples 468736, loss 0.585969, accuracy 0.859375 BatchTime 1.752648, for discriminator pretraining 
epoch 50, samples 468992, loss 0.559877, accuracy 0.855469 BatchTime 1.638307, for discriminator pretraining 
epoch 50, samples 469248, loss 0.629245, accuracy 0.824219 BatchTime 1.692911, for discriminator pretraining 
epoch 50, samples 469504, loss 0.886602, accuracy 0.792969 BatchTime 1.657273, for discriminator pretraining 
epoch 50, samples 469760, loss 0.608268, accuracy 0.851562 BatchTime 1.755090, for discriminator pretraining 
epoch 50, samples 470016, loss 0.525726, accuracy 0.833333 BatchTime 0.933218, for discriminator pretraining 
Seen  8996  examples for discriminator. Time Cost :  60.39389204978943
load vocab successfully!!
Epoch : 51
epoch 51, samples 470272, loss 0.371120, accuracy 0.890625 BatchTime 2.913593, for discriminator pretraining 
epoch 51, samples 470528, loss 0.501978, accuracy 0.878906 BatchTime 1.867768, for discriminator pretraining 
epoch 51, samples 470784, loss 0.548200, accuracy 0.878906 BatchTime 1.655648, for discriminator pretraining 
epoch 51, samples 471040, loss 0.501566, accuracy 0.855469 BatchTime 1.652834, for discriminator pretraining 
epoch 51, samples 471296, loss 0.472180, accuracy 0.863281 BatchTime 1.675370, for discriminator pretraining 
epoch 51, samples 471552, loss 0.551976, accuracy 0.839844 BatchTime 1.656132, for discriminator pretraining 
epoch 51, samples 471808, loss 0.402013, accuracy 0.890625 BatchTime 1.631578, for discriminator pretraining 
epoch 51, samples 472064, loss 0.521790, accuracy 0.847656 BatchTime 1.623157, for discriminator pretraining 
epoch 51, samples 472320, loss 0.528347, accuracy 0.859375 BatchTime 1.762620, for discriminator pretraining 
epoch 51, samples 472576, loss 0.348759, accuracy 0.910156 BatchTime 1.762611, for discriminator pretraining 
epoch 51, samples 472832, loss 0.454163, accuracy 0.867188 BatchTime 1.628572, for discriminator pretraining 
epoch 51, samples 473088, loss 0.572848, accuracy 0.843750 BatchTime 1.632276, for discriminator pretraining 
epoch 51, samples 473344, loss 0.523929, accuracy 0.867188 BatchTime 1.704718, for discriminator pretraining 
epoch 51, samples 473600, loss 0.498096, accuracy 0.855469 BatchTime 1.778085, for discriminator pretraining 
epoch 51, samples 473856, loss 0.425530, accuracy 0.867188 BatchTime 1.810185, for discriminator pretraining 
epoch 51, samples 474112, loss 0.562585, accuracy 0.859375 BatchTime 1.618228, for discriminator pretraining 
epoch 51, samples 474368, loss 0.702326, accuracy 0.847656 BatchTime 1.583296, for discriminator pretraining 
epoch 51, samples 474624, loss 0.579561, accuracy 0.871094 BatchTime 1.617106, for discriminator pretraining 
epoch 51, samples 474880, loss 0.627265, accuracy 0.847656 BatchTime 1.638298, for discriminator pretraining 
epoch 51, samples 475136, loss 0.686049, accuracy 0.839844 BatchTime 1.727622, for discriminator pretraining 
epoch 51, samples 475392, loss 0.475575, accuracy 0.875000 BatchTime 1.784597, for discriminator pretraining 
epoch 51, samples 475648, loss 0.528244, accuracy 0.847656 BatchTime 1.630154, for discriminator pretraining 
epoch 51, samples 475904, loss 0.558231, accuracy 0.847656 BatchTime 1.614012, for discriminator pretraining 
epoch 51, samples 476160, loss 0.520504, accuracy 0.847656 BatchTime 1.629118, for discriminator pretraining 
epoch 51, samples 476416, loss 0.578494, accuracy 0.839844 BatchTime 1.633708, for discriminator pretraining 
epoch 51, samples 476672, loss 0.799632, accuracy 0.835938 BatchTime 1.623629, for discriminator pretraining 
epoch 51, samples 476928, loss 0.587770, accuracy 0.855469 BatchTime 1.694310, for discriminator pretraining 
epoch 51, samples 477184, loss 0.497458, accuracy 0.871094 BatchTime 1.755316, for discriminator pretraining 
epoch 51, samples 477440, loss 0.522869, accuracy 0.863281 BatchTime 1.694384, for discriminator pretraining 
epoch 51, samples 477696, loss 0.543655, accuracy 0.851562 BatchTime 1.613674, for discriminator pretraining 
epoch 51, samples 477952, loss 0.729080, accuracy 0.839844 BatchTime 1.631460, for discriminator pretraining 
epoch 51, samples 478208, loss 0.533557, accuracy 0.875000 BatchTime 1.631581, for discriminator pretraining 
epoch 51, samples 478464, loss 0.916846, accuracy 0.812500 BatchTime 1.645460, for discriminator pretraining 
epoch 51, samples 478720, loss 0.732679, accuracy 0.824219 BatchTime 1.636235, for discriminator pretraining 
epoch 51, samples 478976, loss 0.922520, accuracy 0.804688 BatchTime 1.627233, for discriminator pretraining 
epoch 51, samples 479232, loss 1.312185, accuracy 0.764706 BatchTime 0.855718, for discriminator pretraining 
Seen  8994  examples for discriminator. Time Cost :  59.67730116844177
load vocab successfully!!
Epoch : 52
epoch 52, samples 479488, loss 0.348573, accuracy 0.898438 BatchTime 2.714167, for discriminator pretraining 
epoch 52, samples 479744, loss 0.440463, accuracy 0.871094 BatchTime 1.808529, for discriminator pretraining 
epoch 52, samples 480000, loss 0.498534, accuracy 0.851562 BatchTime 1.713746, for discriminator pretraining 
epoch 52, samples 480256, loss 0.606896, accuracy 0.859375 BatchTime 1.586861, for discriminator pretraining 
epoch 52, samples 480512, loss 0.421887, accuracy 0.882812 BatchTime 1.637897, for discriminator pretraining 
epoch 52, samples 480768, loss 0.270704, accuracy 0.906250 BatchTime 1.629179, for discriminator pretraining 
epoch 52, samples 481024, loss 0.391382, accuracy 0.894531 BatchTime 1.668941, for discriminator pretraining 
epoch 52, samples 481280, loss 0.503090, accuracy 0.871094 BatchTime 1.628742, for discriminator pretraining 
epoch 52, samples 481536, loss 0.558386, accuracy 0.839844 BatchTime 1.699447, for discriminator pretraining 
epoch 52, samples 481792, loss 0.613765, accuracy 0.867188 BatchTime 1.775023, for discriminator pretraining 
epoch 52, samples 482048, loss 0.293614, accuracy 0.886719 BatchTime 1.756124, for discriminator pretraining 
epoch 52, samples 482304, loss 0.588365, accuracy 0.878906 BatchTime 1.647353, for discriminator pretraining 
epoch 52, samples 482560, loss 0.633799, accuracy 0.871094 BatchTime 1.669008, for discriminator pretraining 
epoch 52, samples 482816, loss 0.718632, accuracy 0.839844 BatchTime 1.619836, for discriminator pretraining 
epoch 52, samples 483072, loss 0.542843, accuracy 0.863281 BatchTime 1.822654, for discriminator pretraining 
epoch 52, samples 483328, loss 0.617974, accuracy 0.847656 BatchTime 1.762267, for discriminator pretraining 
epoch 52, samples 483584, loss 0.496444, accuracy 0.878906 BatchTime 1.682910, for discriminator pretraining 
epoch 52, samples 483840, loss 0.451012, accuracy 0.863281 BatchTime 1.630751, for discriminator pretraining 
epoch 52, samples 484096, loss 0.569484, accuracy 0.828125 BatchTime 1.623506, for discriminator pretraining 
epoch 52, samples 484352, loss 0.471841, accuracy 0.867188 BatchTime 1.636061, for discriminator pretraining 
epoch 52, samples 484608, loss 0.691584, accuracy 0.863281 BatchTime 1.670689, for discriminator pretraining 
epoch 52, samples 484864, loss 0.561374, accuracy 0.855469 BatchTime 1.646199, for discriminator pretraining 
epoch 52, samples 485120, loss 0.535535, accuracy 0.859375 BatchTime 1.653440, for discriminator pretraining 
epoch 52, samples 485376, loss 0.458842, accuracy 0.878906 BatchTime 1.686264, for discriminator pretraining 
epoch 52, samples 485632, loss 0.655221, accuracy 0.824219 BatchTime 1.775779, for discriminator pretraining 
epoch 52, samples 485888, loss 0.667227, accuracy 0.828125 BatchTime 1.689398, for discriminator pretraining 
epoch 52, samples 486144, loss 0.707382, accuracy 0.828125 BatchTime 1.659477, for discriminator pretraining 
epoch 52, samples 486400, loss 0.637996, accuracy 0.843750 BatchTime 1.632020, for discriminator pretraining 
save params when epoch 52, samples 486400
epoch 52, samples 486656, loss 0.683617, accuracy 0.824219 BatchTime 1.665780, for discriminator pretraining 
epoch 52, samples 486912, loss 0.742738, accuracy 0.820312 BatchTime 1.756179, for discriminator pretraining 
epoch 52, samples 487168, loss 0.892719, accuracy 0.808594 BatchTime 1.755206, for discriminator pretraining 
epoch 52, samples 487424, loss 0.730521, accuracy 0.796875 BatchTime 1.613806, for discriminator pretraining 
epoch 52, samples 487680, loss 0.539839, accuracy 0.871094 BatchTime 1.647401, for discriminator pretraining 
epoch 52, samples 487936, loss 0.569280, accuracy 0.832031 BatchTime 1.637482, for discriminator pretraining 
epoch 52, samples 488192, loss 0.615999, accuracy 0.867188 BatchTime 1.665728, for discriminator pretraining 
epoch 52, samples 488448, loss 0.836738, accuracy 0.833333 BatchTime 0.874855, for discriminator pretraining 
Seen  9002  examples for discriminator. Time Cost :  66.3330934047699
load vocab successfully!!
Epoch : 53
epoch 53, samples 488704, loss 0.402673, accuracy 0.875000 BatchTime 2.745271, for discriminator pretraining 
epoch 53, samples 488960, loss 0.589393, accuracy 0.839844 BatchTime 1.801666, for discriminator pretraining 
epoch 53, samples 489216, loss 0.524405, accuracy 0.859375 BatchTime 1.738931, for discriminator pretraining 
epoch 53, samples 489472, loss 0.546938, accuracy 0.867188 BatchTime 1.758355, for discriminator pretraining 
epoch 53, samples 489728, loss 0.623406, accuracy 0.835938 BatchTime 1.752172, for discriminator pretraining 
epoch 53, samples 489984, loss 0.574508, accuracy 0.882812 BatchTime 1.650906, for discriminator pretraining 
epoch 53, samples 490240, loss 0.376581, accuracy 0.886719 BatchTime 1.694934, for discriminator pretraining 
epoch 53, samples 490496, loss 0.467520, accuracy 0.843750 BatchTime 1.629452, for discriminator pretraining 
epoch 53, samples 490752, loss 0.511811, accuracy 0.871094 BatchTime 1.673897, for discriminator pretraining 
epoch 53, samples 491008, loss 0.454947, accuracy 0.882812 BatchTime 1.623652, for discriminator pretraining 
epoch 53, samples 491264, loss 0.585515, accuracy 0.832031 BatchTime 1.665435, for discriminator pretraining 
epoch 53, samples 491520, loss 0.526989, accuracy 0.859375 BatchTime 1.725167, for discriminator pretraining 
epoch 53, samples 491776, loss 0.493361, accuracy 0.847656 BatchTime 1.661730, for discriminator pretraining 
epoch 53, samples 492032, loss 0.645051, accuracy 0.835938 BatchTime 1.619407, for discriminator pretraining 
epoch 53, samples 492288, loss 0.575201, accuracy 0.843750 BatchTime 1.664829, for discriminator pretraining 
epoch 53, samples 492544, loss 0.565610, accuracy 0.851562 BatchTime 1.618435, for discriminator pretraining 
epoch 53, samples 492800, loss 0.543527, accuracy 0.867188 BatchTime 1.619269, for discriminator pretraining 
epoch 53, samples 493056, loss 0.725800, accuracy 0.835938 BatchTime 1.584212, for discriminator pretraining 
epoch 53, samples 493312, loss 0.595446, accuracy 0.855469 BatchTime 1.652224, for discriminator pretraining 
epoch 53, samples 493568, loss 0.897844, accuracy 0.835938 BatchTime 1.627294, for discriminator pretraining 
epoch 53, samples 493824, loss 0.600368, accuracy 0.843750 BatchTime 1.663622, for discriminator pretraining 
epoch 53, samples 494080, loss 0.363854, accuracy 0.902344 BatchTime 1.629032, for discriminator pretraining 
epoch 53, samples 494336, loss 0.725978, accuracy 0.820312 BatchTime 1.670097, for discriminator pretraining 
epoch 53, samples 494592, loss 0.730614, accuracy 0.855469 BatchTime 1.597612, for discriminator pretraining 
epoch 53, samples 494848, loss 0.682375, accuracy 0.839844 BatchTime 1.662500, for discriminator pretraining 
epoch 53, samples 495104, loss 0.626940, accuracy 0.832031 BatchTime 1.744113, for discriminator pretraining 
epoch 53, samples 495360, loss 0.755534, accuracy 0.820312 BatchTime 1.667197, for discriminator pretraining 
epoch 53, samples 495616, loss 0.629816, accuracy 0.847656 BatchTime 1.620142, for discriminator pretraining 
epoch 53, samples 495872, loss 0.489843, accuracy 0.859375 BatchTime 1.659297, for discriminator pretraining 
epoch 53, samples 496128, loss 0.572155, accuracy 0.859375 BatchTime 1.590494, for discriminator pretraining 
epoch 53, samples 496384, loss 0.572370, accuracy 0.824219 BatchTime 1.586596, for discriminator pretraining 
epoch 53, samples 496640, loss 0.762447, accuracy 0.820312 BatchTime 1.576222, for discriminator pretraining 
epoch 53, samples 496896, loss 0.557971, accuracy 0.886719 BatchTime 1.647696, for discriminator pretraining 
epoch 53, samples 497152, loss 0.485174, accuracy 0.894531 BatchTime 1.631795, for discriminator pretraining 
epoch 53, samples 497408, loss 0.536195, accuracy 0.855469 BatchTime 1.654696, for discriminator pretraining 
epoch 53, samples 497664, loss 0.874302, accuracy 0.750000 BatchTime 0.822114, for discriminator pretraining 
Seen  8992  examples for discriminator. Time Cost :  59.09633827209473
load vocab successfully!!
Epoch : 54
epoch 54, samples 497920, loss 0.386324, accuracy 0.867188 BatchTime 2.541703, for discriminator pretraining 
epoch 54, samples 498176, loss 0.271893, accuracy 0.917969 BatchTime 1.652773, for discriminator pretraining 
epoch 54, samples 498432, loss 0.473094, accuracy 0.867188 BatchTime 1.686095, for discriminator pretraining 
epoch 54, samples 498688, loss 0.461948, accuracy 0.863281 BatchTime 1.618975, for discriminator pretraining 
epoch 54, samples 498944, loss 0.559063, accuracy 0.867188 BatchTime 1.704681, for discriminator pretraining 
epoch 54, samples 499200, loss 0.397398, accuracy 0.878906 BatchTime 1.734655, for discriminator pretraining 
epoch 54, samples 499456, loss 0.678819, accuracy 0.828125 BatchTime 1.799682, for discriminator pretraining 
epoch 54, samples 499712, loss 0.480463, accuracy 0.851562 BatchTime 1.631846, for discriminator pretraining 
epoch 54, samples 499968, loss 0.475480, accuracy 0.855469 BatchTime 1.706768, for discriminator pretraining 
epoch 54, samples 500224, loss 0.413966, accuracy 0.882812 BatchTime 1.633148, for discriminator pretraining 
epoch 54, samples 500480, loss 0.715549, accuracy 0.832031 BatchTime 1.741247, for discriminator pretraining 
epoch 54, samples 500736, loss 0.993354, accuracy 0.804688 BatchTime 1.768832, for discriminator pretraining 
epoch 54, samples 500992, loss 0.549797, accuracy 0.832031 BatchTime 1.732690, for discriminator pretraining 
epoch 54, samples 501248, loss 0.542009, accuracy 0.847656 BatchTime 1.619342, for discriminator pretraining 
epoch 54, samples 501504, loss 0.425614, accuracy 0.878906 BatchTime 1.688544, for discriminator pretraining 
epoch 54, samples 501760, loss 0.618862, accuracy 0.839844 BatchTime 1.867049, for discriminator pretraining 
epoch 54, samples 502016, loss 0.353955, accuracy 0.910156 BatchTime 1.692244, for discriminator pretraining 
epoch 54, samples 502272, loss 0.446221, accuracy 0.875000 BatchTime 1.625137, for discriminator pretraining 
epoch 54, samples 502528, loss 0.647014, accuracy 0.847656 BatchTime 1.690541, for discriminator pretraining 
epoch 54, samples 502784, loss 0.597555, accuracy 0.878906 BatchTime 1.624231, for discriminator pretraining 
epoch 54, samples 503040, loss 0.515379, accuracy 0.867188 BatchTime 1.694129, for discriminator pretraining 
epoch 54, samples 503296, loss 0.573120, accuracy 0.828125 BatchTime 1.656498, for discriminator pretraining 
epoch 54, samples 503552, loss 0.668445, accuracy 0.832031 BatchTime 1.749600, for discriminator pretraining 
epoch 54, samples 503808, loss 0.662428, accuracy 0.843750 BatchTime 1.761014, for discriminator pretraining 
epoch 54, samples 504064, loss 0.672016, accuracy 0.832031 BatchTime 1.744791, for discriminator pretraining 
epoch 54, samples 504320, loss 0.634692, accuracy 0.863281 BatchTime 1.553946, for discriminator pretraining 
epoch 54, samples 504576, loss 0.571806, accuracy 0.843750 BatchTime 1.670175, for discriminator pretraining 
epoch 54, samples 504832, loss 0.421787, accuracy 0.875000 BatchTime 1.635983, for discriminator pretraining 
epoch 54, samples 505088, loss 0.486920, accuracy 0.871094 BatchTime 1.711869, for discriminator pretraining 
epoch 54, samples 505344, loss 0.432676, accuracy 0.871094 BatchTime 1.593787, for discriminator pretraining 
epoch 54, samples 505600, loss 0.715790, accuracy 0.812500 BatchTime 1.685786, for discriminator pretraining 
epoch 54, samples 505856, loss 0.570053, accuracy 0.859375 BatchTime 1.677496, for discriminator pretraining 
epoch 54, samples 506112, loss 0.657500, accuracy 0.843750 BatchTime 1.696032, for discriminator pretraining 
epoch 54, samples 506368, loss 0.590304, accuracy 0.843750 BatchTime 1.714220, for discriminator pretraining 
epoch 54, samples 506624, loss 0.634335, accuracy 0.832031 BatchTime 1.786100, for discriminator pretraining 
epoch 54, samples 506880, loss 0.284149, accuracy 0.880952 BatchTime 0.891278, for discriminator pretraining 
Seen  9002  examples for discriminator. Time Cost :  60.177836418151855
load vocab successfully!!
Epoch : 55
epoch 55, samples 507136, loss 0.555539, accuracy 0.859375 BatchTime 2.771222, for discriminator pretraining 
epoch 55, samples 507392, loss 0.344878, accuracy 0.886719 BatchTime 1.758262, for discriminator pretraining 
epoch 55, samples 507648, loss 0.320263, accuracy 0.886719 BatchTime 1.727946, for discriminator pretraining 
epoch 55, samples 507904, loss 0.529504, accuracy 0.871094 BatchTime 1.684933, for discriminator pretraining 
epoch 55, samples 508160, loss 0.391942, accuracy 0.882812 BatchTime 1.784287, for discriminator pretraining 
epoch 55, samples 508416, loss 0.418175, accuracy 0.871094 BatchTime 1.736999, for discriminator pretraining 
epoch 55, samples 508672, loss 0.419546, accuracy 0.875000 BatchTime 1.754822, for discriminator pretraining 
epoch 55, samples 508928, loss 0.495692, accuracy 0.863281 BatchTime 1.637570, for discriminator pretraining 
epoch 55, samples 509184, loss 0.584555, accuracy 0.859375 BatchTime 1.737557, for discriminator pretraining 
epoch 55, samples 509440, loss 0.490736, accuracy 0.886719 BatchTime 1.654080, for discriminator pretraining 
epoch 55, samples 509696, loss 0.615040, accuracy 0.835938 BatchTime 1.725691, for discriminator pretraining 
epoch 55, samples 509952, loss 0.540726, accuracy 0.871094 BatchTime 1.669842, for discriminator pretraining 
epoch 55, samples 510208, loss 0.702383, accuracy 0.863281 BatchTime 1.764423, for discriminator pretraining 
epoch 55, samples 510464, loss 0.494034, accuracy 0.878906 BatchTime 1.793809, for discriminator pretraining 
epoch 55, samples 510720, loss 0.621661, accuracy 0.859375 BatchTime 1.796500, for discriminator pretraining 
epoch 55, samples 510976, loss 0.476917, accuracy 0.843750 BatchTime 1.646837, for discriminator pretraining 
epoch 55, samples 511232, loss 0.543806, accuracy 0.851562 BatchTime 1.740312, for discriminator pretraining 
epoch 55, samples 511488, loss 0.620217, accuracy 0.843750 BatchTime 1.631399, for discriminator pretraining 
epoch 55, samples 511744, loss 0.947069, accuracy 0.816406 BatchTime 1.692687, for discriminator pretraining 
------------------------------------------Hour 1 --------------------
epoch 55, samples 512000, loss 0.719717, accuracy 0.839844 BatchTime 1.652052, for discriminator pretraining 
save params when epoch 55, samples 512000
testing the accuracy on the evaluation sets
epoch 55, samples 512256, loss 0.594888, accuracy 0.871094 BatchTime 1.778883, for discriminator pretraining 
epoch 55, samples 512512, loss 0.530012, accuracy 0.855469 BatchTime 1.748369, for discriminator pretraining 
epoch 55, samples 512768, loss 0.664358, accuracy 0.847656 BatchTime 1.693925, for discriminator pretraining 
epoch 55, samples 513024, loss 0.644368, accuracy 0.812500 BatchTime 1.619500, for discriminator pretraining 
epoch 55, samples 513280, loss 0.474461, accuracy 0.882812 BatchTime 1.720216, for discriminator pretraining 
epoch 55, samples 513536, loss 0.460186, accuracy 0.902344 BatchTime 1.616867, for discriminator pretraining 
epoch 55, samples 513792, loss 0.478333, accuracy 0.878906 BatchTime 1.678955, for discriminator pretraining 
epoch 55, samples 514048, loss 0.638540, accuracy 0.843750 BatchTime 1.743853, for discriminator pretraining 
epoch 55, samples 514304, loss 0.514230, accuracy 0.871094 BatchTime 1.786529, for discriminator pretraining 
epoch 55, samples 514560, loss 0.556182, accuracy 0.863281 BatchTime 1.633450, for discriminator pretraining 
epoch 55, samples 514816, loss 0.616950, accuracy 0.839844 BatchTime 1.677690, for discriminator pretraining 
epoch 55, samples 515072, loss 0.719691, accuracy 0.832031 BatchTime 1.642498, for discriminator pretraining 
epoch 55, samples 515328, loss 0.972673, accuracy 0.812500 BatchTime 1.722148, for discriminator pretraining 
epoch 55, samples 515584, loss 0.892776, accuracy 0.804688 BatchTime 1.625273, for discriminator pretraining 
epoch 55, samples 515840, loss 0.657555, accuracy 0.851562 BatchTime 1.672183, for discriminator pretraining 
epoch 55, samples 516096, loss 0.665743, accuracy 0.857143 BatchTime 0.834870, for discriminator pretraining 
Seen  8988  examples for discriminator. Time Cost :  67.15339207649231
load vocab successfully!!
Epoch : 56
epoch 56, samples 516352, loss 0.260523, accuracy 0.886719 BatchTime 2.651291, for discriminator pretraining 
epoch 56, samples 516608, loss 0.364987, accuracy 0.875000 BatchTime 1.652071, for discriminator pretraining 
epoch 56, samples 516864, loss 0.678729, accuracy 0.832031 BatchTime 1.617797, for discriminator pretraining 
epoch 56, samples 517120, loss 0.618022, accuracy 0.843750 BatchTime 1.620397, for discriminator pretraining 
epoch 56, samples 517376, loss 0.442808, accuracy 0.882812 BatchTime 1.749181, for discriminator pretraining 
epoch 56, samples 517632, loss 0.346870, accuracy 0.851562 BatchTime 1.743443, for discriminator pretraining 
epoch 56, samples 517888, loss 0.540317, accuracy 0.855469 BatchTime 1.705033, for discriminator pretraining 
epoch 56, samples 518144, loss 0.542415, accuracy 0.855469 BatchTime 1.632480, for discriminator pretraining 
epoch 56, samples 518400, loss 0.508545, accuracy 0.847656 BatchTime 1.650407, for discriminator pretraining 
epoch 56, samples 518656, loss 0.506261, accuracy 0.859375 BatchTime 1.592533, for discriminator pretraining 
epoch 56, samples 518912, loss 0.317190, accuracy 0.910156 BatchTime 1.623394, for discriminator pretraining 
epoch 56, samples 519168, loss 0.515614, accuracy 0.820312 BatchTime 1.626695, for discriminator pretraining 
epoch 56, samples 519424, loss 0.505214, accuracy 0.878906 BatchTime 1.671884, for discriminator pretraining 
epoch 56, samples 519680, loss 0.445111, accuracy 0.859375 BatchTime 1.616690, for discriminator pretraining 
epoch 56, samples 519936, loss 0.403108, accuracy 0.878906 BatchTime 1.737661, for discriminator pretraining 
epoch 56, samples 520192, loss 0.597842, accuracy 0.867188 BatchTime 1.722546, for discriminator pretraining 
epoch 56, samples 520448, loss 0.531628, accuracy 0.882812 BatchTime 1.684383, for discriminator pretraining 
epoch 56, samples 520704, loss 0.518439, accuracy 0.851562 BatchTime 1.675004, for discriminator pretraining 
epoch 56, samples 520960, loss 0.498138, accuracy 0.875000 BatchTime 1.637263, for discriminator pretraining 
epoch 56, samples 521216, loss 0.568138, accuracy 0.851562 BatchTime 1.643355, for discriminator pretraining 
epoch 56, samples 521472, loss 0.617264, accuracy 0.847656 BatchTime 1.663322, for discriminator pretraining 
epoch 56, samples 521728, loss 0.589743, accuracy 0.847656 BatchTime 1.644032, for discriminator pretraining 
epoch 56, samples 521984, loss 0.405904, accuracy 0.910156 BatchTime 1.630919, for discriminator pretraining 
epoch 56, samples 522240, loss 0.716249, accuracy 0.820312 BatchTime 1.617021, for discriminator pretraining 
epoch 56, samples 522496, loss 0.854060, accuracy 0.816406 BatchTime 1.744562, for discriminator pretraining 
epoch 56, samples 522752, loss 0.621670, accuracy 0.839844 BatchTime 1.615499, for discriminator pretraining 
epoch 56, samples 523008, loss 0.609093, accuracy 0.847656 BatchTime 1.745492, for discriminator pretraining 
epoch 56, samples 523264, loss 0.623641, accuracy 0.824219 BatchTime 1.759870, for discriminator pretraining 
epoch 56, samples 523520, loss 0.571441, accuracy 0.839844 BatchTime 1.688521, for discriminator pretraining 
epoch 56, samples 523776, loss 0.481866, accuracy 0.882812 BatchTime 1.636022, for discriminator pretraining 
epoch 56, samples 524032, loss 0.497242, accuracy 0.875000 BatchTime 1.660861, for discriminator pretraining 
epoch 56, samples 524288, loss 0.715322, accuracy 0.847656 BatchTime 1.644205, for discriminator pretraining 
epoch 56, samples 524544, loss 0.492964, accuracy 0.882812 BatchTime 1.655808, for discriminator pretraining 
epoch 56, samples 524800, loss 0.433211, accuracy 0.878906 BatchTime 1.655260, for discriminator pretraining 
epoch 56, samples 525056, loss 0.712258, accuracy 0.839844 BatchTime 1.757659, for discriminator pretraining 
epoch 56, samples 525312, loss 0.679254, accuracy 0.800000 BatchTime 0.843777, for discriminator pretraining 
Seen  8990  examples for discriminator. Time Cost :  59.40433430671692
load vocab successfully!!
Epoch : 57
epoch 57, samples 525568, loss 0.563435, accuracy 0.859375 BatchTime 2.625030, for discriminator pretraining 
epoch 57, samples 525824, loss 0.502916, accuracy 0.882812 BatchTime 1.741198, for discriminator pretraining 
epoch 57, samples 526080, loss 0.397025, accuracy 0.863281 BatchTime 1.663318, for discriminator pretraining 
epoch 57, samples 526336, loss 0.445460, accuracy 0.890625 BatchTime 1.624117, for discriminator pretraining 
epoch 57, samples 526592, loss 0.438221, accuracy 0.863281 BatchTime 1.676272, for discriminator pretraining 
epoch 57, samples 526848, loss 0.520428, accuracy 0.871094 BatchTime 1.681541, for discriminator pretraining 
epoch 57, samples 527104, loss 0.371607, accuracy 0.867188 BatchTime 1.705094, for discriminator pretraining 
epoch 57, samples 527360, loss 0.343594, accuracy 0.890625 BatchTime 1.692872, for discriminator pretraining 
epoch 57, samples 527616, loss 0.458156, accuracy 0.839844 BatchTime 1.734596, for discriminator pretraining 
epoch 57, samples 527872, loss 0.408247, accuracy 0.875000 BatchTime 1.594342, for discriminator pretraining 
epoch 57, samples 528128, loss 0.428829, accuracy 0.867188 BatchTime 1.657429, for discriminator pretraining 
epoch 57, samples 528384, loss 0.489532, accuracy 0.878906 BatchTime 1.636806, for discriminator pretraining 
epoch 57, samples 528640, loss 0.553051, accuracy 0.855469 BatchTime 1.661657, for discriminator pretraining 
epoch 57, samples 528896, loss 0.468308, accuracy 0.871094 BatchTime 1.655173, for discriminator pretraining 
epoch 57, samples 529152, loss 0.780446, accuracy 0.847656 BatchTime 1.738527, for discriminator pretraining 
epoch 57, samples 529408, loss 0.651802, accuracy 0.843750 BatchTime 1.722281, for discriminator pretraining 
epoch 57, samples 529664, loss 0.581538, accuracy 0.855469 BatchTime 1.650370, for discriminator pretraining 
epoch 57, samples 529920, loss 0.393398, accuracy 0.875000 BatchTime 1.649696, for discriminator pretraining 
epoch 57, samples 530176, loss 0.541365, accuracy 0.847656 BatchTime 1.635916, for discriminator pretraining 
epoch 57, samples 530432, loss 0.765534, accuracy 0.832031 BatchTime 1.725993, for discriminator pretraining 
epoch 57, samples 530688, loss 0.744654, accuracy 0.835938 BatchTime 1.713674, for discriminator pretraining 
epoch 57, samples 530944, loss 0.639472, accuracy 0.867188 BatchTime 1.628940, for discriminator pretraining 
epoch 57, samples 531200, loss 0.542614, accuracy 0.832031 BatchTime 1.590460, for discriminator pretraining 
epoch 57, samples 531456, loss 0.320789, accuracy 0.902344 BatchTime 1.599017, for discriminator pretraining 
epoch 57, samples 531712, loss 0.673176, accuracy 0.824219 BatchTime 1.704639, for discriminator pretraining 
epoch 57, samples 531968, loss 0.859314, accuracy 0.835938 BatchTime 1.784839, for discriminator pretraining 
epoch 57, samples 532224, loss 0.565099, accuracy 0.843750 BatchTime 1.726022, for discriminator pretraining 
epoch 57, samples 532480, loss 0.486055, accuracy 0.871094 BatchTime 1.625207, for discriminator pretraining 
epoch 57, samples 532736, loss 0.493103, accuracy 0.843750 BatchTime 1.653130, for discriminator pretraining 
epoch 57, samples 532992, loss 0.793543, accuracy 0.816406 BatchTime 1.636457, for discriminator pretraining 
epoch 57, samples 533248, loss 0.759009, accuracy 0.835938 BatchTime 1.695035, for discriminator pretraining 
epoch 57, samples 533504, loss 0.522963, accuracy 0.828125 BatchTime 1.765625, for discriminator pretraining 
epoch 57, samples 533760, loss 0.715208, accuracy 0.851562 BatchTime 1.776273, for discriminator pretraining 
epoch 57, samples 534016, loss 0.595769, accuracy 0.855469 BatchTime 1.638329, for discriminator pretraining 
epoch 57, samples 534272, loss 0.672206, accuracy 0.847656 BatchTime 1.673940, for discriminator pretraining 
epoch 57, samples 534528, loss 0.906231, accuracy 0.794118 BatchTime 0.840365, for discriminator pretraining 
Seen  8994  examples for discriminator. Time Cost :  59.688437700271606
load vocab successfully!!
Epoch : 58
epoch 58, samples 534784, loss 0.297462, accuracy 0.894531 BatchTime 2.639196, for discriminator pretraining 
epoch 58, samples 535040, loss 0.707899, accuracy 0.824219 BatchTime 1.769079, for discriminator pretraining 
epoch 58, samples 535296, loss 0.511050, accuracy 0.867188 BatchTime 1.697487, for discriminator pretraining 
epoch 58, samples 535552, loss 0.477987, accuracy 0.871094 BatchTime 1.624672, for discriminator pretraining 
epoch 58, samples 535808, loss 0.502768, accuracy 0.882812 BatchTime 1.667781, for discriminator pretraining 
epoch 58, samples 536064, loss 0.482137, accuracy 0.882812 BatchTime 1.744190, for discriminator pretraining 
epoch 58, samples 536320, loss 0.399899, accuracy 0.894531 BatchTime 1.739810, for discriminator pretraining 
epoch 58, samples 536576, loss 0.557561, accuracy 0.847656 BatchTime 1.644295, for discriminator pretraining 
epoch 58, samples 536832, loss 0.661422, accuracy 0.824219 BatchTime 1.631693, for discriminator pretraining 
epoch 58, samples 537088, loss 0.616013, accuracy 0.851562 BatchTime 1.632106, for discriminator pretraining 
epoch 58, samples 537344, loss 0.515033, accuracy 0.875000 BatchTime 1.631184, for discriminator pretraining 
epoch 58, samples 537600, loss 0.510347, accuracy 0.839844 BatchTime 1.758207, for discriminator pretraining 
save params when epoch 58, samples 537600
epoch 58, samples 537856, loss 0.601171, accuracy 0.820312 BatchTime 1.772642, for discriminator pretraining 
epoch 58, samples 538112, loss 0.374187, accuracy 0.863281 BatchTime 1.623916, for discriminator pretraining 
epoch 58, samples 538368, loss 0.477210, accuracy 0.890625 BatchTime 1.647797, for discriminator pretraining 
epoch 58, samples 538624, loss 0.614771, accuracy 0.835938 BatchTime 1.732425, for discriminator pretraining 
epoch 58, samples 538880, loss 0.526838, accuracy 0.867188 BatchTime 1.727517, for discriminator pretraining 
epoch 58, samples 539136, loss 0.521664, accuracy 0.878906 BatchTime 1.614200, for discriminator pretraining 
epoch 58, samples 539392, loss 0.501728, accuracy 0.851562 BatchTime 1.669858, for discriminator pretraining 
epoch 58, samples 539648, loss 0.575773, accuracy 0.851562 BatchTime 1.646976, for discriminator pretraining 
epoch 58, samples 539904, loss 0.568270, accuracy 0.835938 BatchTime 1.730769, for discriminator pretraining 
epoch 58, samples 540160, loss 0.469830, accuracy 0.871094 BatchTime 1.731587, for discriminator pretraining 
epoch 58, samples 540416, loss 0.513858, accuracy 0.878906 BatchTime 1.713543, for discriminator pretraining 
epoch 58, samples 540672, loss 0.558219, accuracy 0.851562 BatchTime 1.628763, for discriminator pretraining 
epoch 58, samples 540928, loss 0.543566, accuracy 0.863281 BatchTime 1.669375, for discriminator pretraining 
epoch 58, samples 541184, loss 0.624405, accuracy 0.867188 BatchTime 1.614459, for discriminator pretraining 
epoch 58, samples 541440, loss 0.566840, accuracy 0.886719 BatchTime 1.687318, for discriminator pretraining 
epoch 58, samples 541696, loss 0.609038, accuracy 0.855469 BatchTime 1.665325, for discriminator pretraining 
epoch 58, samples 541952, loss 0.466205, accuracy 0.843750 BatchTime 1.743825, for discriminator pretraining 
epoch 58, samples 542208, loss 0.592229, accuracy 0.859375 BatchTime 1.681577, for discriminator pretraining 
epoch 58, samples 542464, loss 0.510934, accuracy 0.855469 BatchTime 1.615875, for discriminator pretraining 
epoch 58, samples 542720, loss 0.556271, accuracy 0.863281 BatchTime 1.650263, for discriminator pretraining 
epoch 58, samples 542976, loss 0.520331, accuracy 0.851562 BatchTime 1.709678, for discriminator pretraining 
epoch 58, samples 543232, loss 0.542562, accuracy 0.863281 BatchTime 1.746728, for discriminator pretraining 
epoch 58, samples 543488, loss 0.640375, accuracy 0.839844 BatchTime 1.725057, for discriminator pretraining 
epoch 58, samples 543744, loss 0.748586, accuracy 0.823529 BatchTime 0.884235, for discriminator pretraining 
Seen  8994  examples for discriminator. Time Cost :  65.69967746734619
load vocab successfully!!
Epoch : 59
epoch 59, samples 544000, loss 0.297575, accuracy 0.910156 BatchTime 2.647832, for discriminator pretraining 
epoch 59, samples 544256, loss 0.445510, accuracy 0.886719 BatchTime 1.770504, for discriminator pretraining 
epoch 59, samples 544512, loss 0.609904, accuracy 0.847656 BatchTime 1.976003, for discriminator pretraining 
epoch 59, samples 544768, loss 0.539725, accuracy 0.871094 BatchTime 1.740841, for discriminator pretraining 
epoch 59, samples 545024, loss 0.484169, accuracy 0.859375 BatchTime 1.746071, for discriminator pretraining 
epoch 59, samples 545280, loss 0.333282, accuracy 0.894531 BatchTime 1.686850, for discriminator pretraining 
epoch 59, samples 545536, loss 0.498490, accuracy 0.882812 BatchTime 1.687106, for discriminator pretraining 
epoch 59, samples 545792, loss 0.636169, accuracy 0.835938 BatchTime 1.630629, for discriminator pretraining 
epoch 59, samples 546048, loss 0.535892, accuracy 0.851562 BatchTime 1.714008, for discriminator pretraining 
epoch 59, samples 546304, loss 0.436595, accuracy 0.882812 BatchTime 1.629936, for discriminator pretraining 
epoch 59, samples 546560, loss 0.504501, accuracy 0.824219 BatchTime 1.717217, for discriminator pretraining 
epoch 59, samples 546816, loss 0.367959, accuracy 0.906250 BatchTime 1.635131, for discriminator pretraining 
epoch 59, samples 547072, loss 0.578038, accuracy 0.847656 BatchTime 1.820284, for discriminator pretraining 
epoch 59, samples 547328, loss 0.523062, accuracy 0.855469 BatchTime 1.760768, for discriminator pretraining 
epoch 59, samples 547584, loss 0.412360, accuracy 0.867188 BatchTime 1.688914, for discriminator pretraining 
epoch 59, samples 547840, loss 0.472558, accuracy 0.851562 BatchTime 1.628499, for discriminator pretraining 
epoch 59, samples 548096, loss 0.506697, accuracy 0.839844 BatchTime 1.704614, for discriminator pretraining 
epoch 59, samples 548352, loss 0.589079, accuracy 0.832031 BatchTime 1.761876, for discriminator pretraining 
epoch 59, samples 548608, loss 0.465276, accuracy 0.859375 BatchTime 1.793856, for discriminator pretraining 
epoch 59, samples 548864, loss 0.446916, accuracy 0.871094 BatchTime 1.636005, for discriminator pretraining 
epoch 59, samples 549120, loss 0.498892, accuracy 0.867188 BatchTime 1.683149, for discriminator pretraining 
epoch 59, samples 549376, loss 0.737742, accuracy 0.839844 BatchTime 1.629346, for discriminator pretraining 
epoch 59, samples 549632, loss 0.527965, accuracy 0.875000 BatchTime 1.695966, for discriminator pretraining 
epoch 59, samples 549888, loss 0.518090, accuracy 0.859375 BatchTime 1.624777, for discriminator pretraining 
epoch 59, samples 550144, loss 0.734260, accuracy 0.804688 BatchTime 1.752899, for discriminator pretraining 
epoch 59, samples 550400, loss 0.611392, accuracy 0.882812 BatchTime 1.752504, for discriminator pretraining 
epoch 59, samples 550656, loss 0.558404, accuracy 0.863281 BatchTime 1.716043, for discriminator pretraining 
epoch 59, samples 550912, loss 0.748873, accuracy 0.812500 BatchTime 1.618611, for discriminator pretraining 
epoch 59, samples 551168, loss 0.822129, accuracy 0.808594 BatchTime 1.713264, for discriminator pretraining 
epoch 59, samples 551424, loss 0.797199, accuracy 0.820312 BatchTime 1.627102, for discriminator pretraining 
epoch 59, samples 551680, loss 0.664926, accuracy 0.839844 BatchTime 1.691516, for discriminator pretraining 
epoch 59, samples 551936, loss 0.601456, accuracy 0.847656 BatchTime 1.627828, for discriminator pretraining 
epoch 59, samples 552192, loss 0.795768, accuracy 0.812500 BatchTime 1.810169, for discriminator pretraining 
epoch 59, samples 552448, loss 0.605201, accuracy 0.851562 BatchTime 1.761306, for discriminator pretraining 
epoch 59, samples 552704, loss 0.691341, accuracy 0.808594 BatchTime 1.698755, for discriminator pretraining 
epoch 59, samples 552960, loss 0.086849, accuracy 0.944444 BatchTime 0.802797, for discriminator pretraining 
Seen  8978  examples for discriminator. Time Cost :  60.7411584854126
load vocab successfully!!
Epoch : 60
epoch 60, samples 553216, loss 0.324966, accuracy 0.867188 BatchTime 2.571244, for discriminator pretraining 
epoch 60, samples 553472, loss 0.434584, accuracy 0.875000 BatchTime 1.762509, for discriminator pretraining 
epoch 60, samples 553728, loss 0.485883, accuracy 0.875000 BatchTime 1.705725, for discriminator pretraining 
epoch 60, samples 553984, loss 0.580968, accuracy 0.859375 BatchTime 1.615378, for discriminator pretraining 
epoch 60, samples 554240, loss 0.691990, accuracy 0.851562 BatchTime 1.634640, for discriminator pretraining 
epoch 60, samples 554496, loss 0.582950, accuracy 0.878906 BatchTime 1.618412, for discriminator pretraining 
epoch 60, samples 554752, loss 0.401369, accuracy 0.882812 BatchTime 1.681519, for discriminator pretraining 
epoch 60, samples 555008, loss 0.358270, accuracy 0.882812 BatchTime 1.678198, for discriminator pretraining 
epoch 60, samples 555264, loss 0.623491, accuracy 0.847656 BatchTime 1.773343, for discriminator pretraining 
epoch 60, samples 555520, loss 0.505939, accuracy 0.855469 BatchTime 1.689572, for discriminator pretraining 
epoch 60, samples 555776, loss 0.383901, accuracy 0.859375 BatchTime 1.722451, for discriminator pretraining 
epoch 60, samples 556032, loss 0.343377, accuracy 0.886719 BatchTime 1.583098, for discriminator pretraining 
epoch 60, samples 556288, loss 0.704099, accuracy 0.828125 BatchTime 1.659013, for discriminator pretraining 
epoch 60, samples 556544, loss 0.664874, accuracy 0.851562 BatchTime 1.736994, for discriminator pretraining 
epoch 60, samples 556800, loss 0.582209, accuracy 0.843750 BatchTime 1.756711, for discriminator pretraining 
epoch 60, samples 557056, loss 0.532535, accuracy 0.863281 BatchTime 1.648998, for discriminator pretraining 
epoch 60, samples 557312, loss 0.548252, accuracy 0.878906 BatchTime 1.660913, for discriminator pretraining 
epoch 60, samples 557568, loss 0.506287, accuracy 0.851562 BatchTime 1.652519, for discriminator pretraining 
epoch 60, samples 557824, loss 0.670386, accuracy 0.835938 BatchTime 1.630151, for discriminator pretraining 
epoch 60, samples 558080, loss 0.557351, accuracy 0.863281 BatchTime 1.632332, for discriminator pretraining 
epoch 60, samples 558336, loss 0.495387, accuracy 0.894531 BatchTime 1.765193, for discriminator pretraining 
epoch 60, samples 558592, loss 0.454300, accuracy 0.863281 BatchTime 1.725007, for discriminator pretraining 
epoch 60, samples 558848, loss 0.536059, accuracy 0.859375 BatchTime 1.736510, for discriminator pretraining 
epoch 60, samples 559104, loss 0.741762, accuracy 0.824219 BatchTime 1.635942, for discriminator pretraining 
epoch 60, samples 559360, loss 0.412680, accuracy 0.847656 BatchTime 1.770926, for discriminator pretraining 
epoch 60, samples 559616, loss 0.458768, accuracy 0.851562 BatchTime 1.747105, for discriminator pretraining 
epoch 60, samples 559872, loss 0.673082, accuracy 0.843750 BatchTime 1.723071, for discriminator pretraining 
epoch 60, samples 560128, loss 0.540183, accuracy 0.859375 BatchTime 1.654861, for discriminator pretraining 
epoch 60, samples 560384, loss 0.609535, accuracy 0.843750 BatchTime 1.658114, for discriminator pretraining 
epoch 60, samples 560640, loss 0.503846, accuracy 0.871094 BatchTime 1.637331, for discriminator pretraining 
epoch 60, samples 560896, loss 0.633911, accuracy 0.843750 BatchTime 1.717940, for discriminator pretraining 
epoch 60, samples 561152, loss 0.671400, accuracy 0.832031 BatchTime 1.691319, for discriminator pretraining 
epoch 60, samples 561408, loss 0.702589, accuracy 0.812500 BatchTime 1.783571, for discriminator pretraining 
epoch 60, samples 561664, loss 0.756375, accuracy 0.832031 BatchTime 1.704017, for discriminator pretraining 
epoch 60, samples 561920, loss 0.540568, accuracy 0.855469 BatchTime 1.716686, for discriminator pretraining 
epoch 60, samples 562176, loss 0.063064, accuracy 0.964286 BatchTime 0.842592, for discriminator pretraining 
Seen  8988  examples for discriminator. Time Cost :  60.13948392868042
load vocab successfully!!
Epoch : 61
epoch 61, samples 562432, loss 0.360989, accuracy 0.875000 BatchTime 2.562181, for discriminator pretraining 
epoch 61, samples 562688, loss 0.349692, accuracy 0.894531 BatchTime 1.753714, for discriminator pretraining 
epoch 61, samples 562944, loss 0.290863, accuracy 0.894531 BatchTime 1.739256, for discriminator pretraining 
epoch 61, samples 563200, loss 0.469618, accuracy 0.835938 BatchTime 1.589295, for discriminator pretraining 
save params when epoch 61, samples 563200
epoch 61, samples 563456, loss 0.693929, accuracy 0.839844 BatchTime 1.733122, for discriminator pretraining 
epoch 61, samples 563712, loss 0.630764, accuracy 0.851562 BatchTime 1.755148, for discriminator pretraining 
epoch 61, samples 563968, loss 0.542602, accuracy 0.875000 BatchTime 1.709215, for discriminator pretraining 
epoch 61, samples 564224, loss 0.390510, accuracy 0.875000 BatchTime 1.629395, for discriminator pretraining 
epoch 61, samples 564480, loss 0.493762, accuracy 0.871094 BatchTime 1.692806, for discriminator pretraining 
epoch 61, samples 564736, loss 0.535175, accuracy 0.863281 BatchTime 1.636933, for discriminator pretraining 
epoch 61, samples 564992, loss 0.394232, accuracy 0.886719 BatchTime 1.733709, for discriminator pretraining 
epoch 61, samples 565248, loss 0.519702, accuracy 0.859375 BatchTime 1.650938, for discriminator pretraining 
epoch 61, samples 565504, loss 0.377993, accuracy 0.886719 BatchTime 1.696463, for discriminator pretraining 
epoch 61, samples 565760, loss 0.559749, accuracy 0.843750 BatchTime 1.775578, for discriminator pretraining 
epoch 61, samples 566016, loss 0.507068, accuracy 0.851562 BatchTime 1.818538, for discriminator pretraining 
epoch 61, samples 566272, loss 0.540566, accuracy 0.847656 BatchTime 1.692754, for discriminator pretraining 
epoch 61, samples 566528, loss 0.254570, accuracy 0.917969 BatchTime 1.737215, for discriminator pretraining 
epoch 61, samples 566784, loss 0.427518, accuracy 0.871094 BatchTime 1.692883, for discriminator pretraining 
epoch 61, samples 567040, loss 0.594049, accuracy 0.851562 BatchTime 1.793231, for discriminator pretraining 
epoch 61, samples 567296, loss 0.563381, accuracy 0.847656 BatchTime 1.661508, for discriminator pretraining 
epoch 61, samples 567552, loss 0.651401, accuracy 0.828125 BatchTime 1.704486, for discriminator pretraining 
epoch 61, samples 567808, loss 0.610002, accuracy 0.820312 BatchTime 1.676615, for discriminator pretraining 
epoch 61, samples 568064, loss 0.612586, accuracy 0.832031 BatchTime 1.794790, for discriminator pretraining 
epoch 61, samples 568320, loss 0.500749, accuracy 0.843750 BatchTime 1.756965, for discriminator pretraining 
epoch 61, samples 568576, loss 0.509700, accuracy 0.871094 BatchTime 1.716111, for discriminator pretraining 
epoch 61, samples 568832, loss 0.410845, accuracy 0.894531 BatchTime 1.630551, for discriminator pretraining 
epoch 61, samples 569088, loss 0.505684, accuracy 0.875000 BatchTime 1.726348, for discriminator pretraining 
epoch 61, samples 569344, loss 0.822397, accuracy 0.843750 BatchTime 1.630758, for discriminator pretraining 
epoch 61, samples 569600, loss 0.706397, accuracy 0.832031 BatchTime 1.756765, for discriminator pretraining 
epoch 61, samples 569856, loss 0.710416, accuracy 0.785156 BatchTime 1.753893, for discriminator pretraining 
epoch 61, samples 570112, loss 0.688830, accuracy 0.859375 BatchTime 1.736436, for discriminator pretraining 
epoch 61, samples 570368, loss 0.767795, accuracy 0.832031 BatchTime 1.617785, for discriminator pretraining 
epoch 61, samples 570624, loss 0.838213, accuracy 0.812500 BatchTime 1.668788, for discriminator pretraining 
epoch 61, samples 570880, loss 0.680695, accuracy 0.847656 BatchTime 1.629058, for discriminator pretraining 
epoch 61, samples 571136, loss 0.487360, accuracy 0.851562 BatchTime 1.813556, for discriminator pretraining 
epoch 61, samples 571392, loss 0.704482, accuracy 0.815789 BatchTime 1.009533, for discriminator pretraining 
Seen  8998  examples for discriminator. Time Cost :  66.26992416381836
load vocab successfully!!
Epoch : 62
epoch 62, samples 571648, loss 0.394389, accuracy 0.886719 BatchTime 2.679690, for discriminator pretraining 
epoch 62, samples 571904, loss 0.557796, accuracy 0.839844 BatchTime 1.781587, for discriminator pretraining 
epoch 62, samples 572160, loss 0.400289, accuracy 0.878906 BatchTime 1.719328, for discriminator pretraining 
epoch 62, samples 572416, loss 0.336106, accuracy 0.882812 BatchTime 1.631208, for discriminator pretraining 
epoch 62, samples 572672, loss 0.437934, accuracy 0.878906 BatchTime 1.679631, for discriminator pretraining 
epoch 62, samples 572928, loss 0.398403, accuracy 0.882812 BatchTime 1.676893, for discriminator pretraining 
epoch 62, samples 573184, loss 0.383803, accuracy 0.867188 BatchTime 1.792907, for discriminator pretraining 
epoch 62, samples 573440, loss 0.402828, accuracy 0.863281 BatchTime 1.700878, for discriminator pretraining 
epoch 62, samples 573696, loss 0.620849, accuracy 0.847656 BatchTime 1.674818, for discriminator pretraining 
epoch 62, samples 573952, loss 0.461300, accuracy 0.875000 BatchTime 1.626291, for discriminator pretraining 
epoch 62, samples 574208, loss 0.387921, accuracy 0.859375 BatchTime 1.682591, for discriminator pretraining 
epoch 62, samples 574464, loss 0.580268, accuracy 0.851562 BatchTime 1.651201, for discriminator pretraining 
epoch 62, samples 574720, loss 0.631083, accuracy 0.867188 BatchTime 1.701229, for discriminator pretraining 
epoch 62, samples 574976, loss 0.444882, accuracy 0.867188 BatchTime 1.637559, for discriminator pretraining 
epoch 62, samples 575232, loss 0.460038, accuracy 0.894531 BatchTime 1.785329, for discriminator pretraining 
epoch 62, samples 575488, loss 0.594440, accuracy 0.824219 BatchTime 1.759575, for discriminator pretraining 
epoch 62, samples 575744, loss 0.471691, accuracy 0.878906 BatchTime 1.717615, for discriminator pretraining 
epoch 62, samples 576000, loss 0.619828, accuracy 0.847656 BatchTime 1.596833, for discriminator pretraining 
epoch 62, samples 576256, loss 0.690386, accuracy 0.835938 BatchTime 1.698144, for discriminator pretraining 
epoch 62, samples 576512, loss 0.677199, accuracy 0.812500 BatchTime 1.622273, for discriminator pretraining 
epoch 62, samples 576768, loss 0.673757, accuracy 0.832031 BatchTime 1.723474, for discriminator pretraining 
epoch 62, samples 577024, loss 0.613498, accuracy 0.867188 BatchTime 1.733146, for discriminator pretraining 
epoch 62, samples 577280, loss 0.480786, accuracy 0.898438 BatchTime 1.679286, for discriminator pretraining 
epoch 62, samples 577536, loss 0.418803, accuracy 0.863281 BatchTime 1.632072, for discriminator pretraining 
epoch 62, samples 577792, loss 0.488716, accuracy 0.886719 BatchTime 1.721632, for discriminator pretraining 
epoch 62, samples 578048, loss 0.410753, accuracy 0.886719 BatchTime 1.622872, for discriminator pretraining 
epoch 62, samples 578304, loss 0.533547, accuracy 0.867188 BatchTime 1.702572, for discriminator pretraining 
epoch 62, samples 578560, loss 0.717468, accuracy 0.832031 BatchTime 1.732473, for discriminator pretraining 
epoch 62, samples 578816, loss 0.448976, accuracy 0.890625 BatchTime 1.801577, for discriminator pretraining 
epoch 62, samples 579072, loss 0.588411, accuracy 0.851562 BatchTime 1.611686, for discriminator pretraining 
epoch 62, samples 579328, loss 0.352040, accuracy 0.863281 BatchTime 1.697015, for discriminator pretraining 
epoch 62, samples 579584, loss 0.545595, accuracy 0.828125 BatchTime 1.617296, for discriminator pretraining 
epoch 62, samples 579840, loss 0.597912, accuracy 0.820312 BatchTime 1.744771, for discriminator pretraining 
epoch 62, samples 580096, loss 0.469242, accuracy 0.855469 BatchTime 1.763408, for discriminator pretraining 
epoch 62, samples 580352, loss 0.712555, accuracy 0.843750 BatchTime 1.784408, for discriminator pretraining 
epoch 62, samples 580608, loss 0.514617, accuracy 0.888889 BatchTime 0.862250, for discriminator pretraining 
Seen  8996  examples for discriminator. Time Cost :  60.39526176452637
load vocab successfully!!
Epoch : 63
epoch 63, samples 580864, loss 0.370619, accuracy 0.875000 BatchTime 2.657201, for discriminator pretraining 
epoch 63, samples 581120, loss 0.588821, accuracy 0.859375 BatchTime 1.767381, for discriminator pretraining 
epoch 63, samples 581376, loss 0.413558, accuracy 0.890625 BatchTime 1.808885, for discriminator pretraining 
epoch 63, samples 581632, loss 0.486792, accuracy 0.878906 BatchTime 1.780784, for discriminator pretraining 
epoch 63, samples 581888, loss 0.505861, accuracy 0.859375 BatchTime 1.697963, for discriminator pretraining 
epoch 63, samples 582144, loss 0.556391, accuracy 0.859375 BatchTime 1.626212, for discriminator pretraining 
epoch 63, samples 582400, loss 0.527409, accuracy 0.863281 BatchTime 1.745513, for discriminator pretraining 
epoch 63, samples 582656, loss 0.544415, accuracy 0.843750 BatchTime 1.767572, for discriminator pretraining 
epoch 63, samples 582912, loss 0.369984, accuracy 0.878906 BatchTime 1.764036, for discriminator pretraining 
epoch 63, samples 583168, loss 0.412956, accuracy 0.871094 BatchTime 1.623572, for discriminator pretraining 
epoch 63, samples 583424, loss 0.546925, accuracy 0.867188 BatchTime 1.729688, for discriminator pretraining 
epoch 63, samples 583680, loss 0.600639, accuracy 0.835938 BatchTime 1.627071, for discriminator pretraining 
epoch 63, samples 583936, loss 0.383132, accuracy 0.914062 BatchTime 1.718357, for discriminator pretraining 
epoch 63, samples 584192, loss 0.418645, accuracy 0.867188 BatchTime 1.644334, for discriminator pretraining 
epoch 63, samples 584448, loss 0.458118, accuracy 0.867188 BatchTime 1.689849, for discriminator pretraining 
epoch 63, samples 584704, loss 0.547991, accuracy 0.859375 BatchTime 1.754395, for discriminator pretraining 
epoch 63, samples 584960, loss 0.476379, accuracy 0.859375 BatchTime 1.860798, for discriminator pretraining 
epoch 63, samples 585216, loss 0.545109, accuracy 0.871094 BatchTime 1.640056, for discriminator pretraining 
epoch 63, samples 585472, loss 0.405975, accuracy 0.875000 BatchTime 1.762676, for discriminator pretraining 
epoch 63, samples 585728, loss 0.501668, accuracy 0.886719 BatchTime 1.840095, for discriminator pretraining 
epoch 63, samples 585984, loss 0.514406, accuracy 0.839844 BatchTime 1.806042, for discriminator pretraining 
epoch 63, samples 586240, loss 0.573016, accuracy 0.855469 BatchTime 1.673580, for discriminator pretraining 
epoch 63, samples 586496, loss 0.624356, accuracy 0.851562 BatchTime 1.783771, for discriminator pretraining 
epoch 63, samples 586752, loss 0.840989, accuracy 0.828125 BatchTime 1.790608, for discriminator pretraining 
epoch 63, samples 587008, loss 0.734195, accuracy 0.859375 BatchTime 1.812459, for discriminator pretraining 
epoch 63, samples 587264, loss 0.530334, accuracy 0.835938 BatchTime 1.654906, for discriminator pretraining 
epoch 63, samples 587520, loss 0.578967, accuracy 0.847656 BatchTime 1.791945, for discriminator pretraining 
epoch 63, samples 587776, loss 0.754376, accuracy 0.812500 BatchTime 1.782722, for discriminator pretraining 
epoch 63, samples 588032, loss 0.391029, accuracy 0.878906 BatchTime 1.833831, for discriminator pretraining 
epoch 63, samples 588288, loss 0.478460, accuracy 0.867188 BatchTime 1.659052, for discriminator pretraining 
epoch 63, samples 588544, loss 0.615957, accuracy 0.847656 BatchTime 1.737057, for discriminator pretraining 
epoch 63, samples 588800, loss 0.782052, accuracy 0.816406 BatchTime 1.642805, for discriminator pretraining 
save params when epoch 63, samples 588800
epoch 63, samples 589056, loss 0.720799, accuracy 0.789062 BatchTime 1.788736, for discriminator pretraining 
epoch 63, samples 589312, loss 0.789826, accuracy 0.828125 BatchTime 1.743735, for discriminator pretraining 
epoch 63, samples 589568, loss 0.680915, accuracy 0.835938 BatchTime 1.786009, for discriminator pretraining 
epoch 63, samples 589824, loss 0.706414, accuracy 0.840909 BatchTime 0.992812, for discriminator pretraining 
Seen  9004  examples for discriminator. Time Cost :  67.18368816375732
load vocab successfully!!
Epoch : 64
epoch 64, samples 590080, loss 0.399981, accuracy 0.882812 BatchTime 2.791711, for discriminator pretraining 
epoch 64, samples 590336, loss 0.595294, accuracy 0.812500 BatchTime 1.899154, for discriminator pretraining 
epoch 64, samples 590592, loss 0.478100, accuracy 0.898438 BatchTime 1.732409, for discriminator pretraining 
epoch 64, samples 590848, loss 0.451725, accuracy 0.863281 BatchTime 1.673903, for discriminator pretraining 
epoch 64, samples 591104, loss 0.514599, accuracy 0.894531 BatchTime 1.688550, for discriminator pretraining 
epoch 64, samples 591360, loss 0.448689, accuracy 0.863281 BatchTime 1.718420, for discriminator pretraining 
epoch 64, samples 591616, loss 0.315374, accuracy 0.886719 BatchTime 1.758056, for discriminator pretraining 
epoch 64, samples 591872, loss 0.587509, accuracy 0.847656 BatchTime 1.659059, for discriminator pretraining 
epoch 64, samples 592128, loss 0.459426, accuracy 0.871094 BatchTime 1.660372, for discriminator pretraining 
epoch 64, samples 592384, loss 0.430306, accuracy 0.859375 BatchTime 1.627447, for discriminator pretraining 
epoch 64, samples 592640, loss 0.432648, accuracy 0.859375 BatchTime 1.684380, for discriminator pretraining 
epoch 64, samples 592896, loss 0.331920, accuracy 0.902344 BatchTime 1.637004, for discriminator pretraining 
epoch 64, samples 593152, loss 0.564544, accuracy 0.835938 BatchTime 1.733800, for discriminator pretraining 
epoch 64, samples 593408, loss 0.556653, accuracy 0.859375 BatchTime 1.651599, for discriminator pretraining 
epoch 64, samples 593664, loss 0.484998, accuracy 0.871094 BatchTime 1.727679, for discriminator pretraining 
epoch 64, samples 593920, loss 0.568492, accuracy 0.835938 BatchTime 1.721200, for discriminator pretraining 
epoch 64, samples 594176, loss 0.585231, accuracy 0.824219 BatchTime 1.675949, for discriminator pretraining 
epoch 64, samples 594432, loss 0.603340, accuracy 0.843750 BatchTime 1.649476, for discriminator pretraining 
epoch 64, samples 594688, loss 0.618416, accuracy 0.843750 BatchTime 1.777141, for discriminator pretraining 
epoch 64, samples 594944, loss 0.307499, accuracy 0.894531 BatchTime 1.706958, for discriminator pretraining 
epoch 64, samples 595200, loss 0.482387, accuracy 0.886719 BatchTime 1.682683, for discriminator pretraining 
epoch 64, samples 595456, loss 0.577524, accuracy 0.855469 BatchTime 1.686506, for discriminator pretraining 
epoch 64, samples 595712, loss 0.679278, accuracy 0.835938 BatchTime 1.797384, for discriminator pretraining 
epoch 64, samples 595968, loss 0.464995, accuracy 0.867188 BatchTime 1.675025, for discriminator pretraining 
epoch 64, samples 596224, loss 0.574123, accuracy 0.832031 BatchTime 1.662209, for discriminator pretraining 
epoch 64, samples 596480, loss 0.652176, accuracy 0.855469 BatchTime 1.623037, for discriminator pretraining 
epoch 64, samples 596736, loss 0.670573, accuracy 0.824219 BatchTime 1.677274, for discriminator pretraining 
epoch 64, samples 596992, loss 0.565692, accuracy 0.839844 BatchTime 1.708512, for discriminator pretraining 
epoch 64, samples 597248, loss 0.619650, accuracy 0.839844 BatchTime 1.760295, for discriminator pretraining 
epoch 64, samples 597504, loss 0.575516, accuracy 0.863281 BatchTime 1.667014, for discriminator pretraining 
epoch 64, samples 597760, loss 0.675574, accuracy 0.859375 BatchTime 1.672940, for discriminator pretraining 
epoch 64, samples 598016, loss 0.513006, accuracy 0.882812 BatchTime 1.684933, for discriminator pretraining 
epoch 64, samples 598272, loss 0.547693, accuracy 0.855469 BatchTime 1.773118, for discriminator pretraining 
epoch 64, samples 598528, loss 0.567706, accuracy 0.871094 BatchTime 1.655349, for discriminator pretraining 
epoch 64, samples 598784, loss 0.467814, accuracy 0.863281 BatchTime 1.648638, for discriminator pretraining 
epoch 64, samples 599040, loss 0.297861, accuracy 0.909091 BatchTime 0.840468, for discriminator pretraining 
Seen  8982  examples for discriminator. Time Cost :  60.48794889450073
load vocab successfully!!
Epoch : 65
epoch 65, samples 599296, loss 0.319816, accuracy 0.878906 BatchTime 2.639842, for discriminator pretraining 
epoch 65, samples 599552, loss 0.254154, accuracy 0.929688 BatchTime 1.812725, for discriminator pretraining 
epoch 65, samples 599808, loss 0.282140, accuracy 0.875000 BatchTime 1.762016, for discriminator pretraining 
epoch 65, samples 600064, loss 0.625406, accuracy 0.855469 BatchTime 1.733728, for discriminator pretraining 
epoch 65, samples 600320, loss 0.538419, accuracy 0.871094 BatchTime 1.701530, for discriminator pretraining 
epoch 65, samples 600576, loss 0.529938, accuracy 0.851562 BatchTime 1.611776, for discriminator pretraining 
epoch 65, samples 600832, loss 0.611326, accuracy 0.863281 BatchTime 1.689045, for discriminator pretraining 
epoch 65, samples 601088, loss 0.549010, accuracy 0.851562 BatchTime 1.637521, for discriminator pretraining 
epoch 65, samples 601344, loss 0.442319, accuracy 0.890625 BatchTime 1.679569, for discriminator pretraining 
epoch 65, samples 601600, loss 0.524346, accuracy 0.875000 BatchTime 1.619375, for discriminator pretraining 
epoch 65, samples 601856, loss 0.339467, accuracy 0.894531 BatchTime 1.703283, for discriminator pretraining 
epoch 65, samples 602112, loss 0.438325, accuracy 0.863281 BatchTime 1.628757, for discriminator pretraining 
epoch 65, samples 602368, loss 0.560179, accuracy 0.859375 BatchTime 1.700385, for discriminator pretraining 
epoch 65, samples 602624, loss 0.532672, accuracy 0.855469 BatchTime 1.644474, for discriminator pretraining 
epoch 65, samples 602880, loss 0.699274, accuracy 0.832031 BatchTime 1.736376, for discriminator pretraining 
epoch 65, samples 603136, loss 0.533820, accuracy 0.875000 BatchTime 1.691849, for discriminator pretraining 
epoch 65, samples 603392, loss 0.586200, accuracy 0.851562 BatchTime 1.783138, for discriminator pretraining 
epoch 65, samples 603648, loss 0.570556, accuracy 0.859375 BatchTime 1.710292, for discriminator pretraining 
epoch 65, samples 603904, loss 0.658991, accuracy 0.828125 BatchTime 1.706900, for discriminator pretraining 
epoch 65, samples 604160, loss 0.530339, accuracy 0.875000 BatchTime 1.620902, for discriminator pretraining 
epoch 65, samples 604416, loss 0.561572, accuracy 0.855469 BatchTime 1.695791, for discriminator pretraining 
epoch 65, samples 604672, loss 0.743859, accuracy 0.824219 BatchTime 1.631089, for discriminator pretraining 
epoch 65, samples 604928, loss 0.609001, accuracy 0.832031 BatchTime 1.687816, for discriminator pretraining 
epoch 65, samples 605184, loss 0.735744, accuracy 0.835938 BatchTime 1.755679, for discriminator pretraining 
epoch 65, samples 605440, loss 0.471887, accuracy 0.863281 BatchTime 1.779277, for discriminator pretraining 
epoch 65, samples 605696, loss 0.581413, accuracy 0.835938 BatchTime 1.679702, for discriminator pretraining 
epoch 65, samples 605952, loss 0.481812, accuracy 0.851562 BatchTime 1.639315, for discriminator pretraining 
epoch 65, samples 606208, loss 0.599059, accuracy 0.839844 BatchTime 1.619720, for discriminator pretraining 
epoch 65, samples 606464, loss 0.590383, accuracy 0.835938 BatchTime 1.707682, for discriminator pretraining 
epoch 65, samples 606720, loss 0.568244, accuracy 0.843750 BatchTime 1.594695, for discriminator pretraining 
epoch 65, samples 606976, loss 0.744590, accuracy 0.835938 BatchTime 1.763517, for discriminator pretraining 
epoch 65, samples 607232, loss 0.677043, accuracy 0.859375 BatchTime 1.741089, for discriminator pretraining 
epoch 65, samples 607488, loss 0.554448, accuracy 0.847656 BatchTime 1.703166, for discriminator pretraining 
epoch 65, samples 607744, loss 0.554586, accuracy 0.843750 BatchTime 1.624126, for discriminator pretraining 
epoch 65, samples 608000, loss 0.456706, accuracy 0.851562 BatchTime 1.703227, for discriminator pretraining 
epoch 65, samples 608256, loss 0.683025, accuracy 0.764706 BatchTime 0.870312, for discriminator pretraining 
Seen  8994  examples for discriminator. Time Cost :  60.17245888710022
load vocab successfully!!
Epoch : 66
epoch 66, samples 608512, loss 0.310764, accuracy 0.902344 BatchTime 2.773854, for discriminator pretraining 
epoch 66, samples 608768, loss 0.474395, accuracy 0.839844 BatchTime 1.860560, for discriminator pretraining 
epoch 66, samples 609024, loss 0.532365, accuracy 0.886719 BatchTime 1.793255, for discriminator pretraining 
epoch 66, samples 609280, loss 0.462718, accuracy 0.890625 BatchTime 1.673205, for discriminator pretraining 
epoch 66, samples 609536, loss 0.372524, accuracy 0.875000 BatchTime 1.705532, for discriminator pretraining 
epoch 66, samples 609792, loss 0.403129, accuracy 0.890625 BatchTime 1.625273, for discriminator pretraining 
epoch 66, samples 610048, loss 0.407680, accuracy 0.871094 BatchTime 1.686038, for discriminator pretraining 
epoch 66, samples 610304, loss 0.430164, accuracy 0.867188 BatchTime 1.657459, for discriminator pretraining 
epoch 66, samples 610560, loss 0.316284, accuracy 0.882812 BatchTime 1.667284, for discriminator pretraining 
epoch 66, samples 610816, loss 0.438110, accuracy 0.871094 BatchTime 1.631616, for discriminator pretraining 
epoch 66, samples 611072, loss 0.366914, accuracy 0.878906 BatchTime 1.713078, for discriminator pretraining 
epoch 66, samples 611328, loss 0.523314, accuracy 0.847656 BatchTime 1.634640, for discriminator pretraining 
epoch 66, samples 611584, loss 0.559497, accuracy 0.867188 BatchTime 1.727654, for discriminator pretraining 
epoch 66, samples 611840, loss 0.603087, accuracy 0.847656 BatchTime 1.790978, for discriminator pretraining 
epoch 66, samples 612096, loss 0.534460, accuracy 0.882812 BatchTime 1.820783, for discriminator pretraining 
epoch 66, samples 612352, loss 0.605532, accuracy 0.851562 BatchTime 1.687726, for discriminator pretraining 
epoch 66, samples 612608, loss 0.441724, accuracy 0.890625 BatchTime 1.804226, for discriminator pretraining 
epoch 66, samples 612864, loss 0.520755, accuracy 0.832031 BatchTime 1.691249, for discriminator pretraining 
epoch 66, samples 613120, loss 0.623284, accuracy 0.863281 BatchTime 1.689551, for discriminator pretraining 
epoch 66, samples 613376, loss 0.515456, accuracy 0.867188 BatchTime 1.612083, for discriminator pretraining 
epoch 66, samples 613632, loss 0.685394, accuracy 0.816406 BatchTime 1.709124, for discriminator pretraining 
epoch 66, samples 613888, loss 0.588727, accuracy 0.847656 BatchTime 1.736936, for discriminator pretraining 
epoch 66, samples 614144, loss 0.505602, accuracy 0.859375 BatchTime 1.771104, for discriminator pretraining 
epoch 66, samples 614400, loss 0.487384, accuracy 0.851562 BatchTime 1.686135, for discriminator pretraining 
save params when epoch 66, samples 614400
epoch 66, samples 614656, loss 0.440133, accuracy 0.867188 BatchTime 1.703626, for discriminator pretraining 
epoch 66, samples 614912, loss 0.703557, accuracy 0.832031 BatchTime 1.759731, for discriminator pretraining 
epoch 66, samples 615168, loss 0.777738, accuracy 0.855469 BatchTime 1.709494, for discriminator pretraining 
epoch 66, samples 615424, loss 0.701885, accuracy 0.835938 BatchTime 1.628922, for discriminator pretraining 
epoch 66, samples 615680, loss 0.461120, accuracy 0.867188 BatchTime 1.706934, for discriminator pretraining 
epoch 66, samples 615936, loss 0.629449, accuracy 0.812500 BatchTime 1.605307, for discriminator pretraining 
epoch 66, samples 616192, loss 0.601067, accuracy 0.839844 BatchTime 1.674229, for discriminator pretraining 
epoch 66, samples 616448, loss 0.551501, accuracy 0.859375 BatchTime 1.650607, for discriminator pretraining 
epoch 66, samples 616704, loss 0.393356, accuracy 0.863281 BatchTime 1.755208, for discriminator pretraining 
epoch 66, samples 616960, loss 0.833819, accuracy 0.820312 BatchTime 1.744306, for discriminator pretraining 
epoch 66, samples 617216, loss 0.719353, accuracy 0.820312 BatchTime 1.745684, for discriminator pretraining 
epoch 66, samples 617472, loss 0.888401, accuracy 0.766667 BatchTime 0.844312, for discriminator pretraining 
Seen  8990  examples for discriminator. Time Cost :  66.71012353897095
load vocab successfully!!
Epoch : 67
epoch 67, samples 617728, loss 0.202526, accuracy 0.917969 BatchTime 2.572708, for discriminator pretraining 
epoch 67, samples 617984, loss 0.405178, accuracy 0.875000 BatchTime 1.769828, for discriminator pretraining 
epoch 67, samples 618240, loss 0.318559, accuracy 0.917969 BatchTime 1.643507, for discriminator pretraining 
epoch 67, samples 618496, loss 0.487583, accuracy 0.855469 BatchTime 1.639288, for discriminator pretraining 
epoch 67, samples 618752, loss 0.536669, accuracy 0.855469 BatchTime 1.729090, for discriminator pretraining 
epoch 67, samples 619008, loss 0.546052, accuracy 0.855469 BatchTime 1.648916, for discriminator pretraining 
epoch 67, samples 619264, loss 0.805648, accuracy 0.828125 BatchTime 1.797871, for discriminator pretraining 
epoch 67, samples 619520, loss 0.502475, accuracy 0.863281 BatchTime 1.714257, for discriminator pretraining 
epoch 67, samples 619776, loss 0.421945, accuracy 0.878906 BatchTime 1.718986, for discriminator pretraining 
epoch 67, samples 620032, loss 0.500136, accuracy 0.882812 BatchTime 1.628524, for discriminator pretraining 
epoch 67, samples 620288, loss 0.552302, accuracy 0.855469 BatchTime 1.695768, for discriminator pretraining 
epoch 67, samples 620544, loss 0.619452, accuracy 0.867188 BatchTime 1.617023, for discriminator pretraining 
epoch 67, samples 620800, loss 0.372182, accuracy 0.890625 BatchTime 1.706942, for discriminator pretraining 
epoch 67, samples 621056, loss 0.536366, accuracy 0.847656 BatchTime 1.630540, for discriminator pretraining 
epoch 67, samples 621312, loss 0.381129, accuracy 0.898438 BatchTime 1.681037, for discriminator pretraining 
epoch 67, samples 621568, loss 0.448937, accuracy 0.875000 BatchTime 1.731074, for discriminator pretraining 
epoch 67, samples 621824, loss 0.463757, accuracy 0.859375 BatchTime 1.806942, for discriminator pretraining 
epoch 67, samples 622080, loss 0.572661, accuracy 0.847656 BatchTime 1.618667, for discriminator pretraining 
epoch 67, samples 622336, loss 0.467699, accuracy 0.851562 BatchTime 1.670989, for discriminator pretraining 
epoch 67, samples 622592, loss 0.217359, accuracy 0.917969 BatchTime 1.656417, for discriminator pretraining 
epoch 67, samples 622848, loss 0.594033, accuracy 0.851562 BatchTime 1.796461, for discriminator pretraining 
epoch 67, samples 623104, loss 0.609531, accuracy 0.839844 BatchTime 1.709266, for discriminator pretraining 
epoch 67, samples 623360, loss 0.518615, accuracy 0.843750 BatchTime 1.720536, for discriminator pretraining 
epoch 67, samples 623616, loss 0.536614, accuracy 0.871094 BatchTime 1.627494, for discriminator pretraining 
epoch 67, samples 623872, loss 0.541150, accuracy 0.863281 BatchTime 1.729317, for discriminator pretraining 
epoch 67, samples 624128, loss 0.512233, accuracy 0.867188 BatchTime 1.663480, for discriminator pretraining 
epoch 67, samples 624384, loss 0.426210, accuracy 0.894531 BatchTime 1.688884, for discriminator pretraining 
epoch 67, samples 624640, loss 0.595312, accuracy 0.843750 BatchTime 1.695987, for discriminator pretraining 
epoch 67, samples 624896, loss 0.533827, accuracy 0.839844 BatchTime 1.805365, for discriminator pretraining 
epoch 67, samples 625152, loss 0.744994, accuracy 0.824219 BatchTime 1.622619, for discriminator pretraining 
epoch 67, samples 625408, loss 0.574599, accuracy 0.832031 BatchTime 1.650846, for discriminator pretraining 
epoch 67, samples 625664, loss 0.594030, accuracy 0.859375 BatchTime 1.631553, for discriminator pretraining 
epoch 67, samples 625920, loss 0.645588, accuracy 0.843750 BatchTime 1.714425, for discriminator pretraining 
epoch 67, samples 626176, loss 0.474055, accuracy 0.882812 BatchTime 1.720019, for discriminator pretraining 
epoch 67, samples 626432, loss 0.606678, accuracy 0.835938 BatchTime 1.735988, for discriminator pretraining 
epoch 67, samples 626688, loss 0.614079, accuracy 0.894737 BatchTime 0.876161, for discriminator pretraining 
Seen  8998  examples for discriminator. Time Cost :  60.325735092163086
load vocab successfully!!
Epoch : 68
epoch 68, samples 626944, loss 0.353938, accuracy 0.886719 BatchTime 2.730335, for discriminator pretraining 
epoch 68, samples 627200, loss 0.454810, accuracy 0.863281 BatchTime 1.798881, for discriminator pretraining 
epoch 68, samples 627456, loss 0.266735, accuracy 0.902344 BatchTime 1.862560, for discriminator pretraining 
epoch 68, samples 627712, loss 0.224826, accuracy 0.914062 BatchTime 1.733121, for discriminator pretraining 
epoch 68, samples 627968, loss 0.314505, accuracy 0.878906 BatchTime 1.740285, for discriminator pretraining 
epoch 68, samples 628224, loss 0.534154, accuracy 0.843750 BatchTime 1.626964, for discriminator pretraining 
epoch 68, samples 628480, loss 0.590523, accuracy 0.847656 BatchTime 1.704218, for discriminator pretraining 
epoch 68, samples 628736, loss 0.443004, accuracy 0.871094 BatchTime 1.739660, for discriminator pretraining 
epoch 68, samples 628992, loss 0.515866, accuracy 0.851562 BatchTime 1.772312, for discriminator pretraining 
epoch 68, samples 629248, loss 0.411504, accuracy 0.875000 BatchTime 1.614592, for discriminator pretraining 
epoch 68, samples 629504, loss 0.450993, accuracy 0.886719 BatchTime 1.713519, for discriminator pretraining 
epoch 68, samples 629760, loss 0.527143, accuracy 0.855469 BatchTime 1.632014, for discriminator pretraining 
epoch 68, samples 630016, loss 0.602905, accuracy 0.859375 BatchTime 1.775075, for discriminator pretraining 
epoch 68, samples 630272, loss 0.629832, accuracy 0.843750 BatchTime 1.648969, for discriminator pretraining 
epoch 68, samples 630528, loss 0.474785, accuracy 0.863281 BatchTime 1.789676, for discriminator pretraining 
epoch 68, samples 630784, loss 0.433379, accuracy 0.882812 BatchTime 1.738247, for discriminator pretraining 
epoch 68, samples 631040, loss 0.474654, accuracy 0.851562 BatchTime 1.944185, for discriminator pretraining 
epoch 68, samples 631296, loss 0.550989, accuracy 0.843750 BatchTime 1.622900, for discriminator pretraining 
epoch 68, samples 631552, loss 0.447263, accuracy 0.859375 BatchTime 1.697797, for discriminator pretraining 
epoch 68, samples 631808, loss 0.671055, accuracy 0.812500 BatchTime 1.629493, for discriminator pretraining 
epoch 68, samples 632064, loss 0.540522, accuracy 0.859375 BatchTime 1.708301, for discriminator pretraining 
epoch 68, samples 632320, loss 0.626039, accuracy 0.851562 BatchTime 1.748141, for discriminator pretraining 
epoch 68, samples 632576, loss 0.607988, accuracy 0.847656 BatchTime 1.796774, for discriminator pretraining 
epoch 68, samples 632832, loss 0.639998, accuracy 0.812500 BatchTime 1.620433, for discriminator pretraining 
epoch 68, samples 633088, loss 0.678100, accuracy 0.843750 BatchTime 1.712843, for discriminator pretraining 
epoch 68, samples 633344, loss 0.503318, accuracy 0.875000 BatchTime 1.635823, for discriminator pretraining 
epoch 68, samples 633600, loss 0.595077, accuracy 0.835938 BatchTime 1.681627, for discriminator pretraining 
epoch 68, samples 633856, loss 0.549979, accuracy 0.882812 BatchTime 1.656603, for discriminator pretraining 
epoch 68, samples 634112, loss 0.607898, accuracy 0.843750 BatchTime 1.774840, for discriminator pretraining 
epoch 68, samples 634368, loss 0.512466, accuracy 0.855469 BatchTime 1.736464, for discriminator pretraining 
epoch 68, samples 634624, loss 0.565248, accuracy 0.839844 BatchTime 1.738016, for discriminator pretraining 
epoch 68, samples 634880, loss 0.423445, accuracy 0.847656 BatchTime 1.624834, for discriminator pretraining 
epoch 68, samples 635136, loss 0.705464, accuracy 0.871094 BatchTime 1.705273, for discriminator pretraining 
epoch 68, samples 635392, loss 0.615216, accuracy 0.843750 BatchTime 1.615178, for discriminator pretraining 
epoch 68, samples 635648, loss 0.875801, accuracy 0.781250 BatchTime 1.713755, for discriminator pretraining 
epoch 68, samples 635904, loss 0.628478, accuracy 0.880952 BatchTime 0.873112, for discriminator pretraining 
Seen  9002  examples for discriminator. Time Cost :  61.02952837944031
load vocab successfully!!
Epoch : 69
epoch 69, samples 636160, loss 0.364517, accuracy 0.898438 BatchTime 2.622899, for discriminator pretraining 
epoch 69, samples 636416, loss 0.523133, accuracy 0.863281 BatchTime 1.877771, for discriminator pretraining 
epoch 69, samples 636672, loss 0.462140, accuracy 0.878906 BatchTime 1.815010, for discriminator pretraining 
epoch 69, samples 636928, loss 0.573053, accuracy 0.851562 BatchTime 1.570346, for discriminator pretraining 
epoch 69, samples 637184, loss 0.503845, accuracy 0.871094 BatchTime 1.675500, for discriminator pretraining 
epoch 69, samples 637440, loss 0.354809, accuracy 0.878906 BatchTime 1.658527, for discriminator pretraining 
epoch 69, samples 637696, loss 0.461350, accuracy 0.851562 BatchTime 1.746423, for discriminator pretraining 
epoch 69, samples 637952, loss 0.476192, accuracy 0.863281 BatchTime 1.629261, for discriminator pretraining 
epoch 69, samples 638208, loss 0.482396, accuracy 0.859375 BatchTime 1.739702, for discriminator pretraining 
epoch 69, samples 638464, loss 0.461126, accuracy 0.894531 BatchTime 1.704789, for discriminator pretraining 
epoch 69, samples 638720, loss 0.596467, accuracy 0.863281 BatchTime 1.796935, for discriminator pretraining 
epoch 69, samples 638976, loss 0.351145, accuracy 0.871094 BatchTime 1.697950, for discriminator pretraining 
epoch 69, samples 639232, loss 0.437660, accuracy 0.863281 BatchTime 1.735773, for discriminator pretraining 
epoch 69, samples 639488, loss 0.413614, accuracy 0.890625 BatchTime 1.655745, for discriminator pretraining 
epoch 69, samples 639744, loss 0.496930, accuracy 0.871094 BatchTime 1.739729, for discriminator pretraining 
epoch 69, samples 640000, loss 0.433907, accuracy 0.878906 BatchTime 1.630032, for discriminator pretraining 
save params when epoch 69, samples 640000
epoch 69, samples 640256, loss 0.339753, accuracy 0.886719 BatchTime 1.842668, for discriminator pretraining 
epoch 69, samples 640512, loss 0.580492, accuracy 0.843750 BatchTime 1.752902, for discriminator pretraining 
epoch 69, samples 640768, loss 0.409990, accuracy 0.890625 BatchTime 1.732141, for discriminator pretraining 
epoch 69, samples 641024, loss 0.410802, accuracy 0.871094 BatchTime 1.659625, for discriminator pretraining 
epoch 69, samples 641280, loss 0.474709, accuracy 0.867188 BatchTime 1.727465, for discriminator pretraining 
epoch 69, samples 641536, loss 0.489899, accuracy 0.859375 BatchTime 1.774816, for discriminator pretraining 
epoch 69, samples 641792, loss 0.496538, accuracy 0.828125 BatchTime 1.799320, for discriminator pretraining 
epoch 69, samples 642048, loss 0.560521, accuracy 0.808594 BatchTime 1.594374, for discriminator pretraining 
epoch 69, samples 642304, loss 0.425823, accuracy 0.886719 BatchTime 1.723946, for discriminator pretraining 
epoch 69, samples 642560, loss 0.352703, accuracy 0.886719 BatchTime 1.755578, for discriminator pretraining 
epoch 69, samples 642816, loss 0.631950, accuracy 0.824219 BatchTime 1.806109, for discriminator pretraining 
epoch 69, samples 643072, loss 0.726774, accuracy 0.820312 BatchTime 1.617200, for discriminator pretraining 
epoch 69, samples 643328, loss 0.849573, accuracy 0.800781 BatchTime 1.735591, for discriminator pretraining 
epoch 69, samples 643584, loss 0.693760, accuracy 0.828125 BatchTime 1.650090, for discriminator pretraining 
epoch 69, samples 643840, loss 0.599203, accuracy 0.851562 BatchTime 1.780656, for discriminator pretraining 
epoch 69, samples 644096, loss 0.598459, accuracy 0.843750 BatchTime 1.775055, for discriminator pretraining 
epoch 69, samples 644352, loss 0.547503, accuracy 0.839844 BatchTime 1.753464, for discriminator pretraining 
epoch 69, samples 644608, loss 0.518480, accuracy 0.851562 BatchTime 1.602322, for discriminator pretraining 
epoch 69, samples 644864, loss 0.513026, accuracy 0.843750 BatchTime 1.728980, for discriminator pretraining 
epoch 69, samples 645120, loss 0.480755, accuracy 0.852941 BatchTime 0.863362, for discriminator pretraining 
Seen  8994  examples for discriminator. Time Cost :  67.11292290687561
load vocab successfully!!
Epoch : 70
epoch 70, samples 645376, loss 0.405470, accuracy 0.863281 BatchTime 2.690801, for discriminator pretraining 
epoch 70, samples 645632, loss 0.394764, accuracy 0.878906 BatchTime 1.836271, for discriminator pretraining 
epoch 70, samples 645888, loss 0.434411, accuracy 0.871094 BatchTime 1.816205, for discriminator pretraining 
epoch 70, samples 646144, loss 0.426320, accuracy 0.878906 BatchTime 1.630386, for discriminator pretraining 
epoch 70, samples 646400, loss 0.412382, accuracy 0.875000 BatchTime 1.712852, for discriminator pretraining 
epoch 70, samples 646656, loss 0.473267, accuracy 0.867188 BatchTime 1.640145, for discriminator pretraining 
epoch 70, samples 646912, loss 0.331516, accuracy 0.894531 BatchTime 1.747953, for discriminator pretraining 
epoch 70, samples 647168, loss 0.415063, accuracy 0.863281 BatchTime 1.641840, for discriminator pretraining 
epoch 70, samples 647424, loss 0.494738, accuracy 0.871094 BatchTime 1.777315, for discriminator pretraining 
epoch 70, samples 647680, loss 0.626724, accuracy 0.832031 BatchTime 1.745205, for discriminator pretraining 
epoch 70, samples 647936, loss 0.638969, accuracy 0.859375 BatchTime 1.791264, for discriminator pretraining 
epoch 70, samples 648192, loss 0.509149, accuracy 0.863281 BatchTime 1.680203, for discriminator pretraining 
epoch 70, samples 648448, loss 0.380751, accuracy 0.855469 BatchTime 1.772325, for discriminator pretraining 
epoch 70, samples 648704, loss 0.548889, accuracy 0.863281 BatchTime 1.739416, for discriminator pretraining 
epoch 70, samples 648960, loss 0.523313, accuracy 0.851562 BatchTime 1.767926, for discriminator pretraining 
epoch 70, samples 649216, loss 0.418762, accuracy 0.871094 BatchTime 1.639447, for discriminator pretraining 
epoch 70, samples 649472, loss 0.439438, accuracy 0.875000 BatchTime 1.726153, for discriminator pretraining 
epoch 70, samples 649728, loss 0.508456, accuracy 0.847656 BatchTime 1.667749, for discriminator pretraining 
epoch 70, samples 649984, loss 0.607035, accuracy 0.835938 BatchTime 1.844372, for discriminator pretraining 
epoch 70, samples 650240, loss 0.550482, accuracy 0.863281 BatchTime 1.747970, for discriminator pretraining 
epoch 70, samples 650496, loss 0.514166, accuracy 0.843750 BatchTime 1.722313, for discriminator pretraining 
epoch 70, samples 650752, loss 0.405609, accuracy 0.871094 BatchTime 1.740367, for discriminator pretraining 
epoch 70, samples 651008, loss 0.818961, accuracy 0.832031 BatchTime 1.850177, for discriminator pretraining 
epoch 70, samples 651264, loss 0.730100, accuracy 0.863281 BatchTime 1.590764, for discriminator pretraining 
epoch 70, samples 651520, loss 0.598436, accuracy 0.859375 BatchTime 1.700164, for discriminator pretraining 
epoch 70, samples 651776, loss 0.498265, accuracy 0.859375 BatchTime 1.587255, for discriminator pretraining 
epoch 70, samples 652032, loss 0.837308, accuracy 0.800781 BatchTime 1.650838, for discriminator pretraining 
epoch 70, samples 652288, loss 0.770191, accuracy 0.835938 BatchTime 1.610923, for discriminator pretraining 
epoch 70, samples 652544, loss 0.634443, accuracy 0.828125 BatchTime 1.756463, for discriminator pretraining 
epoch 70, samples 652800, loss 0.631733, accuracy 0.851562 BatchTime 1.771513, for discriminator pretraining 
epoch 70, samples 653056, loss 0.660696, accuracy 0.835938 BatchTime 1.706750, for discriminator pretraining 
epoch 70, samples 653312, loss 0.396589, accuracy 0.890625 BatchTime 1.596680, for discriminator pretraining 
epoch 70, samples 653568, loss 0.538703, accuracy 0.820312 BatchTime 1.733890, for discriminator pretraining 
epoch 70, samples 653824, loss 0.453130, accuracy 0.875000 BatchTime 1.622710, for discriminator pretraining 
epoch 70, samples 654080, loss 0.551486, accuracy 0.839844 BatchTime 1.724319, for discriminator pretraining 
epoch 70, samples 654336, loss 0.607626, accuracy 0.821429 BatchTime 0.850607, for discriminator pretraining 
Seen  8988  examples for discriminator. Time Cost :  61.00060725212097
load vocab successfully!!
Epoch : 71
epoch 71, samples 654592, loss 0.404221, accuracy 0.882812 BatchTime 2.796030, for discriminator pretraining 
epoch 71, samples 654848, loss 0.364335, accuracy 0.878906 BatchTime 1.771868, for discriminator pretraining 
epoch 71, samples 655104, loss 0.469470, accuracy 0.875000 BatchTime 1.726021, for discriminator pretraining 
epoch 71, samples 655360, loss 0.554161, accuracy 0.855469 BatchTime 1.598976, for discriminator pretraining 
epoch 71, samples 655616, loss 0.515749, accuracy 0.863281 BatchTime 1.704711, for discriminator pretraining 
epoch 71, samples 655872, loss 0.320053, accuracy 0.902344 BatchTime 1.626387, for discriminator pretraining 
epoch 71, samples 656128, loss 0.414474, accuracy 0.863281 BatchTime 1.715009, for discriminator pretraining 
epoch 71, samples 656384, loss 0.417107, accuracy 0.875000 BatchTime 1.577872, for discriminator pretraining 
epoch 71, samples 656640, loss 0.497205, accuracy 0.851562 BatchTime 1.697370, for discriminator pretraining 
epoch 71, samples 656896, loss 0.527810, accuracy 0.839844 BatchTime 1.642248, for discriminator pretraining 
epoch 71, samples 657152, loss 0.561735, accuracy 0.867188 BatchTime 1.795533, for discriminator pretraining 
epoch 71, samples 657408, loss 0.540631, accuracy 0.871094 BatchTime 1.696210, for discriminator pretraining 
epoch 71, samples 657664, loss 0.359616, accuracy 0.890625 BatchTime 1.774879, for discriminator pretraining 
epoch 71, samples 657920, loss 0.542131, accuracy 0.871094 BatchTime 1.655094, for discriminator pretraining 
epoch 71, samples 658176, loss 0.510944, accuracy 0.839844 BatchTime 1.747218, for discriminator pretraining 
epoch 71, samples 658432, loss 0.527822, accuracy 0.855469 BatchTime 1.663261, for discriminator pretraining 
epoch 71, samples 658688, loss 0.343530, accuracy 0.906250 BatchTime 1.709234, for discriminator pretraining 
epoch 71, samples 658944, loss 0.570503, accuracy 0.832031 BatchTime 1.749339, for discriminator pretraining 
epoch 71, samples 659200, loss 0.402349, accuracy 0.855469 BatchTime 1.795733, for discriminator pretraining 
epoch 71, samples 659456, loss 0.489376, accuracy 0.875000 BatchTime 1.691237, for discriminator pretraining 
epoch 71, samples 659712, loss 0.500534, accuracy 0.875000 BatchTime 1.744888, for discriminator pretraining 
epoch 71, samples 659968, loss 0.488796, accuracy 0.855469 BatchTime 1.648936, for discriminator pretraining 
epoch 71, samples 660224, loss 0.463698, accuracy 0.875000 BatchTime 1.796008, for discriminator pretraining 
epoch 71, samples 660480, loss 0.608395, accuracy 0.820312 BatchTime 1.759467, for discriminator pretraining 
epoch 71, samples 660736, loss 0.675725, accuracy 0.839844 BatchTime 1.666689, for discriminator pretraining 
epoch 71, samples 660992, loss 0.668052, accuracy 0.816406 BatchTime 1.604844, for discriminator pretraining 
epoch 71, samples 661248, loss 0.561641, accuracy 0.863281 BatchTime 1.729348, for discriminator pretraining 
epoch 71, samples 661504, loss 0.688012, accuracy 0.820312 BatchTime 1.670295, for discriminator pretraining 
epoch 71, samples 661760, loss 0.727148, accuracy 0.816406 BatchTime 1.710588, for discriminator pretraining 
epoch 71, samples 662016, loss 0.644011, accuracy 0.847656 BatchTime 1.672193, for discriminator pretraining 
epoch 71, samples 662272, loss 0.619992, accuracy 0.847656 BatchTime 1.670027, for discriminator pretraining 
epoch 71, samples 662528, loss 0.730106, accuracy 0.796875 BatchTime 1.615014, for discriminator pretraining 
epoch 71, samples 662784, loss 0.485362, accuracy 0.875000 BatchTime 1.756198, for discriminator pretraining 
epoch 71, samples 663040, loss 0.499745, accuracy 0.843750 BatchTime 1.632282, for discriminator pretraining 
epoch 71, samples 663296, loss 0.468061, accuracy 0.875000 BatchTime 1.764403, for discriminator pretraining 
epoch 71, samples 663552, loss 0.794738, accuracy 0.800000 BatchTime 0.849035, for discriminator pretraining 
Seen  8990  examples for discriminator. Time Cost :  60.49520564079285
load vocab successfully!!
Epoch : 72
epoch 72, samples 663808, loss 0.488575, accuracy 0.839844 BatchTime 2.895089, for discriminator pretraining 
epoch 72, samples 664064, loss 0.646300, accuracy 0.832031 BatchTime 1.767262, for discriminator pretraining 
epoch 72, samples 664320, loss 0.489858, accuracy 0.835938 BatchTime 1.707704, for discriminator pretraining 
epoch 72, samples 664576, loss 0.340837, accuracy 0.882812 BatchTime 1.622755, for discriminator pretraining 
epoch 72, samples 664832, loss 0.488466, accuracy 0.875000 BatchTime 1.877118, for discriminator pretraining 
epoch 72, samples 665088, loss 0.551378, accuracy 0.855469 BatchTime 1.746080, for discriminator pretraining 
epoch 72, samples 665344, loss 0.436919, accuracy 0.890625 BatchTime 1.752480, for discriminator pretraining 
epoch 72, samples 665600, loss 0.324684, accuracy 0.910156 BatchTime 1.661740, for discriminator pretraining 
save params when epoch 72, samples 665600
epoch 72, samples 665856, loss 0.488411, accuracy 0.890625 BatchTime 1.751533, for discriminator pretraining 
epoch 72, samples 666112, loss 0.391563, accuracy 0.867188 BatchTime 1.682151, for discriminator pretraining 
epoch 72, samples 666368, loss 0.730829, accuracy 0.828125 BatchTime 1.787268, for discriminator pretraining 
epoch 72, samples 666624, loss 0.502758, accuracy 0.867188 BatchTime 1.735368, for discriminator pretraining 
epoch 72, samples 666880, loss 0.569026, accuracy 0.867188 BatchTime 1.735144, for discriminator pretraining 
epoch 72, samples 667136, loss 0.459576, accuracy 0.871094 BatchTime 1.627249, for discriminator pretraining 
epoch 72, samples 667392, loss 0.376661, accuracy 0.882812 BatchTime 1.835433, for discriminator pretraining 
epoch 72, samples 667648, loss 0.469120, accuracy 0.855469 BatchTime 1.743781, for discriminator pretraining 
epoch 72, samples 667904, loss 0.567080, accuracy 0.875000 BatchTime 1.751815, for discriminator pretraining 
epoch 72, samples 668160, loss 0.562061, accuracy 0.855469 BatchTime 1.652383, for discriminator pretraining 
epoch 72, samples 668416, loss 0.493707, accuracy 0.882812 BatchTime 1.756310, for discriminator pretraining 
epoch 72, samples 668672, loss 0.449156, accuracy 0.855469 BatchTime 1.629264, for discriminator pretraining 
epoch 72, samples 668928, loss 0.461044, accuracy 0.863281 BatchTime 1.704642, for discriminator pretraining 
epoch 72, samples 669184, loss 0.480894, accuracy 0.863281 BatchTime 1.741988, for discriminator pretraining 
epoch 72, samples 669440, loss 0.623027, accuracy 0.824219 BatchTime 1.780250, for discriminator pretraining 
epoch 72, samples 669696, loss 0.536345, accuracy 0.843750 BatchTime 1.622086, for discriminator pretraining 
epoch 72, samples 669952, loss 0.700190, accuracy 0.824219 BatchTime 1.724276, for discriminator pretraining 
epoch 72, samples 670208, loss 0.477905, accuracy 0.871094 BatchTime 1.588874, for discriminator pretraining 
epoch 72, samples 670464, loss 0.447288, accuracy 0.875000 BatchTime 1.737034, for discriminator pretraining 
epoch 72, samples 670720, loss 0.407858, accuracy 0.863281 BatchTime 1.772297, for discriminator pretraining 
epoch 72, samples 670976, loss 0.631532, accuracy 0.851562 BatchTime 1.806972, for discriminator pretraining 
epoch 72, samples 671232, loss 0.618748, accuracy 0.851562 BatchTime 1.633870, for discriminator pretraining 
epoch 72, samples 671488, loss 0.445103, accuracy 0.875000 BatchTime 1.735509, for discriminator pretraining 
epoch 72, samples 671744, loss 0.639533, accuracy 0.835938 BatchTime 1.616040, for discriminator pretraining 
epoch 72, samples 672000, loss 0.518430, accuracy 0.863281 BatchTime 1.784407, for discriminator pretraining 
epoch 72, samples 672256, loss 0.538276, accuracy 0.855469 BatchTime 1.701923, for discriminator pretraining 
epoch 72, samples 672512, loss 0.690877, accuracy 0.835938 BatchTime 1.712930, for discriminator pretraining 
epoch 72, samples 672768, loss 0.997736, accuracy 0.763158 BatchTime 0.897281, for discriminator pretraining 
Seen  8998  examples for discriminator. Time Cost :  67.70639228820801
load vocab successfully!!
Epoch : 73
epoch 73, samples 673024, loss 0.364119, accuracy 0.894531 BatchTime 2.940357, for discriminator pretraining 
epoch 73, samples 673280, loss 0.789419, accuracy 0.828125 BatchTime 1.768518, for discriminator pretraining 
epoch 73, samples 673536, loss 0.592030, accuracy 0.867188 BatchTime 1.738732, for discriminator pretraining 
epoch 73, samples 673792, loss 0.501816, accuracy 0.871094 BatchTime 1.713351, for discriminator pretraining 
epoch 73, samples 674048, loss 0.272788, accuracy 0.921875 BatchTime 1.713313, for discriminator pretraining 
epoch 73, samples 674304, loss 0.416977, accuracy 0.839844 BatchTime 1.701627, for discriminator pretraining 
epoch 73, samples 674560, loss 0.387132, accuracy 0.882812 BatchTime 1.730862, for discriminator pretraining 
epoch 73, samples 674816, loss 0.345757, accuracy 0.878906 BatchTime 1.764774, for discriminator pretraining 
epoch 73, samples 675072, loss 0.266817, accuracy 0.914062 BatchTime 1.801934, for discriminator pretraining 
epoch 73, samples 675328, loss 0.435011, accuracy 0.855469 BatchTime 1.599367, for discriminator pretraining 
epoch 73, samples 675584, loss 0.442059, accuracy 0.878906 BatchTime 1.669361, for discriminator pretraining 
epoch 73, samples 675840, loss 0.541185, accuracy 0.828125 BatchTime 1.590261, for discriminator pretraining 
epoch 73, samples 676096, loss 0.519040, accuracy 0.847656 BatchTime 1.706389, for discriminator pretraining 
epoch 73, samples 676352, loss 0.316210, accuracy 0.890625 BatchTime 1.641962, for discriminator pretraining 
epoch 73, samples 676608, loss 0.467991, accuracy 0.851562 BatchTime 1.779912, for discriminator pretraining 
epoch 73, samples 676864, loss 0.453194, accuracy 0.871094 BatchTime 1.761058, for discriminator pretraining 
epoch 73, samples 677120, loss 0.629328, accuracy 0.859375 BatchTime 1.744858, for discriminator pretraining 
epoch 73, samples 677376, loss 0.660077, accuracy 0.824219 BatchTime 1.632254, for discriminator pretraining 
epoch 73, samples 677632, loss 0.589010, accuracy 0.859375 BatchTime 1.723109, for discriminator pretraining 
epoch 73, samples 677888, loss 0.542699, accuracy 0.832031 BatchTime 1.627710, for discriminator pretraining 
epoch 73, samples 678144, loss 0.413252, accuracy 0.882812 BatchTime 1.720695, for discriminator pretraining 
epoch 73, samples 678400, loss 0.574104, accuracy 0.835938 BatchTime 1.637595, for discriminator pretraining 
epoch 73, samples 678656, loss 0.424691, accuracy 0.890625 BatchTime 1.714915, for discriminator pretraining 
epoch 73, samples 678912, loss 0.403745, accuracy 0.855469 BatchTime 1.635616, for discriminator pretraining 
epoch 73, samples 679168, loss 0.485515, accuracy 0.843750 BatchTime 1.738791, for discriminator pretraining 
epoch 73, samples 679424, loss 0.441845, accuracy 0.859375 BatchTime 1.721810, for discriminator pretraining 
epoch 73, samples 679680, loss 0.532888, accuracy 0.843750 BatchTime 1.787311, for discriminator pretraining 
epoch 73, samples 679936, loss 0.658335, accuracy 0.828125 BatchTime 1.655944, for discriminator pretraining 
epoch 73, samples 680192, loss 0.667111, accuracy 0.843750 BatchTime 1.715075, for discriminator pretraining 
epoch 73, samples 680448, loss 0.507693, accuracy 0.851562 BatchTime 1.625393, for discriminator pretraining 
epoch 73, samples 680704, loss 0.665016, accuracy 0.851562 BatchTime 1.722951, for discriminator pretraining 
epoch 73, samples 680960, loss 0.711497, accuracy 0.824219 BatchTime 1.627439, for discriminator pretraining 
epoch 73, samples 681216, loss 0.643961, accuracy 0.832031 BatchTime 1.752711, for discriminator pretraining 
epoch 73, samples 681472, loss 0.709665, accuracy 0.828125 BatchTime 1.732747, for discriminator pretraining 
epoch 73, samples 681728, loss 0.511622, accuracy 0.832031 BatchTime 1.790735, for discriminator pretraining 
epoch 73, samples 681984, loss 0.594454, accuracy 0.815789 BatchTime 0.877698, for discriminator pretraining 
Seen  8998  examples for discriminator. Time Cost :  60.92918062210083
load vocab successfully!!
Epoch : 74
epoch 74, samples 682240, loss 0.474697, accuracy 0.875000 BatchTime 2.555678, for discriminator pretraining 
epoch 74, samples 682496, loss 0.450629, accuracy 0.863281 BatchTime 1.732425, for discriminator pretraining 
epoch 74, samples 682752, loss 0.402665, accuracy 0.902344 BatchTime 1.724016, for discriminator pretraining 
epoch 74, samples 683008, loss 0.325553, accuracy 0.878906 BatchTime 1.737518, for discriminator pretraining 
epoch 74, samples 683264, loss 0.363475, accuracy 0.890625 BatchTime 1.809844, for discriminator pretraining 
epoch 74, samples 683520, loss 0.296131, accuracy 0.898438 BatchTime 1.674894, for discriminator pretraining 
epoch 74, samples 683776, loss 0.502326, accuracy 0.847656 BatchTime 1.725313, for discriminator pretraining 
epoch 74, samples 684032, loss 0.403124, accuracy 0.890625 BatchTime 1.701828, for discriminator pretraining 
epoch 74, samples 684288, loss 0.258906, accuracy 0.910156 BatchTime 1.815562, for discriminator pretraining 
epoch 74, samples 684544, loss 0.441083, accuracy 0.859375 BatchTime 1.689179, for discriminator pretraining 
Killed
